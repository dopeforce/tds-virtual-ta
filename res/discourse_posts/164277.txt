---
id:          164277
title:       Project 1 - LLM-based Automation Agent - Discussion Thread [TDS Jan 2025]
created_at:  2025-01-19T08:17:46.650Z
---

[2025-01-19T08:17:46.856Z] Anand S (@s.anand: Course_faculty)
Please post any questions related to
Project 1 - LLM-based Automation Agent
.
Deadline:
Sunday, February 16, 2025 6:29 PM
Update on 27 Jan 2025
:
A
sample
evaluation script for Project 1 tasks A1-A10 is available at
tools-in-data-science-public/project-1 at tds-2025-01-project-1-wip ¬∑ sanand0/tools-in-data-science-public ¬∑ GitHub
You can use this to validate your code for Project 1.
Please note:
This is a sample. It
WILL
change.
Don‚Äôt rely on the dataset being the same. It
WILL
change.
LLMs give different results each time they are called. Make sure:
Your code gives correct results
reliably
(i.e. try a few times)
Change the task in the evaluation script slightly to test variations
Your
AI Proxy usage
resets on 1 Feb. You have a limited budget. Utilize what you can this month.
For those who
submit their code
by Friday 31 Jan, I will run a sample evaluation and share the results.

[2025-01-19T08:20:32.879Z] Anand S (@s.anand: Course_faculty)


[2025-01-19T13:44:38.945Z] Shouvik Roy  (@roy2003)
sir show us all the way to do project

[2025-01-19T13:45:31.017Z] Jivraj Singh Shekhawat (@Jivraj: Course TA)
Hi Shouvik,
We will have live sessions to guide on how to do project.
Kind regards
Jivraj

[2025-01-20T10:44:32.687Z] Sakthivel S (@23f2000237)
Will those session be on youtube too?

[2025-01-20T10:48:22.899Z] Carlton D'Silva (@carlton: Regular)
Hi Sakthivel,
Yes all sessions are being recorded and are available on youtube within a day.
Jan 25 TDS Playlist
Kind regards

[2025-01-23T09:57:29.120Z] Guddu Kumar Mishra  (@22f3001315)
Screenshot 2025-01-23 151614
1281√ó125 18.1 KB
sir
@Jivraj
after editing line 127 in datagen.py i got those  required data files. is it allowed ? also i had to run datagen.py MANUALLY(is this process also should be automatic)?

[2025-01-23T11:30:21.008Z] Jivraj Singh Shekhawat (@Jivraj: Course TA)
Hi Guddu ,
I didn‚Äôt make any changes to file and it worked for me. Can you mention what is need of making changes ?
command that I used :
uv run datagen.py 22f3002542@ds.study.iitm.ac.in --root ./data
here --root option defines the folder where you want to store generated data. by default it would try to create a folder in root directory of operating system.
Kind regards
Jivraj

[2025-01-23T13:05:16.643Z] Aishik Bandyopadhyay (@23f2005325)
getting this issue :
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Your authentication token is not from a valid issuer.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_issuer'}}

[2025-01-23T13:22:03.304Z] Jivraj Singh Shekhawat (@Jivraj: Course TA)
Hi Aishik,
Pls add context to your query, without that we won‚Äôt be able to understand, where exactly you are facing problem.
23f2005325:
openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Your authentication token is not from a valid issuer.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_issuer'}}
Possible reasons for this issue:
Not using anand sir‚Äôs proxy url for sending requests.
Token not being correct.

[2025-01-25T16:20:57.111Z] Aishik Bandyopadhyay (@23f2005325)
yes I was not setting the base url to the proxy. I have fixed it thank you .

[2025-01-25T18:12:39.754Z] Aishik Bandyopadhyay (@23f2005325)
While implementing task A5, I am confused about what recent actually means in the phrase ‚Äúrecent log file‚Äù, mentioned under task A5, in the problem statement. This confusion arises because there are no dates corresponding to the log files. Should I consider log-0 as the most recent one? or the log-<largest_number> file? Please clarify.

[2025-01-26T10:30:43.750Z] Aishik Bandyopadhyay (@23f2005325)
I am getting the following response when I am trying to extract credit card number from the credit-card.png :
{'id': 'chatcmpl-<redacted>', 'object': 'chat.completion', 'created': 1737872397, 'model': 'gpt-4o-mini-2024-07-18', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': "I'm sorry, but I can't assist with that.", 'refusal': None}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 946, 'completion_tokens': 11, 'total_tokens': 957, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'service_tier': 'default', 'system_fingerprint': '<redacted>', 'monthlyCost': 0.07715699999999998, 'cost': 0.0029040000000000003, 'monthlyRequests': 31, 'costError': 'crypto.createHash is not a function'}
my code is as below :
def extract_credit_card_number():
    import requests
    import base64
    import os
    from dotenv import load_dotenv
    load_dotenv()

    BASE_URL = "http://aiproxy.sanand.workers.dev/openai/v1/chat/completions"
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {os.environ["AIPROXY_TOKEN"]}"
    }

    image_path = "../data/credit_card.png"

    with open(image_path, "rb") as image_file:
        base64_image = base64.b64encode(image_file.read()).decode("utf-8")

    payload = {
        "model": "gpt-4o-mini",
        "messages": [
            {
                "role": "system",
                "content": "You are a helpful assistant that provides detailed and accurate descriptions of images. Focus on describing the objects, colors, textures, the overall scene, and most importantly, the text and numbers in the image. Be concise but thorough."
            },
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": "You are given an image containing a credit card number. Extract the credit card number from the image"
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/png;base64,{base64_image}"
                        }
                    }
                ]
            }
        ],
    }

    response = requests.post(BASE_URL, headers=headers, json=payload)

    if response.status_code == 200:
        result = response.json()
        print("RESULT:", result)
        cno = result["choices"][0]["message"]["content"]
        print("CREDIT CARD NUMBER:", cno)
    else:
        print(f"Error: {response.status_code}")
        print(response.text)
please guide
@Jivraj
@Saransh_Saini

[2025-01-26T17:16:01.337Z] Sathyavathi S  (@23f1000299)
do we have to do these tasks in the linux? As in some of the GA1, the linux answers only accepted. Please tell me that, do we can do it in the desktop or we have to use linux?
@Jivraj
@carlton

[2025-01-26T18:10:34.636Z] Saransh Saini (@Saransh_Saini: Course TA)
The bash commands are usually run in a linux machine, but you can easily run those commands in VSCode without installing any virtual machines. Download the WSL extension in VSCode and you will get a WSL terminal to work with.
For more information watch this video
https://youtu.be/q74CP4fB7cY?si=M_zw8WzpmMCyVQat
or watch TDS Live Sessions.
Regards,
TDS TA

[2025-01-27T01:27:41.658Z] Andrew David (@23f1002382)
what frameworks can we use? hopefully anything?
or what frameworks can‚Äôt we use?
@carlton
@Jivraj

[2025-01-27T03:04:44.636Z] Carlton D'Silva (@carlton: Regular)
Project 1 deliverables are all that matter. How you accomplish them is not very relevant. The keys to a successful Project 1 are:
Deliverables,
and
an example
of the Evaluation has been provided.
If your project runs in accordance with the Evaluation methodology then it is considered.
Screenshot 2025-01-27 at 8.35.23 am
1764√ó1764 374 KB
Please read the documentation carefully from top to bottom.
So the main question is how do you test if the script will run according to the evaluation? The whole point is for it to run not just on your system. It should be deployable anywhere on any machine. Your solution should work anywhere we test it. Thats why you package it in a docker container. How you achieve that is up to you. But if we cannot run your docker container according to the specification we have provided then it has failed this crucial test.
Kind regards

[2025-01-27T03:09:21.493Z] Carlton D'Silva (@carlton: Regular)
@23f1002382
You can use any library as long as your Project 1 meets the deliverable requirements and does all the (20+) API tasks.
Kind regards

[2025-01-27T13:32:36.477Z] Anand S (@s.anand: Course_faculty)
A
sample
evaluation script for Project 1 tasks A1-A10 is available at
tools-in-data-science-public/project-1 at tds-2025-01-project-1-wip ¬∑ sanand0/tools-in-data-science-public ¬∑ GitHub
You can use this to validate your code for Project 1.
Please note:
This is a sample. It
WILL
change.
Don‚Äôt rely on the dataset being the same. It
WILL
change.
LLMs give different results each time they are called. Make sure:
Your code gives correct results
reliably
(i.e. try a few times)
Change the task in the evaluation script slightly to test variations
Your
AI Proxy usage
resets on 1 Feb. You have a limited budget. Utilize what you can this month.
For those who
submit their code
by Friday, I will run a sample evaluation and share the results.
@carlton
@Jivraj
@Saransh_Saini
- please socialize this during the live sessions.

[2025-01-27T14:00:22.634Z] Divyasree (@Divya1)
By clicking the project link ,I am getting the notes‚Ä¶but no project is available in my project 1

[2025-01-27T14:02:29.072Z] Divyasree (@Divya1)
by clicking the link
image
1198√ó136 9.49 KB
image
1750√ó581 70.9 KB
I am getting this opened.

[2025-01-27T21:30:57.919Z] Jivraj Singh Shekhawat (@Jivraj: Course TA)
Hi
@Divya1
,
There won‚Äôt be any project1 page such as GA1s, there is a google form(which can be found in same page) which needs to be filled after you do project1.

[2025-01-27T21:57:49.221Z] Jivraj Singh Shekhawat (@Jivraj: Course TA)
Hi
@23f2005325
,
Extracting details from credit cards is sensitive, try using strong prompts or take code from LLM and execute it in script.
kind regards

[2025-01-28T08:28:17.260Z] Andrew David (@23f1002382)
Regarding Wednenday 9-10 pm live session, maybe the instructors could also discuss how to use docker as a virtual environment using maybe ollama(local llm as now there is deepseek opensource, i doubt we would need to use openai for testing, just for production(test submission)  would be enough) and also some agent(langchain, autogen, crewai) just a quick how-to on setting up and problems while setting up if possible
More resources on docker. Using docker as a virtual environment. Editing and executing code in Dockerfiles (like when you change code in src a web framework automatically reloads page(hot reload)), something along the lines of this .
@carlton
@Jivraj

[2025-01-28T11:55:55.799Z] Jivraj Singh Shekhawat (@Jivraj: Course TA)
23f1002382:
Regarding Wednenday 9-10 pm live session, maybe the instructors could also discuss how to use docker as a virtual environmen
In Tuesday‚Äôs(21 January) session we had discussed docker towards ending of session.
What was discussed in that live session regarding docker:
Search for existing containers on repositories such as dockerhub.
Pull an existing docker image.
Run that image inside a container.
Enter to that container and modify something(such as installing python inside a ubuntu container, for customization or create some file)
Once done you can commit it.
And push customized container‚Äôs image to docker hub.
Regarding local models running for project1, it‚Äôs a good idea, we will see if it‚Äôs possible to discuss in session.

[2025-01-28T18:07:19.143Z] Divyasree (@Divya1)
In the google forms , I have 2 questions in one form now to submit should it is compulsory that to answer the both the questions?

[2025-01-29T02:57:18.959Z] Carlton D'Silva (@carlton: Regular)
Hi
@Divya1
Screenshot 2025-01-29 at 8.19.05 am
1738√ó982 122 KB
Please do very carefully all things mentioned in the Deliverables as well as look at the Evaluation Section.
Screenshot 2025-01-29 at 8.26.08 am
1460√ó496 45.5 KB
We had a session on 28th Jan introducing all the important aspects of Project.
If you do not do everything exactly as mentioned
especially the pre - requisites
mentioned in the Evaluation section you will get 0 in the project and
there will be no appeal
for failing to meet the pre - requisites of the evaluation criteria.
In order for us to evaluate the project you have to provide the deliverables mentioned above.
Kind regards

[2025-01-29T06:32:45.816Z] Andrew David (@23f1002382)
Subject:
Request to Add Instructors to Private GitHub Repo
Message:
"Dear [Instructors‚Äô Names],
I‚Äôve set up the environment and dependencies for the project and was wondering if it would be appropriate to add you to my private GitHub repository. I‚Äôd appreciate any guidance on improving performance, scalability, and design principles. Please let me know if this is feasible or if there‚Äôs a more suitable way to seek feedback. Apologies if this request is out of scope.
Thank you for your time!
Best,
[Your Name]"*
ChatGPT can make mistakes. Check important info.

[2025-01-29T10:41:16.527Z] Anand S (@s.anand: Course_faculty)
@23f1002382
- You‚Äôre welcome to use the evaluation script in this post for private repos.
Project 1 - LLM-based Automation Agent - Discussion Thread [TDS Jan 2025]
Tools in Data Science
A sample evaluation script for Project 1 tasks A1-A10 is available at
tools-in-data-science-public/project-1 at tds-2025-01-project-1-wip ¬∑ sanand0/tools-in-data-science-public ¬∑ GitHub
You can use this to validate your code for Project 1.
Please note:

This is a sample. It WILL change.
Don‚Äôt rely on the dataset being the same. It WILL change.
LLMs give different results each time they are called. Make sure:

Your code gives correct results reliably (i.e. try a few times)
Change the task in t‚Ä¶
For public repos submitted in the form, I‚Äôll run this script over the weekend and share preliminary results.

[2025-01-29T11:29:04.323Z] Andrew David (@23f1002382)
T  h  a  n  k      y  o  u         sir.

[2025-01-30T06:20:34.650Z] Joel Jeffrey (@JoelJeffrey)
For A6, /data/docs/ has subfolders with .md files from which we have to extract the heading level 1‚Äôs (#) right? Apparently there are few files with different content but the same name. Can someone confirm the same? If yes how to address these files
@Jivraj
@carlton

[2025-01-30T06:26:20.605Z] Andrew David (@23f1002382)
I had set up the environment and dependencies and everything was working fine. When i tried to recreate it from scratch in a new codespace it broke. I fixed almost everything except this error
@ANdIeCOOl ‚ûú /workspaces/TDS-Project-1 (main) $ crewai create crew b2b
Traceback (most recent call last):
  File "/home/codespace/.python/current/bin/crewai", line 5, in <module>
    from crewai.cli.cli import crewai
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/crewai/__init__.py", line 3, in <module>
    from crewai.agent import Agent
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/crewai/agent.py", line 7, in <module>
    from crewai.agents import CacheHandler
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/crewai/agents/__init__.py", line 2, in <module>
    from .parser import CrewAgentParser
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/crewai/agents/parser.py", line 6, in <module>
    from crewai.utilities import I18N
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/crewai/utilities/__init__.py", line 13, in <module>
    from .embedding_configurator import EmbeddingConfigurator
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/crewai/utilities/embedding_configurator.py", line 4, in <module>
    from chromadb import Documents, EmbeddingFunction, Embeddings
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/chromadb/__init__.py", line 6, in <module>
    from chromadb.auth.token_authn import TokenTransportHeader
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/chromadb/auth/token_authn/__init__.py", line 24, in <module>
    from chromadb.telemetry.opentelemetry import (
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/chromadb/telemetry/opentelemetry/__init__.py", line 13, in <module>
    from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/grpc/trace_exporter/__init__.py", line 25, in <module>
    from opentelemetry.exporter.otlp.proto.grpc.exporter import (  # noqa: F401
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/opentelemetry/exporter/otlp/proto/grpc/exporter.py", line 72, in <module>
    from opentelemetry.sdk.metrics.export import MetricsData
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/opentelemetry/sdk/metrics/__init__.py", line 16, in <module>
    from opentelemetry.sdk.metrics._internal import Meter, MeterProvider
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/opentelemetry/sdk/metrics/_internal/__init__.py", line 56, in <module>
    from opentelemetry.sdk.metrics._internal.measurement_consumer import (
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/opentelemetry/sdk/metrics/_internal/measurement_consumer.py", line 29, in <module>
    from opentelemetry.sdk.metrics._internal.metric_reader_storage import (
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/opentelemetry/sdk/metrics/_internal/metric_reader_storage.py", line 26, in <module>
    from opentelemetry.sdk.metrics._internal._view_instrument_match import (
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/opentelemetry/sdk/metrics/_internal/_view_instrument_match.py", line 22, in <module>
    from opentelemetry.sdk.metrics._internal.aggregation import (
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/opentelemetry/sdk/metrics/_internal/aggregation.py", line 48, in <module>
    from opentelemetry.sdk.metrics._internal.exponential_histogram.mapping.exponent_mapping import (
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/opentelemetry/sdk/metrics/_internal/exponential_histogram/mapping/exponent_mapping.py", line 25, in <module>
    from opentelemetry.sdk.metrics._internal.exponential_histogram.mapping.ieee_754 import (
  File "/usr/local/python/3.12.1/lib/python3.12/site-packages/opentelemetry/sdk/metrics/_internal/exponential_histogram/mapping/ieee_754.py", line 15, in <module>
    from ctypes import c_double, c_uint64
  File "/usr/local/python/3.12.1/lib/python3.12/ctypes/__init__.py", line 8, in <module>
    from _ctypes import Union, Structure, Array
ImportError: /usr/local/python/3.12.1/lib/python3.12/lib-dynload/_ctypes.cpython-312-x86_64-linux-gnu.so: undefined symbol: ffi_type_uint32, version LIBFFI_BASE_7.0
i updated the libffi package using sudo but while breaking something else can someone pls help me?
@carlton
@Jivraj
@s.anand
history of commands in new codespace
1  crewai --version
    2  pip install crewai crewai-tools
    3  python3 -c "import sqlite3; print(sqlite3.sqlite_version)"
    4  export PATH=/opt/conda/bin:$PATH
    5  export LD_LIBRARY_PATH=/opt/conda/lib:$LD_LIBRARY_PATH
    6  python3 -c "import sqlite3; print(sqlite3.sqlite_version)"
    7  crewai create crew <project_name>
    8  crewai create crew b2b
    9  history
UPDATE: IT‚Äôs WORKING if you do this in order
1  python3 -c "import sqlite3; print(sqlite3.sqlite_version)"
    2  export PATH=/opt/conda/bin:$PATH
    3  export LD_LIBRARY_PATH=/opt/conda/lib:$LD_LIBRARY_PATH
    4  python3 -c "import sqlite3; print(sqlite3.sqlite_version)"
    5  pip install --no-cache-dir --force-reinstall typing_extensions pydantic crewai crewai-tools
    6  conda install -c conda-forge typing_extensions
    7  exec bash
    8  crewai create crew "Project 1 - LLM-based Automation Agent"
Something about different environment conda and python can the instructors please help me understand it(resources ), so i can trouble shoot this later with better accuracy come precision

[2025-01-30T12:51:19.538Z] Andrew David (@23f1002382)
evaluate.py
TDS course repo
github.com
tools-in-data-science-public/project-1 at tds-2025-01-project-1-wip ¬∑...
Contribute to sanand0/tools-in-data-science-public development by creating an account on GitHub.
line 20
from datagen import (
    get_markdown,
    get_dates,
    get_contacts,
    get_logs,
    get_docs,
    get_email,
    get_credit_card,
    get_comments,
    get_tickets,
)
but we get datagen.py only in a1 task
line 69
async def a1(email: str, **kwargs):
    await run(
        f"""
Install `uv` (if required) and run the script `https://raw.githubusercontent.com/sanand0/tools-in-data-science-public/tds-2025-01/datagen.py`
with `{email}` as the only argument
"""
    )
    return email in await read("/data/format.md")
The issue is
importing
datagen
before ensuring it exists
just checking
@carlton
@Jivraj

[2025-01-30T21:37:48.839Z] Jivraj Singh Shekhawat (@Jivraj: Course TA)
Hi
@23f1002382
,
Yes datagen.py must be present in same directory from where you  are executing evaluate.py.
Oh, You trying to use crewai locally for Project1
kind regards

[2025-01-30T21:56:52.077Z] Jivraj Singh Shekhawat (@Jivraj: Course TA)
Hi
@JoelJeffrey
,
Filepath is unique for every file, which needs to be inserted to json file.

[2025-01-31T06:55:55.139Z] Joel Jeffrey (@JoelJeffrey)
Ok. So just to confirm, since there are files with the same name, the json file should map the filepath and not the filename to the title right?
Screenshot from 2025-01-31 12-25-29
790√ó117 19.9 KB

[2025-01-31T08:40:50.303Z] Andrew David (@23f1002382)
no crewai, it takes really long i put time out for 300 secs(in run(task:str) in evaluate.py) still sometimes its not enough. I‚Äôll try with autogen next and then langchain

[2025-01-31T08:41:45.108Z] Guddu Kumar Mishra  (@22f3001315)
INFO:     127.0.0.1:65085 - "GET /read?path=/data/format.md HTTP/1.1" 200 OK
data/format.md 81ms
INFO:     127.0.0.1:65149 - "POST /run?task=%0AFormat+the+contents+of+%60%2Fdata%2Fformat.md%60+using+%60prettier%403.4.2%60%2C+updating+the+file+in-place%0A HTTP/1.1" 200 OK
INFO:     127.0.0.1:65251 - "GET /read?path=/data/format.md HTTP/1.1" 200 OK
INFO:     127.0.0.1:65263 - "POST /run?task=The+file+%60%2Fdata%2Fdates.txt%60+contains+a+list+of+dates%2C+one+per+line.+Count+the+number+of+Wednesdays+in+the+list%2C+and+write+just+the+number+to+%60%2Fdata%2Fdates-wednesdays.txt%60 HTTP/1.1" 200 OK
INFO:     127.0.0.1:65298 - "GET /read?path=/data/dates-wednesdays.txt HTTP/1.1" 200 OK
INFO:     127.0.0.1:65312 - "POST /run?task=Sort+the+array+of+contacts+in+%60%2Fdata%2Fcontacts.json%60+by+%60last_name%60%2C+then+%60first_name%60%2C+and+write+the+result+to+%60%2Fdata%2Fcontacts-sorted.json%60 HTTP/1.1" 200 OK
INFO:     127.0.0.1:65350 - "GET /read?path=/data/contacts-sorted.json HTTP/1.1" 200 OK
INFO:     127.0.0.1:65361 - "POST /run?task=Write+the+first+line+of+the+10+most+recent+%60.log%60+file+in+%60%2Fdata%2Flogs%2F%60+to+%60%2Fdata%2Flogs-recent.txt%60%2C+most+recent+first HTTP/1.1" 200 OK
INFO:     127.0.0.1:65390 - "GET /read?path=/data/logs-recent.txt HTTP/1.1" 200 OK
INFO:     127.0.0.1:65402 - "POST /run?task=Find+all+Markdown+%28%60.md%60%29+files+in+%60%2Fdata%2Fdocs%2F%60.%0AFor+each+file%2C+extract+the+first+occurrance+of+each+H1+%28i.e.+a+line+starting+with+%60%23+%60%29.%0ACreate+an+index+file+%60%2Fdata%2Fdocs%2Findex.json%60+that+maps+each+filename+%28without+the+%60%2Fdata%2Fdocs%2F%60+prefix%29+to+its+title%0A%28e.g.+%60%7B%22README.md%22%3A+%22Home%22%2C+%22path%2Fto%2Flarge-language-models.md%22%3A+%22Large+Language+Models%22%2C+...%7D%60%29 HTTP/1.1" 200 OK
INFO:     127.0.0.1:65436 - "GET /read?path=/data/docs/index.json HTTP/1.1" 200 OK
INFO:     127.0.0.1:65452 - "POST /run?task=%60%2Fdata%2Fcredit_card.png%60+contains+a+credit+card+number.+Pass+the+image+to+an+LLM%2C+have+it+extract+the+card+number%2C+and+write+it+without+spaces+to+%60%2Fdata%2Fcredit-card.txt%60 HTTP/1.1" 500 Internal Server Error
INFO:     127.0.0.1:65482 - "GET /read?path=/data/credit-card.txt HTTP/1.1" 500 Internal Server Error
INFO:     127.0.0.1:65503 - "POST /run?task=The+SQLite+database+file+%60%2Fdata%2Fticket-sales.db%60+has+a+%60tickets%60+with+columns+%60type%60%2C+%60units%60%2C+and+%60price%60.+Each+row+is+a+customer+bid+for+a+concert+ticket.+What+is+the+total+sales+of+all+the+items+in+the+%22Gold%22+ticket+type%3F+Write+the+number+in+%60%2Fdata%2Fticket-sales-gold.txt%60 HTTP/1.1" 200 OK
INFO:     127.0.0.1:49154 - "GET /read?path=/data/ticket-sales-gold.txt HTTP/1.1" 200 OK
result after running evaluate.py:
Score: 0 / 10
why sir
@Jivraj
@Saransh_Saini
what is the problem here??
please do a live session of complete project process with one or two tasks if possible

[2025-01-31T09:04:35.954Z] Carlton D'Silva (@carlton: Regular)
Hi Guddu,
We are planning several project sessions in order to show the workflow of creating a successful project.
Although you are returning a 200 ok, the get request file must match the expectation. In other words after running the first task for example, has the new format.md been formatted correctly and matches the expected output.
In this case you would write out the the
expected
variable in the
evaluate.py
and see if
result
variable matches the
expected
. Then you can figure out what went wrong.
Kind regards

[2025-01-31T09:32:51.688Z] Guddu Kumar Mishra  (@22f3001315)
Ok sir
But please try to take those sessions sooner
Because it‚Äôs taking too much time for me to do any problem(plus two more courses and one oppe you know) .so I just want to build the project before deadline.

[2025-01-31T11:10:36.199Z] Andrew David (@23f1002382)
Please give the date, time and agenda also please.

[2025-01-31T11:38:24.014Z] Carlton D'Silva (@carlton: Regular)
Yes sir ,
As soon as we know we will send an announcement.
Kind regards.

[2025-02-01T06:48:06.736Z] Andrew David (@23f1002382)
the model keeps wrong answer, it says uvicorn for uv and has no info on how to run uv even after explicitly giving instructions(basically an older model) , basic ‚Äúls‚Äù command is also wrong, among other things. You can check your logs with respect to my api key.
Do you think we could access a better model?
Maybe Download Deepseek 70b or even 671b and create an api while y‚Äôall run the model locally, in the long it would be cheaper for the course?
because the model doesn‚Äôt know basic commands after telling how to do it.
So if the model gives us wrong commands 2/3 times then how would we even solve the question.
I spent a week on this just saying
@s.anand
@carlton
@Jivraj

[2025-02-01T07:03:38.242Z] Andrew David (@23f1002382)
sent pull request maybe accept it then please

[2025-02-01T07:50:52.938Z] Andrew David (@23f1002382)
can we have the code for this session please?
@Jivraj
@carlton

[2025-02-02T08:46:20.663Z] Andrew David (@23f1002382)
i need some help can you send me your repo?

[2025-02-02T10:36:40.360Z] Dewang Gandhi (@23f2004781)
For Project-1 to complete, it requires:
"You MUST complete ALL these 3 steps to get a score. Failure to do so will result in getting 0 in the project. If you do not do ALL these 3 steps before the deadline, there will be no appeal available.
‚Ä¢ Fill the form that is on the Project Page
But I did not get the form; where is it? While I checked inside the project pages also.

[2025-02-02T19:19:05.604Z] Vivek Rekha Ashoka (@23f3001745)
Hello, I recently started working on the project. I understood how to do all the phase A tasks on a high level but I‚Äôm struggling to start the implementation of the first task in phase A. I‚Äôm confused mainly about how the /data directory is supposed to be created, I don‚Äôt know how to generate the data and a little confused about the output formats. I would appreciate if I could get in contact with anyone who could guide me in the right direction.

[2025-02-03T06:42:50.121Z] Hriday Pradhan (@21f3002390)
Hello everyone,
@s.anand
@carlton
I had a few queries regarding the project;
I am preloading my docker image with uv and generating the /data files when the container is ran. For task A1, I am automating my server to remove the /data directory that‚Äôs already present and run datagen.py again. Is this fine?
For /read endpoint, is there a standard for parameters like ‚Äúpath=/data/format.md‚Äù or the parameter could be a plain english sentence like ‚Äúpath=show the data in format.md‚Äù?
Are we concerned about what‚Äôs shown on the console if I run a /run command as long as it gets the job done?
For tasks A1-10, are the file paths provided in the project doc standard or even they‚Äôre flexible? Ex. ‚ÄúCount the number of Wednesdays in file /data/format.md, and write just the number to /data/out.txt‚Äù

[2025-02-03T08:00:58.755Z] Andrew David (@23f1002382)
+1

[2025-02-03T08:54:03.151Z] 24DS1000121 ULAGAOOZHIAN (@24DS1000121_ULAGAOOZ)
Dear Sir,
Can we have a mentorship program for TDS for those who have no experience in programming like me ?
thanks & regards.
ULAGAOOZHIAN

[2025-02-03T13:02:45.150Z] Carlton D'Silva (@carlton: Regular)
Hi Dewang,
Screenshot 2025-02-03 at 6.27.39 pm 1
2268√ó1766 491 KB
Please
read
the Project page Deliverables carefully as well as the Evaluation Pre - Requisites.
Kind regards

[2025-02-04T09:04:40.260Z] Andrew David (@23f1002382)
github.com/ANdIeCOOl/TDS-Project1-Ollama_FastAPI-
README.md
main
# TDS-Project1-Ollama_FastAPI-
## Info
- Create codespaces on main or evalution script branch
Use history.txt to get sqlite to version 3.45.3 into bash session
   - 64  export PATH=/opt/conda/bin:$PATH
   - 65  export LD_LIBRARY_PATH=/opt/conda/lib:$LD_LIBRARY_PATH
   - 66  python3 -c "import sqlite3; print(sqlite3.sqlite_version)"

- cd to latest_ai_development and run cmd [ crewai run] which set up server
- Then in a separate bash terminal run "python evaluate.py"
- also make sure to enter openai or sanand api key in crew.py

# Simple history of commands
1. Terminal 1
    - 1  python3 -c "import sqlite3; print(sqlite3.sqlite_version)"
    - 2  export PATH=/opt/conda/bin:$PATH
    - 3  export LD_LIBRARY_PATH=/opt/conda/lib:$LD_LIBRARY_PATH
    - 4  python3 -c "import sqlite3; print(sqlite3.sqlite_version)"
    - 5  cd latest_ai_development/
    - 7  pip install crewai crewai-tools
This file has been truncated.
show original
My take on autonomous agents. Limited by model capabilities to some extent. Will use function calling hence forth but here is a quick look at using crewai for agent tasks.

[2025-02-04T09:55:02.489Z] Guddu Kumar Mishra  (@22f3001315)
Sir
@carlton
@Jivraj
just saying,
If possible Please do 40-50% of project in upcoming live sessions so that we all have atleast something to submit.

[2025-02-05T16:32:16.103Z] Arjun G (@Arjun7)
I am using ubuntu. How do I use python 3.13. It says my python version is 3.12 even after installing python 3.13
Someone please help

[2025-02-05T18:38:02.561Z] Shivaditya Bhattacharya (@22f3000819)
@s.anand
sir, I see that the project 1 timeline was changed from February 7 - 17, 2025 to January 17 - February 15 which undoubtedly is a good increase in duration. However, I have my GATE DA exam on Feb 15 and the exam center is unexpectedly far. So, I request you to consider pushing the deadline to at least Feb 16. If not, I‚Äôll still do my best.

[2025-02-06T07:04:26.179Z] Hriday Pradhan (@21f3002390)
Hello!
@carlton
@s.anand
Is the proxy server down right now?
I am getting this error when I am accessing the endpoint:
{‚Äòid‚Äô: ‚Äòchatcmpl-Axq55TzulOVjHYuXYIhkRQzCC3PNl‚Äô, ‚Äòobject‚Äô: ‚Äòchat.completion‚Äô, ‚Äòcreated‚Äô: 1738824915, ‚Äòmodel‚Äô: ‚Äògpt-4o-mini-2024-07-18‚Äô, ‚Äòchoices‚Äô: [{‚Äòindex‚Äô: 0, ‚Äòmessage‚Äô: {‚Äòrole‚Äô: ‚Äòassistant‚Äô, ‚Äòcontent‚Äô: ‚Ä¶, ‚ÄòcostError‚Äô: ‚Äòcrypto.createHash is not a function‚Äô}
Or, do I have to install crypto module?

[2025-02-06T07:29:30.529Z] Anand S (@s.anand: Course_faculty)
@21f3002390
- AI Proxy is working and you
did
get the result. You can ignore any
costError
. It won‚Äôt happen in the future anyway.
What‚Äôs happening?
I was trying to generate a unique hash for each request, as a precursor to caching requests. But I made a mistake in the code. Specifically,
crypto.createHash
is not supported in CloudFlare.
I fixed that
by removing this. I‚Äôll introduce caching later if required.

[2025-02-06T09:28:32.920Z] Sarang Tambe (@23f2005138)
For the question
#A8
on recognizing the credit card number in the image, Open AI doesn‚Äôt seem to be recognizing the number correctly and as a result the evaluation is failing. What should be the solution?
image
913√ó498 13.6 KB

[2025-02-06T12:31:43.426Z] DEEPANSHU (@23f2004097)
When will live sessions for demo project start? If started please provide link for that as I am unable to get what the project is about and what are the initial steps to start project.

[2025-02-06T20:18:10.571Z] Aishik Bandyopadhyay (@23f2005325)
Getting the following error :
127.0.0.1 - - [07/Feb/2025 01:44:54] "GET /run?task=generate%20data%20for%20ujanaishik109@gmail.com HTTP/1.1" 200 -
  File "/tmp/datagenyhqKlO.py", line 1
    404: Not Found
    ^^^
SyntaxError: illegal target for annotation
when executing the following code :
Main.py
@routes.route("/run", methods=["GET", "POST"])
def run():
    task = request.args.get("task")
    try:
        res = get_func_name(task)
        func_name = res["func_name"]
        args = res.get("arguments", [])
        print("ARGUMENTS : ", args)
        if args:
            generated_func = globals()[func_name](*args)
            print("GENERATED FUNC :",generated_func)
            res = f"{func_name} executed successfully"
        else:
            generated_func = globals()[func_name]()
            print(generated_func)
            res = f"{func_name} executed successfully"
    except Exception as e:
        res = None
        print("error : ", e)
    return jsonify(res)
Tasks.py
def generate_data_files(user_email: str):
    subprocess.Popen(
        [
            "uv",
            "run",
            "https://raw.githubusercontent.com/sanand0/tools-in-data-science-public/tds-2025-01/datagen.py",
            f"{user_email}",
            "--root",
            "../data",
        ]
    )
    print("data generated successfully")
Please Guide
@s.anand
@carlton
@Jivraj

[2025-02-07T07:29:18.667Z] Joel Jeffrey (@JoelJeffrey)
A query regarding the task description in the query given to LLM for phase A.
For task A3, we have been asked to count wednesdays and the python file corresponding to A3 does count for wednesday alone. However the example says the LLM might be asked to count Sundays or other days. Should we be modifying task A3 code? Or was that just an example and only Wednesdays would need to be counted?

[2025-02-07T10:11:59.243Z] Andrew David (@23f1002382)
@carlton
@Jivraj
Please respond .

[2025-02-07T13:37:29.745Z] Avnish Jajodia (@22f3001777)
When will the project session be held? If I have missed it, can I get the recording?
@carlton

[2025-02-07T14:15:14.659Z] Carlton D'Silva (@carlton: Regular)
Tuesday is when we are currently planning a project session.
Kind regards

[2025-02-07T14:21:00.051Z] Carlton D'Silva (@carlton: Regular)
Tasks in Phase A are defined but that does not mean it has to do one precise thing. If that was the case then there is no use for an LLM.
Your application should be able to take parse the input and be able to run commands that do similar things in parameterised fashion. It could be Wednesdays or Sundays or it might be in Arabic days or anything. So coding to precisely do something very specific is not the goal.
The program has to be intelligent to do a certain type or class of tasks.
We had a session introducing project. Week 3 session 1. But we will have a more hands on session on Tuesday.
Kind regards

[2025-02-07T15:47:26.981Z] Tushar Jalan  (@23f2003751)
the last date of project submission is gonne get extended?

[2025-02-07T16:03:54.000Z] Carlton D'Silva (@carlton: Regular)
Project 1 was released over a month ago. So there will be no extension for Project 1

[2025-02-07T16:06:52.107Z] VIKASH PRASAD (@21f3002277)
how to handle this error
image
1425√ó490 11.1 KB
@carlton
@s.anand

[2025-02-07T19:50:53.195Z] Guddu Kumar Mishra  (@22f3001315)
expected = sum(1 for date in dates if parse(date).weekday() == 2)
    if result.strip() != str(expected):
        return mismatch("/data/dates-wednesdays.txt", expected, result)
    return True```
/data/dates-wednesdays.txt
EXPECTED:
129
RESULT:
‚Äú129‚Äù
If it is expecting str then why throw error sir  ?
@carlton
@Jivraj
or just tell me how to pass count as an int here
with open(output_file, "w") as f:
        f.write(str(count))

[2025-02-08T08:33:27.497Z] Telvin Varghese (@22f2001640)
@s.anand
@carlton
@Jivraj
I am getting below error message from LLM end points
https://api.openai.com/v1/chat/completions
or
https://aiproxy.sanand.workers.dev/openai/v1/embeddings
, while running my project .
Kindly help me to resolve this issue.

[2025-02-08T10:13:42.037Z] Sarang Tambe (@23f2005138)
@carlton
Will there be evaluation script for tasks in group B also?
Some questions about ‚ÄòB‚Äô group tasks:
Q1: For the following tasks (B5, B7, B9, and B10) tasks, how will input files be provided? Will it be URL or will
datagen.py
also generate files for these?
Q2: For the above tasks as well as for B6 ( Extract data from (i.e. scrape) a website), how should output be returned?
Q3: In task B8, for transcribing audio file, which Python package is recommended or do we need to use OpenAI API?
B5. Run a SQL query on a SQLite or DuckDB database
B7. Compress or resize an image
B8. Transcribe audio from an MP3 file
B9. Convert Markdown to HTML
B10. Write an API endpoint that filters a CSV file and returns JSON data

[2025-02-08T10:14:39.105Z] Guddu Kumar Mishra  (@22f3001315)
its expecting to  match every single detail in that even " and ‚Äô .
in that case changing evaluate.py will result in zero or less marks.
llm will only handle  -calling function based on query and parameter   . What is it going to do about the logic of functions.
If i still focus on passing evaluate.py will it be any good sir
@carlton
@s.anand
üî¥ /data/contacts-sorted.json
‚ö†Ô∏è EXPECTED:
[{'first_name': 'Kevin', 'last_name': 'Aguirre', 'email': 'ricardocarlson@example.net'}, {'first_name': 'Andrew', 'last_name': 'Anderson', 'email': 'kimberly08@example.com'}, {'first_name': 'Robert', 'last_name': 'Arnold', 'email': 'hunterpamela@example.com'}, {'first_name': 'Isaac', 'last_name': 'Barker', 'email': 'jessicabriggs@example.net'}, {'first_name':
My output was in good looking structured form but I had to make it look like this just to pass the evaluation.
‚ö†Ô∏è RESULT:
[{"first_name": "Kevin", "last_name": "Aguirre", "email": "ricardocarlson@example.net"}, {"first_name": "Andrew", "last_name": "Anderson", "email": "kimberly08@example.com"}, {"first_name": "Robert", "last_name": "Arnold", "email": "hunterpamela@example.com"}, {"first_name": "Isaac", "last_name": "Barker", "email": "jessicabriggs@example.net"}, {"first_name": "Anthony", "last_name": "Barrett", "email": "kevinknox@example.org"}, {"first_name": "Monique", "last_name": "Bass", "email": "lindsaymcgrath@example.net"}, {"first_name": "Michael", "last_name": "Berry", "email": "an

[2025-02-09T06:06:02.825Z] Tushar Jalan  (@23f2003751)
Sorry, sir, not trying to be rude, but there isn‚Äôt a single full-fledged project session. It‚Äôs a bit difficult to dive into the project without guidance on how to do it. It would be nice to have a full project session where we can start a project from the beginning and follow it to completion.
@carlton
@Jivraj
@s.anand

[2025-02-09T06:33:13.210Z] Yogesh (@Yogesh1)
Yes. I am very worried about this project. I have been trying to do this. But have gotten nowhere until now.

[2025-02-09T08:10:55.954Z] Sujay D (@22f2001590)
@carlton
sir I request you demonstrate atleast few tasks, I spent last 2 days trying to implement but din‚Äôt reach anywhere, its really demotivating sir.

[2025-02-09T09:38:41.944Z] Akash Kumar (@akashkunwar)
Can you please demonstrate it by just doing One task or provide sample example code of 1 similar task in the way you explained here. It will be very helpful right now it is very confusing.

[2025-02-09T10:30:37.275Z] Carlton D'Silva (@carlton: Regular)
We will be doing project session on
Tuesday 9 Feb
[correction] Tuesday 11th of Feb (thanks
@23f1002382
@23f2000237
) . Project 1 uses the things you learnt in week 1-3. But mostly week 2 & 3.
We dont do it in the beginning, (but introduced it 2 weeks ago in a live session), to give students chance to practise the new learnings from week 2 & 3.
The plan has always been to demonstrate a few tasks and have you try doing the rest.
Kind regards

[2025-02-09T10:41:46.503Z] Telvin Varghese (@22f2001640)
@s.anand
@carlton
@Jivraj
I am getting below error message from LLM end points
https://api.openai.com/v1/chat/completions
or
https://aiproxy.sanand.workers.dev/openai/v1/embeddings
, while running my project .
Kindly help me to resolve this issue. I am unable to proceed with my project.

[2025-02-09T11:07:42.376Z] Sakthivel S (@23f2000237)
Today‚Äôs 9th Feb and it‚Äôs a Sunday.

[2025-02-09T15:27:58.255Z] Aindree Chatterjee (@23f2000983)
s.anand:
Update: 27 Feb 2025
:
Sir, does this mean 27th is submission deadline?

[2025-02-10T02:01:43.833Z] Carlton D'Silva (@carlton: Regular)
Hi Aindree,
No its a typo (and will be corrected soon). In the context of what was written it clearly means it was
updated
on 27th January. The update being that the evaluation.py file was provided so that you could test your code against it.
Thanks for bringing it to our attention.
Kind regards

[2025-02-10T05:47:01.257Z] Joel Jeffrey (@JoelJeffrey)
Hi
This would be only for a selected few questions right because say for the credit card question, where the LLM is involved, to get the card number itself, we have to give a fine-tuned and strong query.

[2025-02-10T09:14:25.875Z] Sakthivel S (@23f2000237)
Try using the eval() function, that seemed to work for me

[2025-02-10T10:38:11.034Z] Sarang Tambe (@23f2005138)
@carlton
@s.anand
@Jivraj
Sir, could you please share some guidance on the above?

[2025-02-10T11:26:25.879Z] Srividhya (@23ds1000022)
@jivraj
,
@carlton
I have done the a1 to a10 task and tried querying through localhost and its working fine basically all these ten steps but dont know whether its enough or not. also steps in phase B i am confused that should we create separate endpoints for these tasks or should it be with same /run endpoint and query. then will the input be random by any user. what about the output . where should it be given. phase b needs more explanation.

[2025-02-10T11:35:58.014Z] B Varun karthik (@23f2001305)
At what time will the session be happening tomorrow sir can you please give the details?

[2025-02-10T14:27:20.468Z] Aakanksha Panjwani (@apanjwani)
Hi
@carlton
@Jivraj
Facing some issues in running my project. Taking an example of the Phase A - A3 task.
I am able to read my files through the GET/read/data/dates.txt query.
I am also able to use the count_wednesdays function through the POST/run task/count_wednesdays.
But when I am entering a query such as ‚Äúcount_wednesdays in data/dates.txt‚Äù I am unable to get a response.
image
618√ó246 6.28 KB
Please advice. Thank you.

[2025-02-10T17:09:42.837Z] Sathyavathi S  (@23f1000299)
image
1215√ó112 19 KB
On task A8, credit-card.png is given, but it is in credit_card.
it makes the errors. I checked that 2 to 3 tasks depend on these, and we create the ouput file with ‚Äò-‚Äô this only. please clarify that output and input files name ‚Äò-‚Äô or ‚Äò_‚Äô
@carlton
@Jivraj

[2025-02-10T17:13:41.736Z] Sathyavathi S  (@23f1000299)
On tomorrow live sessions, kindly explain how to use docker, evaluations, github, what generally we have to do submit, please get some tuturials for us to submit those answers. Thankyou Sir
@Jivraj
@carlton

[2025-02-10T18:51:11.574Z] Andrew David (@23f1002382)
(post deleted by author)

[2025-02-10T21:15:48.888Z] Andrew David (@23f1002382)
(post deleted by author)

[2025-02-10T21:25:21.100Z] Andrew David (@23f1002382)
(post deleted by author)

[2025-02-10T21:59:07.953Z] Andrew David (@23f1002382)
Score: 9 / 10
Almost done with A tasks. Please use this for local llm to verify output
Also Ollama doesn‚Äôt require Schemas
CHECK OUT THE REPO AND ANY INPUTS ARE WELCOME
Link to ReadMe and also repo

[2025-02-11T03:51:52.920Z] Carlton D'Silva (@carlton: Regular)
Hi Andrew,
You have done a great job with the Phase A tasks. Very methodical, well structured, logical and even incorporates (unnecessarily) two different ways of evaluating its performance via local llm or the project proxy.
I just want to forewarn you (and others who are tempted to just blindly copy and paste) that evaluate.py is not meant to give you an exact expectation of what prompts will be sent to your application.
In other words getting 10/10 in
evaluate.py
does NOT guarantee 10/10 or even 5/10  or 1/10 in the real evaluation.
So do not write your code so rigidly that it will only work in the very strict interpretation of
evaluate.py
. It has always been meant to give you a feel for what to aim for. Your code should be flexible enough to deal with the general
idea
of the task.
That said,
evaluate.py
is a good way to know what to expect. Some of Phase A tasks although given a detailed specification in the project description, will still be given challenging prompts (i.e. hard difficulty, and requires some clever self correcting mechanism). Some of the tasks will be given straight forward prompt (i.e. easy for your application).  Some of the tasks will be given with some level of parameterisation that deviates from the strict interpretation (i.e. medium difficulty).
Hope that helps with how you deal with Phase B tasks (and making your Phase A more robust to a stronger evaluation.)
A word of caution:
(i.e. this is just some advice, not a set in stone recommendation)
Your requirements.txt is massive. If your code does not execute a task (
possibly your first task
) within 20 seconds (on our server) then it will fail that task. You might want to consider a dynamic, flexible way of installing only required libraries when necessary and keeping the image footprint small and efficient, as we will necessarily have limits on how big we allow images to grow since we have to run and evaluate hundreds of images automatically.
Kind regards

[2025-02-11T07:01:21.237Z] Telvin Varghese (@22f2001640)
Respected
@s.anand
@carlton
and
@Jivraj
,
Is anyone actively monitoring the Discourse page? I have been raising this issue for the past few days, but there has been no response. Does this mean the TAs are not addressing students‚Äô concerns?
I am encountering the following error while running my project with these LLM endpoints:
https://api.openai.com/v1/chat/completions
https://aiproxy.sanand.workers.dev/openai/v1/embeddings
This issue is blocking my progress, and I urgently need assistance to resolve it. Kindly provide guidance or suggest a solution at the earliest.
Looking forward to your response.
Thanks,
Telvin Varghese

[2025-02-11T07:17:01.378Z] Kratika (@Kratikajain)
Hi,
I am not able to understand how to do the Project 1. The date is also very near.
The problem I am facing is, When I did the Modules the page was different, but now in the Project 1 I am not getting any section to submit the project.
Please let me know where are the questions and how tot submit that.
The deadline is near.

[2025-02-11T07:18:03.044Z] Andrew David (@23f1002382)
carlton:
o do not write your code so rigidly that it will only work in the very strict interpretation of
evaluate.py
. It has always been meant to give you a feel for what to aim for. Your code should be flexible enough to deal with the general
idea
of the task.
This where I need help, i tried doing with agentic framework but i failed with the model in llm proxy, which was highly suspect because, that model should have known what the uv framework but it seemed to me to be outdated. Hence executing code Interpreter tools failed as the model gave outdated code. I have raised this issue before
Hence i moved to function calling, using local llms as cost-effective solution and it was quite robust.
I just need to understand how the function should be general, maybe 2-3 tasks you could provide the general description along with all the ways one would query the agent llm(ie our project). This general function is what i need help with. Please kindly do the needful.

[2025-02-11T07:54:33.324Z] Pradeep Mondal (@21f2000709)
carlton:
keeping the image footprint small and efficient, as we will necessarily have limits on how big we allow images to grow since we have to run and evaluate hundreds of images automatically.
Any tentative size cutoff for the docker image?

[2025-02-11T10:14:00.116Z] Carlton D'Silva (@carlton: Regular)
Hi Telvin
You have run out of tokens. Thats what the message is saying. You ran out 3 days ago. It was clearly mentioned that the limit is $1. You have exceeded $2.
Screenshot 2025-02-11 at 3.36.50 pm
2078√ó1276 305 KB
In our current internal build of project 1, we have yet to exceed $0.50
As to whether it can be renewed is something we have still not yet decided, because the question you have raised equally would apply to everyone. Raising it for you means raising it for everyone. $1 for everyone equals raising it by $1600+
(i.e Rs 1.39 Lakhs)
for us!
The budget question then involves more than one person. It also involves the BS Team Operations and not just the TDS team and therefore instead of responding with a response that is not useful, we typically try to solve the problem first and then respond.
In short we are working on it. But as we have mentioned repeatedly in our sessions, use APIs efficiently, thats part of the skill. As soon as we have a resolution we will inform everyone via an announcement and an email.
Kind regards

[2025-02-11T10:34:24.293Z] Telvin Varghese (@22f2001640)
Thanks for your response,
@Carlton
. It seems I won‚Äôt be able to proceed with the project until this issue is resolved. Also, I haven‚Äôt used LLM so much until February 7th to cost $2.

[2025-02-11T10:43:05.396Z] Carlton D'Silva (@carlton: Regular)
Every request you send, gives you a response back with exactly how much that request cost. So you can track your usage.

[2025-02-11T11:08:19.962Z] Telvin Varghese (@22f2001640)
I‚Äôm aware of that. I‚Äôve mostly noticed a cost of $0.0003 per request, so I haven‚Äôt been tracking my total monthly expenses. Moving forward, I‚Äôll keep a record of the cost for each request. Also, do strong prompts impact the overall cost?

[2025-02-11T11:32:35.401Z] Pradeep Mondal (@21f2000709)
@carlton
Is the project session happening today? I don‚Äôt have the link. Can you please send it if it‚Äôs happening?

[2025-02-11T11:34:29.425Z] Aakanksha Panjwani (@apanjwani)
Hi, where is the link for todays Project 1 demo session?
@carlton
@Jivraj

[2025-02-11T11:37:00.655Z] B R GIRI SUBRAHMANYA (@23f2000573)
https://meet.google.com/odh-ycbm-ahj?authuser=0

[2025-02-11T11:46:25.605Z] Prakhar Yadav (@22f3002786)
request
http://localhost:8000/run?task=Extract the sender's email from /data/email.txt and write to /data/email-sender.txt](http://localhost:8000/run?task=Extract the sender's email from /data/email.txt and write to /data/email-sender.txt)
output
{    "detail": "Error code: 401 - {'error': {'message': 'Your authentication token is not from a valid issuer.', 'type': 'invalid\_request\_error', 'param': None, 'code': 'invalid\_issuer'}}"}
@carlton
sir I am getting this issue while running my script. Please help!

[2025-02-11T12:19:31.097Z] Aindree Chatterjee (@23f2000983)
I‚Äôm getting an error in task a2, def do_a2():
‚Äú‚Äù‚ÄúFormat markdown using prettier‚Äù‚Äú‚Äù
format_md_path = DATA_ROOT / ‚Äúformat.md‚Äù
subprocess.Popen([‚Äúprettier‚Äù, str(format_md_path), ‚Äú‚Äìwrite‚Äù, ‚Äú‚Äìparser‚Äù, ‚Äúmarkdown‚Äù])
print(‚Äúdata formatted successfully‚Äù)
any idea how to fix this? Also in A8, a 5 and a 3 is getting interchanged. Can someone help why that is hapening, I changed the prompt to include caution about not switching 3 and 5 as well, that didn‚Äôt help either

[2025-02-11T12:35:58.890Z] Maheshwar Ture (@22f2000113)
what is  the session time?

[2025-02-11T12:45:30.356Z] ABHROJYOTI GHOSH (@23f1002104)
Screenshot 2025-02-11 181453
1459√ó207 15.3 KB
Could you kindly help me with this

[2025-02-11T15:23:49.900Z] Veer Shah (@23f1001524)
in checking for the task of json my code is outputting json with double quotes (valid json) and evaluate.py has exact same json but with single quotes , what should I do?

[2025-02-11T15:26:23.894Z] Andrew David (@23f1002382)
check out my repo and download the datagen and evaluate file for testing

[2025-02-11T15:27:01.472Z] Andrew David (@23f1002382)
it should work, use fastapi text response when /read api

[2025-02-11T16:22:42.078Z] Maheshwar Ture (@22f2000113)
Has anyone used a local LLM for testing? If so, could you please share the request URL and the request body format? I attempted to use a local LLM, but I was unable to succeed

[2025-02-11T17:07:07.884Z] Andrew David (@23f1002382)
use ollama it is openai api compatible, supports function calling without json schema for tool usage. Check it out

[2025-02-11T18:04:05.195Z] Andrew David (@23f1002382)
NEED HELP. CAN SOMEONE CONTACT OLLAMA AND ASK THEM TO CHECK THEIR CODE ITS HAS SOME SILLY MISTAKES IN CODE EXAMPLES. I DONT KNOW HOW TO DO IT.
LINK TO PAGE WITH CODE EXAMPLE
Screenshot 2025-02-11 232608
919√ó714 22.4 KB
correct code in step 2 collection query step
response = ollama.embed(
  model="nomic-embed-text:latest",
  input=task
)
results = collection.query(
  query_embeddings=response["embeddings"], #here embeddings and also not list of list as response embeddings already gives correct format
  n_results=1
)
data = results['documents'][0][0]
@s.anand
@Jivraj
@carlton

[2025-02-11T19:51:59.902Z] Aishik Bandyopadhyay (@23f2005325)
@s.anand
@carlton
@Jivraj
While implementing the Phase B tasks, can I take the data (csv file, git repo, audio, sqlite/duckdb database, website, image and markdown file) of my choice and perform any operation on them as long as they meet the critetia mentioned in the Phase B task list? Please guide.

[2025-02-11T20:29:08.345Z] Aishik Bandyopadhyay (@23f2005325)
@s.anand
@carlton
@Jivraj
In the Task B5, where we have to run an SQL query on a sqlite or duckdb database, should I create a database on my own and then take the query to be ran on it as an argument? Or should I take the query as an argument and run it on the ticker_sales.db in ./data folder? Please guide

[2025-02-11T21:56:07.834Z] Mayank Mehta (@23f2001978)
same issue on my side as well

[2025-02-11T22:23:51.126Z] Mayank Mehta (@23f2001978)
on using the AIPROXY_TOKEN from here
https://aiproxy.sanand.workers.dev/
getting this error :
Error: Your authentication token is not from a valid issuer.
@carlton
@Jivraj
please help!

[2025-02-12T00:20:25.124Z] Yogesh (@Yogesh1)
@carlton
@Jivraj
Can the link to the live session (for project) be provided?

[2025-02-12T00:57:04.758Z] Ansh bansal (@23f2004752)
As in the previous session for task a1 we use llm just to get the url and email , so after retriving the both arguments can i use them in a function and got the work given in work done in function.
Also, am i correct that we use llm only to retrive url or location ??
@carlton
@Jivraj

[2025-02-12T01:27:51.130Z] Ansh bansal (@23f2004752)
Anyone whom have done have done any one task of phase a and one task of phase b, please help‚Ä¶

[2025-02-12T01:47:54.869Z] Ansh bansal (@23f2004752)
Can you do one task from each phase in today‚Äôs session. Please
@carlton
@Jivraj

[2025-02-12T02:13:05.286Z] Maheshwar Ture (@22f2000113)
thanks for the reply I will check

[2025-02-12T03:29:46.481Z] Shreyan Chaubey (@thinkmachine)
TDS project
Tedious project

[2025-02-12T05:12:14.328Z] Anvitha (@AnvithaV)
can anyone share the link of yesterdays live session if there in youtube

[2025-02-12T05:16:06.451Z] NK (@23f2004042)
Its updated in the TDS live sessions playlist

[2025-02-12T06:27:17.724Z] Adithya S (@Adithya)
For task A2
:
A2
. Format the contents of
/data/format.md
using
prettier@3.4.2
, updating the file in-place
I am getting the following error:
üî¥ A2 failed: Command '['npx', 'prettier@3.4.2', '--stdin-filepath', '/data/format.md']' returned non-zero exit status 1.
However, running a
POST request
to
https://localhost:8000/run?task=Format+/data/format.md+with+prettier+3.4.2
gives successful output.
{"success":true,"message":"Formatted and verified successfully!"}%
Here is my code snippet:
def format_file(filepath):
    while True:  # Loop until formatting and verification pass
        try:
            result = subprocess.run(
                ["npx", "prettier@3.4.2", "--write", filepath],
                check=False,  # Don't raise exception automatically
                capture_output=True,
                text=True
            )

            if result.returncode != 0:
                return {"success": False, "message": f"Prettier write failed: {result.stderr}"}

            if verify_prettier_formatting(filepath):
                return {"success": True, "message": "Formatted and verified successfully!"}
            else:
                logging.info("Verification failed. Retrying formatting...") #Log the retry
                # If verification fails, the loop continues and prettier --write is executed again.

        except Exception as e:
            return {"success": False, "message": str(e)}

def verify_prettier_formatting(filepath):
    try:
        subprocess.run(["npx", "prettier@3.4.2", "--check", filepath], check=True, capture_output=True, text=True) #Capture output
        return True  # File is formatted correctly
    except subprocess.CalledProcessError as e:
        logging.error(f"Prettier check failed: {e.stderr}") # Log the error from prettier check
        return False  # File is not formatted correctly
What am I missing here?

[2025-02-12T07:05:33.610Z] Durga Prasad (@22f3001307)
I am getting the same error. Did you find any solution?

[2025-02-12T07:08:29.395Z] Pradeep Mondal (@21f2000709)
Has anyone succeeded in the extraction of credit cards details task? The LLM seems to consider it as illegal task and if I use pytessaract the docker image size will become really large. What to do in this case?
@carlton
@Jivraj

[2025-02-12T07:12:02.257Z] Durga Prasad (@22f3001307)
Hi
@carlton
@Jivraj
,
I followed what you taught in Feb 11 session and tried implementing task A1. My understanding is once i run the subprocess, datagen.py file should be run and /data folder should be created in the project folder. But it is not happening to me. I am getting the following error
Traceback (most recent call last):
  File "/var/folders/rj/z_3b8hl51558519w90k5hp600000gn/T/datagen4COEF3.py", line 284, in <module>
    os.makedirs(config["root"], exist_ok=True)
    ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen os>", line 227, in makedirs
OSError: [Errno 30] Read-only file system: '/data'
If i can‚Äôt automate this process, i don‚Äôt see the point writing code for other tasks. Can anyone help me solving this error?

[2025-02-12T07:22:31.307Z] Andrew David (@23f1002382)
shell = true in evaluate.py, remove it meaning comment it out, task a2 thats causing the error

[2025-02-12T07:25:19.252Z] Andrew David (@23f1002382)
the admin banned me from using laughing emoji
@jkmadathil

[2025-02-12T08:44:41.379Z] Joel Jeffrey (@JoelJeffrey)
For task A6,
HTTP Request: GET
http://localhost:8000/read?path=/data/docs/index.json
‚ÄúHTTP/1.1 200 OK‚Äù
‚ö†Ô∏è EXPECTED:
{'by/perhaps.md': 'Base relationship identify mean happy Mrs whatever.', 'by/they.md': 'Unit its thank half morning determine development place.', 'by/culture.md': 'Prevent north only miss cold.', 'by/region.md': 'Claim card from receive alone you capital book.', 'by/draw.md': 'Shoulder class six finally build call note bring.', 'by/family.md': 'Debate at office traditional stop great.', 'by/defense.md': 'Marriage million crime organization give over.', 'by/treat.md': 'Themselves young course feel.', 'by/little.md': 'Break somebody whose set else history.', 'by/color.md': 'Soon address everyone computer against.', 'daughter/seek.md': 'Throughout growth history save.', 'daughter/bar.md': 'Among ago cover good.', 'daughter/business.md': 'Alone idea security behavior.', 'daughter/poor.md': 'Possible leave him up bag will.', 'daughter/story.md': 'Anything song key first.', 'daughter/product.md': 'Social stand administration challenge personal.', 'daughter/check.md': 'Young prevent play follow.', 'daughter/put.md': 'Doctor eat should add pull customer might.', 'daughter/whose.md': 'Program writer interesting prepare authority skill.', 'daughter/professor.md': 'Effect ahead eye serve single.', 'drop/manage.md': 'Allow expect heavy quality.', 'drop/mission.md': 'Ready kind only meeting.', 'drop/arrive.md': 'Education science car common husband economy.', 'drop/main.md': 'Education left somebody.', 'drop/of.md': 'Write room national change.', 'drop/through.md': 'Adult large protect agency whom magazine behind.', 'drop/former.md': 'Brother college detail.', 'drop/add.md': 'Fish work to individual.', 'drop/from.md': 'Though important executive Democrat smile.', 'drop/else.md': 'Fly candidate may so college.', 'civil/door.md': 'Can choice spring alone ball spend half.', 'civil/ready.md': 'Central about ready information.', 'civil/deep.md': 'Thought charge team type tonight maybe.', 'civil/hand.md': 'Discussion itself in far station head phone.', 'civil/question.md': 'Family evening its degree.', 'civil/argue.md': 'Line culture seven six.', 'civil/gas.md': 'Talk why around necessary.', 'civil/life.md': 'Concern decide better whom.', 'civil/culture.md': 'National could exactly well discuss candidate especially sport.', 'civil/central.md': 'Believe region their our whatever.', 'standard/easy.md': 'Myself must detail win.', 'standard/sound.md': 'Night national film next.', 'standard/five.md': 'Lay would green generation season.', 'standard/audience.md': 'Finally remain actually toward purpose bad.', 'standard/hear.md': 'Poor budget agent artist.', 'standard/with.md': 'Former writer cause pattern school answer.', 'standard/standard.md': 'Do number shoulder animal yourself.', 'standard/late.md': 'Scientist people may story.', 'standard/level.md': 'Work around ask to.', 'standard/analysis.md': 'While natural from staff option artist can.', 'few/choose.md': 'Official travel although price message example indeed.', 'few/sometimes.md': 'Big order defense field represent.', 'few/weight.md': 'Man mission American.', 'few/expect.md': 'Bill well artist night rule bag.', 'few/my.md': 'Open line address contain whole impact into front.', 'few/store.md': 'Hand thought example exist record practice though.', 'few/prove.md': 'Opportunity foot agent herself save other become study.', 'few/southern.md': 'Meet prove admit.', 'few/theory.md': 'Security effort protect future task long close.', 'few/information.md': 'Really morning yeah.', 'community/up.md': 'Final all commercial anything term begin cultural.', 'community/save.md': 'Thought hear home set employee early purpose.', 'community/stay.md': 'Military teach subject cold affect shake.', 'community/book.md': 'Mr oil difficult dog.', 'community/woman.md': 'Big might attorney organization less drop.', 'community/cold.md': 'Election buy member alone school audience.', 'community/else.md': 'Actually service thank state.', 'community/left.md': 'Picture let tell never.', 'community/soldier.md': 'It lawyer cover job.', 'Congress/let.md': 'Bank ability actually outside.', 'Congress/whatever.md': 'Today catch analysis.', 'Congress/remain.md': 'But natural film discussion among whole.', 'Congress/democratic.md': 'Research knowledge owner Mr whole money cup.', 'Congress/which.md': 'Partner score fast herself character minute.', 'Congress/accept.md': 'Expert plant institution relate old research position I.', 'Congress/produce.md': 'Land do heart watch which many.', 'Congress/task.md': 'Book help represent now.', 'Congress/fish.md': 'Herself share yourself movie behind whom check.', 'Congress/remember.md': 'Purpose good policy line trade.', 'ten/rock.md': 'Method wall when book agency.', 'ten/sea.md': 'Trial heart office dark fine everything suggest.', 'ten/simply.md': 'Congress way enjoy hand first.', 'ten/someone.md': 'Themselves hair together maybe yes never.', 'ten/nature.md': 'Eight own hot first success.', 'ten/page.md': 'Edge to window size stand sea.', 'ten/pull.md': 'Factor list try able pattern.', 'ten/international.md': 'Food style wait tend improve.', 'ten/time.md': 'Note center brother process big.', 'ten/serve.md': 'Want exist bank book.', 'live/leader.md': 'Hold garden imagine style water ready several.', 'live/white.md': 'Whatever significant capital air about.', 'live/democratic.md': 'Reach rate none thank key after.', 'live/traditional.md': 'If participant be year how may.', 'live/focus.md': 'Western win tree kid radio however value.', 'live/own.md': 'Say small finish sing raise.', 'live/so.md': 'Type look identify spend drop sit skin heart.', 'live/possible.md': 'Window help reflect when consider science.', 'live/discuss.md': 'Hit result find miss culture heart clear task.'}
‚ö†Ô∏è RESULT:
{'suddenly/mouth.md': 'Outside food subject positive human.', 'suddenly/add.md': 'Window word during born do finally.', 'suddenly/free.md': 'Them ball significant different which traditional.', 'suddenly/management.md': 'Man fire long hour modern.', 'suddenly/leave.md': 'Season people Democrat hand among too.', 'suddenly/low.md': 'Front actually decision security fast song believe leg.', 'suddenly/why.md': 'Account listen such day method sing.', 'suddenly/miss.md': 'Rather although team thank.', 'suddenly/base.md': 'Total low room structure staff.', 'suddenly/strategy.md': 'Never understand less operation onto still trade environment.', 'ground/girl.md': 'Civil speech back sell.', 'ground/game.md': 'Fill whose card or daughter old meet.', 'ground/term.md': 'Pick return put set.', 'ground/every.md': 'Free service trouble effort somebody blood modern.', 'ground/along.md': 'Important plant increase door much.', 'ground/call.md': 'Article agent three scientist.', 'ground/do.md': 'Memory food strategy meeting.', 'ground/end.md': 'Large player discussion similar prove part.', 'ground/full.md': 'Actually start commercial.', 'ground/ever.md': 'Human example gun now my just Republican.', 'way/not.md': 'Decision together land chair.', 'way/morning.md': 'Information later service raise after trial base.', 'way/responsibility.md': 'Our child why environment care goal.', 'way/increase.md': 'Return say response political.', 'way/relationship.md': 'General view thing poor machine market peace.', 'way/soldier.md': 'Produce table should will school produce player wall.', 'way/act.md': 'Smile guess simple read style its international.', 'way/sound.md': 'Conference first finally recognize as.', 'way/reach.md': 'Exactly size discuss management miss article.', 'way/hotel.md': 'From become actually.', 'hit/run.md': 'Stock several region put thought decade evening.', 'hit/free.md': 'Crime usually produce.', 'hit/foot.md': 'Ball specific trip state.', 'hit/ball.md': 'Condition color focus traditional.', 'hit/song.md': 'Section environmental final light word in yes operation.', 'hit/since.md': 'Shoulder wrong matter seek cultural vote themselves.', 'hit/safe.md': 'Hear try spend item can along light.', 'hit/much.md': 'Guess great dream through concern feel.', 'hit/prove.md': 'Her base cup forward.', 'hit/stop.md': 'Nation this avoid herself deal place memory.', 'few/sometimes.md': 'Big order defense field represent.', 'few/southern.md': 'Meet prove admit.', 'few/choose.md': 'Official travel although price message example indeed.', 'few/store.md': 'Hand thought example exist record practice though.', 'few/weight.md': 'Man mission American.', 'few/information.md': 'Really morning yeah.', 'few/prove.md': 'Opportunity foot agent herself save other become study.', 'few/expect.md': 'Bill well artist night rule bag.', 'few/theory.md': 'Security effort protect future task long close.', 'few/my.md': 'Open line address contain whole impact into front.', 'resource/rest.md': 'Ok tough talk.', 'resource/move.md': 'Law write democratic drug itself house accept through.', 'resource/particularly.md': 'Affect woman nice.', 'resource/entire.md': 'Focus to once sea friend group.', 'resource/painting.md': 'Customer environment none trade.', 'resource/structure.md': 'Stuff return protect our bit reality.', 'resource/until.md': 'Growth industry region receive.', 'resource/significant.md': 'Long million fall throughout government tend.', 'resource/hospital.md': 'Quality certain fight want much body between.', 'resource/marriage.md': 'Foot specific mission.', 'for/hope.md': 'Whatever report wife fly close lot student.', 'for/poor.md': 'Explain claim police eye paper much when.', 'for/assume.md': 'Control yeah effect local economy worry.', 'for/couple.md': 'Floor both take indeed audience.', 'for/money.md': 'Join live next care material.', 'for/never.md': 'Me natural full.', 'for/situation.md': 'Show book instead hope lawyer.', 'for/north.md': 'Card level kind send loss growth.', 'for/hit.md': 'Minute wish above pass just later watch.', 'for/perhaps.md': 'Every professor sport unit rock bed.', 'project/individual.md': 'Tough safe machine small outside mention could must.', 'project/change.md': 'Century drug value.', 'project/home.md': 'Big decade edge feeling surface matter force student.', 'project/want.md': 'Region catch nation civil one Mr specific.', 'project/something.md': 'Major control three.', 'project/reality.md': 'Mouth including fine.', 'project/my.md': 'Fire point or success marriage write example.', 'project/issue.md': 'Former true career similar use visit machine.', 'project/surface.md': 'Cold reduce task life American act stage.', 'project/drug.md': 'Reason still field animal.', 'effort/morning.md': 'Policy quickly get capital smile.', 'effort/he.md': 'Thought view product interview explain.', 'effort/house.md': 'High hear thought according.', 'effort/church.md': 'Culture ask change focus.', 'effort/effect.md': 'Before suddenly who student could boy serve.', 'effort/price.md': 'Shoulder financial public reason home explain safe.', 'effort/company.md': 'Exactly treatment concern fly factor care drive.', 'effort/international.md': 'Rich take hear open.', 'effort/federal.md': 'Difference rate character by his blood this.', 'effort/computer.md': 'Lay financial article exactly.', 'by/region.md': 'Claim card from receive alone you capital book.', 'by/they.md': 'Unit its thank half morning determine development place.', 'by/defense.md': 'Marriage million crime organization give over.', 'by/draw.md': 'Shoulder class six finally build call note bring.', 'by/culture.md': 'Prevent north only miss cold.', 'by/family.md': 'Debate at office traditional stop great.', 'by/treat.md': 'Themselves young course feel.', 'by/little.md': 'Break somebody whose set else history.', 'by/color.md': 'Soon address everyone computer against.', 'by/perhaps.md': 'Base relationship identify mean happy Mrs whatever.', 'bill/appear.md': 'Whole senior next stop yard national section.', 'bill/room.md': 'Able improve anything teacher media writer employee.', 'bill/citizen.md': 'Safe anyone major reach mother ground over leave.', 'bill/for.md': 'A several low detail.', 'bill/role.md': 'More light anything study hand power.', 'bill/set.md': 'Necessary century drive attack capital.', 'bill/generation.md': 'Stay could quality shake.', 'bill/drive.md': 'Situation we his.', 'bill/computer.md': 'Culture ahead change perhaps however audience.', 'bill/gas.md': 'Reveal attack and church.', 'color/sell.md': 'Mention although while boy turn.', 'color/throughout.md': 'She actually gun start.', 'color/management.md': 'Short serve beat increase than visit.', 'color/smile.md': 'His season employee husband.', 'color/wear.md': 'Share green measure sometimes.', 'color/official.md': 'Suddenly seat tend thus office action move.', 'color/admit.md': 'Each important clear.', 'color/treat.md': 'Tv outside attorney rich say same environment.', 'color/turn.md': 'Try drop old along.', 'color/sit.md': 'Including turn seem none computer.', 'build/together.md': 'Finally point only police artist.', 'build/rest.md': 'Author run let.', 'build/wall.md': 'Administration a week form side feeling.', 'build/none.md': 'Commercial stop page else.', 'build/explain.md': 'Join tend idea stand not option woman.', 'build/decision.md': 'Poor fund interesting bring.', 'build/beyond.md': 'Artist billion begin record anything none management practice.', 'build/dream.md': 'Decision suddenly prevent speak old power herself.', 'build/each.md': 'Able out key.', 'build/street.md': 'Knowledge specific technology before leave.', 'wrong/market.md': 'Realize key point whatever Democrat or say.', 'wrong/free.md': 'Deal even from mouth source.', 'wrong/sure.md': 'Similar him believe actually.', 'wrong/apply.md': 'Everybody office list service stock significant.', 'wrong/share.md': 'Painting every apply.', 'wrong/standard.md': 'Already place fund really.', 'wrong/might.md': 'Possible during claim view.', 'wrong/nation.md': 'About prove cold question race.', 'wrong/be.md': 'Land debate natural American.', 'wrong/suggest.md': 'Could environmental rather can us night.', 'Congress/remember.md': 'Purpose good policy line trade.', 'Congress/let.md': 'Bank ability actually outside.', 'Congress/produce.md': 'Land do heart watch which many.', 'Congress/task.md': 'Book help represent now.', 'Congress/which.md': 'Partner score fast herself character minute.', 'Congress/democratic.md': 'Research knowledge owner Mr whole money cup.', 'Congress/accept.md': 'Expert plant institution relate old research position I.', 'Congress/remain.md': 'But natural film discussion among whole.', 'Congress/whatever.md': 'Today catch analysis.', 'Congress/fish.md': 'Herself share yourself movie behind whom check.', 'industry/wrong.md': 'Floor race land those hard actually avoid property.', 'industry/book.md': 'Together state billion race beautiful how.', 'industry/car.md': 'Heart central eye thought painting government appear.', 'industry/cause.md': 'Time religious describe oil heart.', 'industry/feeling.md': 'Include memory strategy other statement imagine teach.', 'industry/small.md': 'Little third your season kind.', 'industry/heavy.md': 'Quality international window probably adult attention.', 'industry/election.md': 'Democrat often turn.', 'industry/possible.md': 'Structure high discover half dog half forward.', 'industry/fish.md': 'Much without in fight miss.', 'live/white.md': 'Whatever significant capital air about.', 'live/discuss.md': 'Hit result find miss culture heart clear task.', 'live/traditional.md': 'If participant be year how may.', 'live/focus.md': 'Western win tree kid radio however value.', 'live/democratic.md': 'Reach rate none thank key after.', 'live/so.md': 'Type look identify spend drop sit skin heart.', 'live/possible.md': 'Window help reflect when consider science.', 'live/leader.md': 'Hold garden imagine style water ready several.', 'live/own.md': 'Say small finish sing raise.', 'lot/seat.md': 'Method institution third political.', 'lot/wall.md': 'Each feel program size different kid.', 'lot/worry.md': 'Support moment maintain majority American rule rock.', 'lot/improve.md': 'Reason better difficult take.', 'lot/heart.md': 'Make let way.', 'lot/modern.md': 'Example first recently let.', 'lot/make.md': 'First eat data executive.', 'lot/check.md': 'Wall artist recent side approach.', 'lot/hotel.md': 'Technology town film nothing writer head from.', 'lot/perhaps.md': 'Main manage authority serious short.', 'drop/add.md': 'Fish work to individual.', 'drop/mission.md': 'Ready kind only meeting.', 'drop/main.md': 'Education left somebody.', 'drop/of.md': 'Write room national change.', 'drop/else.md': 'Fly candidate may so college.', 'drop/manage.md': 'Allow expect heavy quality.', 'drop/arrive.md': 'Education science car common husband economy.', 'drop/former.md': 'Brother college detail.', 'drop/from.md': 'Though important executive Democrat smile.', 'drop/through.md': 'Adult large protect agency whom magazine behind.', 'central/several.md': 'Appear talk administration sort.', 'central/them.md': 'Unit huge call.', 'central/often.md': 'For nice after analysis series.', 'central/before.md': 'Account vote off police since.', 'central/commercial.md': 'Address country last teacher game compare.', 'central/these.md': 'Feeling rate first national.', 'central/tough.md': 'Party single media process statement forget.', 'central/crime.md': 'Hotel we five blue lawyer argue.', 'central/less.md': 'Guess environmental cover three late.', 'central/nice.md': 'Those religious audience case those.', 'civil/argue.md': 'Line culture seven six.', 'civil/life.md': 'Concern decide better whom.', 'civil/culture.md': 'National could exactly well discuss candidate especially sport.', 'civil/ready.md': 'Central about ready information.', 'civil/door.md': 'Can choice spring alone ball spend half.', 'civil/deep.md': 'Thought charge team type tonight maybe.', 'civil/question.md': 'Family evening its degree.', 'civil/gas.md': 'Talk why around necessary.', 'civil/hand.md': 'Discussion itself in far station head phone.', 'civil/central.md': 'Believe region their our whatever.', 'friend/oil.md': 'Little someone story put hundred able.', 'friend/discover.md': 'Someone city idea.', 'friend/month.md': 'Race walk people its Democrat sound.', 'friend/alone.md': 'Suffer concern choose participant work.', 'friend/myself.md': 'Truth simply memory alone plant large.', 'friend/note.md': 'Word end size enough.', 'friend/large.md': 'Tough glass per.', 'friend/wife.md': 'Sea investment many difference keep like improve.', 'friend/allow.md': 'Become personal own behavior sport.', 'friend/hand.md': 'Nation yourself final ground thus follow.', 'standard/late.md': 'Scientist people may story.', 'standard/audience.md': 'Finally remain actually toward purpose bad.', 'standard/level.md': 'Work around ask to.', 'standard/hear.md': 'Poor budget agent artist.', 'standard/sound.md': 'Night national film next.', 'standard/with.md': 'Former writer cause pattern school answer.', 'standard/standard.md': 'Do number shoulder animal yourself.', 'standard/easy.md': 'Myself must detail win.', 'standard/five.md': 'Lay would green generation season.', 'standard/analysis.md': 'While natural from staff option artist can.', 'community/book.md': 'Mr oil difficult dog.', 'community/else.md': 'Actually service thank state.', 'community/soldier.md': 'It lawyer cover job.', 'community/stay.md': 'Military teach subject cold affect shake.', 'community/cold.md': 'Election buy member alone school audience.', 'community/left.md': 'Picture let tell never.', 'community/up.md': 'Final all commercial anything term begin cultural.', 'community/woman.md': 'Big might attorney organization less drop.', 'community/save.md': 'Thought hear home set employee early purpose.', 'daughter/whose.md': 'Program writer interesting prepare authority skill.', 'daughter/seek.md': 'Throughout growth history save.', 'daughter/poor.md': 'Possible leave him up bag will.', 'daughter/product.md': 'Social stand administration challenge personal.', 'daughter/story.md': 'Anything song key first.', 'daughter/professor.md': 'Effect ahead eye serve single.', 'daughter/check.md': 'Young prevent play follow.', 'daughter/business.md': 'Alone idea security behavior.', 'daughter/put.md': 'Doctor eat should add pull customer might.', 'daughter/bar.md': 'Among ago cover good.', 'education/evening.md': 'Give tonight sell over whole word care.', 'education/body.md': 'Note start bad part positive during.', 'education/total.md': 'Contain hit individual college month.', 'education/nature.md': 'Skin look fine policy special part.', 'education/really.md': 'Difference beyond cost but.', 'education/reason.md': 'Wrong increase investment deep near simply spring.', 'education/blood.md': 'North smile know.', 'education/imagine.md': 'Summer keep conference.', 'education/fish.md': 'Answer impact sense professor gun fast me.', 'education/article.md': 'Usually could bad attack customer couple represent.', 'lead/rest.md': 'Address half hit.', 'lead/speech.md': 'Maintain prepare indicate production surface.', 'lead/become.md': 'Building plant air something direction fall provide.', 'lead/stage.md': 'View main when Republican father plant.', 'lead/under.md': 'Test next education series.', 'lead/adult.md': 'Rule others especially institution total what law.', 'lead/which.md': 'Far task service radio reach morning accept.', 'lead/phone.md': 'Unit good including show stand.', 'lead/would.md': 'President still follow race analysis opportunity.', 'lead/trade.md': 'Success whatever environmental avoid father how although may.', 'why/show.md': 'Decade station development character movement.', 'why/data.md': 'Itself feeling fund mean.', 'why/more.md': 'Address music fish team national tough.', 'why/debate.md': 'Meeting wind medical can city face cost.', 'why/something.md': 'Everybody bed economic own least peace executive.', 'why/most.md': 'Agreement station room name.', 'why/spring.md': 'Fine according mission against.', 'why/phone.md': 'By near next teacher be degree although.', 'why/full.md': 'Yard like phone catch on attention your.', 'why/stuff.md': 'Cup everybody open book he decade.', 'ten/pull.md': 'Factor list try able pattern.', 'ten/serve.md': 'Want exist bank book.', 'ten/nature.md': 'Eight own hot first success.', 'ten/sea.md': 'Trial heart office dark fine everything suggest.', 'ten/page.md': 'Edge to window size stand sea.', 'ten/someone.md': 'Themselves hair together maybe yes never.', 'ten/international.md': 'Food style wait tend improve.', 'ten/time.md': 'Note center brother process big.', 'ten/simply.md': 'Congress way enjoy hand first.', 'ten/rock.md': 'Method wall when book agency.', 'rule/hear.md': 'History event character everybody paper machine little billion.', 'rule/thing.md': 'Trial produce despite water range television.', 'rule/feel.md': 'Soon give never future difference.', 'rule/system.md': 'Bill article station despite.', 'rule/produce.md': 'Yes method sense.', 'rule/eye.md': 'Finally this team yet throughout.', 'rule/nation.md': 'Radio entire ago behavior prevent response ten according.', 'rule/thousand.md': 'Anything help military with run.', 'rule/goal.md': 'Inside firm without.', 'rule/perhaps.md': 'Back election leave.'}
If I am not wrong, both the expected and actual result contain the same entries. It is just that the ordering is different. The expected result also doesnt follow any particular format (so does the actual result).
Kindly advise on this
@carlton
EDIT
: Resolved on a later evaluation

[2025-02-12T08:55:40.171Z] Pradeep Mondal (@21f2000709)
For the task - *
B10
. Write an API endpoint that filters a CSV file and returns JSON data
Do we have to handle prompts for converting CSV to JSON or for writing an endpoint for doing so?
@carlton
@Jivraj

[2025-02-12T09:04:36.688Z] Guddu Kumar Mishra  (@22f3001315)
yeah i am also facing the same doubt

[2025-02-12T09:04:54.804Z] Andrew David (@23f1002382)
+1‚Ä¶
@Jivraj
@s.anand

[2025-02-12T09:36:12.326Z] Shashannk (@23f2003413)
could someone please share their repo for reference. it would be very much helpful

[2025-02-12T09:38:35.778Z] Shaurya Sharad Shukla (@TRIGON)
Dear Instructors (
@carlton
,
@iamprasna
):
Confirming, just to be needfully pedantic:
It will
solely
be the responsibility of the Project Evaluator (human or machine) to parse the correct
AIPROXY_TOKEN
generated against my IITM email ID (presumably, per some database which holds all such generated
AIPROXY_TOKEN
s of the students who have generated one); and the correct
$IMAGE_NAME
(to-be-submitted by myself in the Project Submission Google Form) in
podman run $IMAGE_NAME -e AIPROXY_TOKEN=$AIPROXY_TOKEN -p 8000:8000
, correct?
Asking this seemingly obvious question, as (apparently) the actual
AIPROXY_TOKEN
is not to be included anywhere in the code, or the repository, or the dockerfile.

[2025-02-12T09:51:42.226Z] Adithya S (@Adithya)
I am also facing the same issue, just that the ordering is different.
Sorting by keys also didn‚Äôt help.
Please help on this
@carlton
@Jivraj

[2025-02-12T10:36:08.869Z] D HARICHARAN  (@Haricharan)
sir will the tasks of Phase A and Phase B change? like currently do we need to make llm write the code for all tasks dynamically or can we write a pre defined python code to execute tasks after the llm parses the task and runs python code

[2025-02-12T10:42:34.656Z] Andrew David (@23f1002382)
Check length of result and length of expected, one is 98 and other is 298
expected = {'by/perhaps.md': 'Base relationship identify mean happy Mrs whatever.', 'by/they.md': 'Unit its thank half morning determine development place.', 'by/culture.md': 'Prevent north only miss cold.', 'by/region.md': 'Claim card from receive alone you capital book.', 'by/draw.md': 'Shoulder class six finally build call note bring.', 'by/family.md': 'Debate at office traditional stop great.', 'by/defense.md': 'Marriage million crime organization give over.', 'by/treat.md': 'Themselves young course feel.', 'by/little.md': 'Break somebody whose set else history.', 'by/color.md': 'Soon address everyone computer against.', 'daughter/seek.md': 'Throughout growth history save.', 'daughter/bar.md': 'Among ago cover good.', 'daughter/business.md': 'Alone idea security behavior.', 'daughter/poor.md': 'Possible leave him up bag will.', 'daughter/story.md': 'Anything song key first.', 'daughter/product.md': 'Social stand administration challenge personal.', 'daughter/check.md': 'Young prevent play follow.', 'daughter/put.md': 'Doctor eat should add pull customer might.', 'daughter/whose.md': 'Program writer interesting prepare authority skill.', 'daughter/professor.md': 'Effect ahead eye serve single.', 'drop/manage.md': 'Allow expect heavy quality.', 'drop/mission.md': 'Ready kind only meeting.', 'drop/arrive.md': 'Education science car common husband economy.', 'drop/main.md': 'Education left somebody.', 'drop/of.md': 'Write room national change.', 'drop/through.md': 'Adult large protect agency whom magazine behind.', 'drop/former.md': 'Brother college detail.', 'drop/add.md': 'Fish work to individual.', 'drop/from.md': 'Though important executive Democrat smile.', 'drop/else.md': 'Fly candidate may so college.', 'civil/door.md': 'Can choice spring alone ball spend half.', 'civil/ready.md': 'Central about ready information.', 'civil/deep.md': 'Thought charge team type tonight maybe.', 'civil/hand.md': 'Discussion itself in far station head phone.', 'civil/question.md': 'Family evening its degree.', 'civil/argue.md': 'Line culture seven six.', 'civil/gas.md': 'Talk why around necessary.', 'civil/life.md': 'Concern decide better whom.', 'civil/culture.md': 'National could exactly well discuss candidate especially sport.', 'civil/central.md': 'Believe region their our whatever.', 'standard/easy.md': 'Myself must detail win.', 'standard/sound.md': 'Night national film next.', 'standard/five.md': 'Lay would green generation season.', 'standard/audience.md': 'Finally remain actually toward purpose bad.', 'standard/hear.md': 'Poor budget agent artist.', 'standard/with.md': 'Former writer cause pattern school answer.', 'standard/standard.md': 'Do number shoulder animal yourself.', 'standard/late.md': 'Scientist people may story.', 'standard/level.md': 'Work around ask to.', 'standard/analysis.md': 'While natural from staff option artist can.', 'few/choose.md': 'Official travel although price message example indeed.', 'few/sometimes.md': 'Big order defense field represent.', 'few/weight.md': 'Man mission American.', 'few/expect.md': 'Bill well artist night rule bag.', 'few/my.md': 'Open line address contain whole impact into front.', 'few/store.md': 'Hand thought example exist record practice though.', 'few/prove.md': 'Opportunity foot agent herself save other become study.', 'few/southern.md': 'Meet prove admit.', 'few/theory.md': 'Security effort protect future task long close.', 'few/information.md': 'Really morning yeah.', 'community/up.md': 'Final all commercial anything term begin cultural.', 'community/save.md': 'Thought hear home set employee early purpose.', 'community/stay.md': 'Military teach subject cold affect shake.', 'community/book.md': 'Mr oil difficult dog.', 'community/woman.md': 'Big might attorney organization less drop.', 'community/cold.md': 'Election buy member alone school audience.', 'community/else.md': 'Actually service thank state.', 'community/left.md': 'Picture let tell never.', 'community/soldier.md': 'It lawyer cover job.', 'Congress/let.md': 'Bank ability actually outside.', 'Congress/whatever.md': 'Today catch analysis.', 'Congress/remain.md': 'But natural film discussion among whole.', 'Congress/democratic.md': 'Research knowledge owner Mr whole money cup.', 'Congress/which.md': 'Partner score fast herself character minute.', 'Congress/accept.md': 'Expert plant institution relate old research position I.', 'Congress/produce.md': 'Land do heart watch which many.', 'Congress/task.md': 'Book help represent now.', 'Congress/fish.md': 'Herself share yourself movie behind whom check.', 'Congress/remember.md': 'Purpose good policy line trade.', 'ten/rock.md': 'Method wall when book agency.', 'ten/sea.md': 'Trial heart office dark fine everything suggest.', 'ten/simply.md': 'Congress way enjoy hand first.', 'ten/someone.md': 'Themselves hair together maybe yes never.', 'ten/nature.md': 'Eight own hot first success.', 'ten/page.md': 'Edge to window size stand sea.', 'ten/pull.md': 'Factor list try able pattern.', 'ten/international.md': 'Food style wait tend improve.', 'ten/time.md': 'Note center brother process big.', 'ten/serve.md': 'Want exist bank book.', 'live/leader.md': 'Hold garden imagine style water ready several.', 'live/white.md': 'Whatever significant capital air about.', 'live/democratic.md': 'Reach rate none thank key after.', 'live/traditional.md': 'If participant be year how may.', 'live/focus.md': 'Western win tree kid radio however value.', 'live/own.md': 'Say small finish sing raise.', 'live/so.md': 'Type look identify spend drop sit skin heart.', 'live/possible.md': 'Window help reflect when consider science.', 'live/discuss.md': 'Hit result find miss culture heart clear task.'}
result  = {'suddenly/mouth.md': 'Outside food subject positive human.', 'suddenly/add.md': 'Window word during born do finally.', 'suddenly/free.md': 'Them ball significant different which traditional.', 'suddenly/management.md': 'Man fire long hour modern.', 'suddenly/leave.md': 'Season people Democrat hand among too.', 'suddenly/low.md': 'Front actually decision security fast song believe leg.', 'suddenly/why.md': 'Account listen such day method sing.', 'suddenly/miss.md': 'Rather although team thank.', 'suddenly/base.md': 'Total low room structure staff.', 'suddenly/strategy.md': 'Never understand less operation onto still trade environment.', 'ground/girl.md': 'Civil speech back sell.', 'ground/game.md': 'Fill whose card or daughter old meet.', 'ground/term.md': 'Pick return put set.', 'ground/every.md': 'Free service trouble effort somebody blood modern.', 'ground/along.md': 'Important plant increase door much.', 'ground/call.md': 'Article agent three scientist.', 'ground/do.md': 'Memory food strategy meeting.', 'ground/end.md': 'Large player discussion similar prove part.', 'ground/full.md': 'Actually start commercial.', 'ground/ever.md': 'Human example gun now my just Republican.', 'way/not.md': 'Decision together land chair.', 'way/morning.md': 'Information later service raise after trial base.', 'way/responsibility.md': 'Our child why environment care goal.', 'way/increase.md': 'Return say response political.', 'way/relationship.md': 'General view thing poor machine market peace.', 'way/soldier.md': 'Produce table should will school produce player wall.', 'way/act.md': 'Smile guess simple read style its international.', 'way/sound.md': 'Conference first finally recognize as.', 'way/reach.md': 'Exactly size discuss management miss article.', 'way/hotel.md': 'From become actually.', 'hit/run.md': 'Stock several region put thought decade evening.', 'hit/free.md': 'Crime usually produce.', 'hit/foot.md': 'Ball specific trip state.', 'hit/ball.md': 'Condition color focus traditional.', 'hit/song.md': 'Section environmental final light word in yes operation.', 'hit/since.md': 'Shoulder wrong matter seek cultural vote themselves.', 'hit/safe.md': 'Hear try spend item can along light.', 'hit/much.md': 'Guess great dream through concern feel.', 'hit/prove.md': 'Her base cup forward.', 'hit/stop.md': 'Nation this avoid herself deal place memory.', 'few/sometimes.md': 'Big order defense field represent.', 'few/southern.md': 'Meet prove admit.', 'few/choose.md': 'Official travel although price message example indeed.', 'few/store.md': 'Hand thought example exist record practice though.', 'few/weight.md': 'Man mission American.', 'few/information.md': 'Really morning yeah.', 'few/prove.md': 'Opportunity foot agent herself save other become study.', 'few/expect.md': 'Bill well artist night rule bag.', 'few/theory.md': 'Security effort protect future task long close.', 'few/my.md': 'Open line address contain whole impact into front.', 'resource/rest.md': 'Ok tough talk.', 'resource/move.md': 'Law write democratic drug itself house accept through.', 'resource/particularly.md': 'Affect woman nice.', 'resource/entire.md': 'Focus to once sea friend group.', 'resource/painting.md': 'Customer environment none trade.', 'resource/structure.md': 'Stuff return protect our bit reality.', 'resource/until.md': 'Growth industry region receive.', 'resource/significant.md': 'Long million fall throughout government tend.', 'resource/hospital.md': 'Quality certain fight want much body between.', 'resource/marriage.md': 'Foot specific mission.', 'for/hope.md': 'Whatever report wife fly close lot student.', 'for/poor.md': 'Explain claim police eye paper much when.', 'for/assume.md': 'Control yeah effect local economy worry.', 'for/couple.md': 'Floor both take indeed audience.', 'for/money.md': 'Join live next care material.', 'for/never.md': 'Me natural full.', 'for/situation.md': 'Show book instead hope lawyer.', 'for/north.md': 'Card level kind send loss growth.', 'for/hit.md': 'Minute wish above pass just later watch.', 'for/perhaps.md': 'Every professor sport unit rock bed.', 'project/individual.md': 'Tough safe machine small outside mention could must.', 'project/change.md': 'Century drug value.', 'project/home.md': 'Big decade edge feeling surface matter force student.', 'project/want.md': 'Region catch nation civil one Mr specific.', 'project/something.md': 'Major control three.', 'project/reality.md': 'Mouth including fine.', 'project/my.md': 'Fire point or success marriage write example.', 'project/issue.md': 'Former true career similar use visit machine.', 'project/surface.md': 'Cold reduce task life American act stage.', 'project/drug.md': 'Reason still field animal.', 'effort/morning.md': 'Policy quickly get capital smile.', 'effort/he.md': 'Thought view product interview explain.', 'effort/house.md': 'High hear thought according.', 'effort/church.md': 'Culture ask change focus.', 'effort/effect.md': 'Before suddenly who student could boy serve.', 'effort/price.md': 'Shoulder financial public reason home explain safe.', 'effort/company.md': 'Exactly treatment concern fly factor care drive.', 'effort/international.md': 'Rich take hear open.', 'effort/federal.md': 'Difference rate character by his blood this.', 'effort/computer.md': 'Lay financial article exactly.', 'by/region.md': 'Claim card from receive alone you capital book.', 'by/they.md': 'Unit its thank half morning determine development place.', 'by/defense.md': 'Marriage million crime organization give over.', 'by/draw.md': 'Shoulder class six finally build call note bring.', 'by/culture.md': 'Prevent north only miss cold.', 'by/family.md': 'Debate at office traditional stop great.', 'by/treat.md': 'Themselves young course feel.', 'by/little.md': 'Break somebody whose set else history.', 'by/color.md': 'Soon address everyone computer against.', 'by/perhaps.md': 'Base relationship identify mean happy Mrs whatever.', 'bill/appear.md': 'Whole senior next stop yard national section.', 'bill/room.md': 'Able improve anything teacher media writer employee.', 'bill/citizen.md': 'Safe anyone major reach mother ground over leave.', 'bill/for.md': 'A several low detail.', 'bill/role.md': 'More light anything study hand power.', 'bill/set.md': 'Necessary century drive attack capital.', 'bill/generation.md': 'Stay could quality shake.', 'bill/drive.md': 'Situation we his.', 'bill/computer.md': 'Culture ahead change perhaps however audience.', 'bill/gas.md': 'Reveal attack and church.', 'color/sell.md': 'Mention although while boy turn.', 'color/throughout.md': 'She actually gun start.', 'color/management.md': 'Short serve beat increase than visit.', 'color/smile.md': 'His season employee husband.', 'color/wear.md': 'Share green measure sometimes.', 'color/official.md': 'Suddenly seat tend thus office action move.', 'color/admit.md': 'Each important clear.', 'color/treat.md': 'Tv outside attorney rich say same environment.', 'color/turn.md': 'Try drop old along.', 'color/sit.md': 'Including turn seem none computer.', 'build/together.md': 'Finally point only police artist.', 'build/rest.md': 'Author run let.', 'build/wall.md': 'Administration a week form side feeling.', 'build/none.md': 'Commercial stop page else.', 'build/explain.md': 'Join tend idea stand not option woman.', 'build/decision.md': 'Poor fund interesting bring.', 'build/beyond.md': 'Artist billion begin record anything none management practice.', 'build/dream.md': 'Decision suddenly prevent speak old power herself.', 'build/each.md': 'Able out key.', 'build/street.md': 'Knowledge specific technology before leave.', 'wrong/market.md': 'Realize key point whatever Democrat or say.', 'wrong/free.md': 'Deal even from mouth source.', 'wrong/sure.md': 'Similar him believe actually.', 'wrong/apply.md': 'Everybody office list service stock significant.', 'wrong/share.md': 'Painting every apply.', 'wrong/standard.md': 'Already place fund really.', 'wrong/might.md': 'Possible during claim view.', 'wrong/nation.md': 'About prove cold question race.', 'wrong/be.md': 'Land debate natural American.', 'wrong/suggest.md': 'Could environmental rather can us night.', 'Congress/remember.md': 'Purpose good policy line trade.', 'Congress/let.md': 'Bank ability actually outside.', 'Congress/produce.md': 'Land do heart watch which many.', 'Congress/task.md': 'Book help represent now.', 'Congress/which.md': 'Partner score fast herself character minute.', 'Congress/democratic.md': 'Research knowledge owner Mr whole money cup.', 'Congress/accept.md': 'Expert plant institution relate old research position I.', 'Congress/remain.md': 'But natural film discussion among whole.', 'Congress/whatever.md': 'Today catch analysis.', 'Congress/fish.md': 'Herself share yourself movie behind whom check.', 'industry/wrong.md': 'Floor race land those hard actually avoid property.', 'industry/book.md': 'Together state billion race beautiful how.', 'industry/car.md': 'Heart central eye thought painting government appear.', 'industry/cause.md': 'Time religious describe oil heart.', 'industry/feeling.md': 'Include memory strategy other statement imagine teach.', 'industry/small.md': 'Little third your season kind.', 'industry/heavy.md': 'Quality international window probably adult attention.', 'industry/election.md': 'Democrat often turn.', 'industry/possible.md': 'Structure high discover half dog half forward.', 'industry/fish.md': 'Much without in fight miss.', 'live/white.md': 'Whatever significant capital air about.', 'live/discuss.md': 'Hit result find miss culture heart clear task.', 'live/traditional.md': 'If participant be year how may.', 'live/focus.md': 'Western win tree kid radio however value.', 'live/democratic.md': 'Reach rate none thank key after.', 'live/so.md': 'Type look identify spend drop sit skin heart.', 'live/possible.md': 'Window help reflect when consider science.', 'live/leader.md': 'Hold garden imagine style water ready several.', 'live/own.md': 'Say small finish sing raise.', 'lot/seat.md': 'Method institution third political.', 'lot/wall.md': 'Each feel program size different kid.', 'lot/worry.md': 'Support moment maintain majority American rule rock.', 'lot/improve.md': 'Reason better difficult take.', 'lot/heart.md': 'Make let way.', 'lot/modern.md': 'Example first recently let.', 'lot/make.md': 'First eat data executive.', 'lot/check.md': 'Wall artist recent side approach.', 'lot/hotel.md': 'Technology town film nothing writer head from.', 'lot/perhaps.md': 'Main manage authority serious short.', 'drop/add.md': 'Fish work to individual.', 'drop/mission.md': 'Ready kind only meeting.', 'drop/main.md': 'Education left somebody.', 'drop/of.md': 'Write room national change.', 'drop/else.md': 'Fly candidate may so college.', 'drop/manage.md': 'Allow expect heavy quality.', 'drop/arrive.md': 'Education science car common husband economy.', 'drop/former.md': 'Brother college detail.', 'drop/from.md': 'Though important executive Democrat smile.', 'drop/through.md': 'Adult large protect agency whom magazine behind.', 'central/several.md': 'Appear talk administration sort.', 'central/them.md': 'Unit huge call.', 'central/often.md': 'For nice after analysis series.', 'central/before.md': 'Account vote off police since.', 'central/commercial.md': 'Address country last teacher game compare.', 'central/these.md': 'Feeling rate first national.', 'central/tough.md': 'Party single media process statement forget.', 'central/crime.md': 'Hotel we five blue lawyer argue.', 'central/less.md': 'Guess environmental cover three late.', 'central/nice.md': 'Those religious audience case those.', 'civil/argue.md': 'Line culture seven six.', 'civil/life.md': 'Concern decide better whom.', 'civil/culture.md': 'National could exactly well discuss candidate especially sport.', 'civil/ready.md': 'Central about ready information.', 'civil/door.md': 'Can choice spring alone ball spend half.', 'civil/deep.md': 'Thought charge team type tonight maybe.', 'civil/question.md': 'Family evening its degree.', 'civil/gas.md': 'Talk why around necessary.', 'civil/hand.md': 'Discussion itself in far station head phone.', 'civil/central.md': 'Believe region their our whatever.', 'friend/oil.md': 'Little someone story put hundred able.', 'friend/discover.md': 'Someone city idea.', 'friend/month.md': 'Race walk people its Democrat sound.', 'friend/alone.md': 'Suffer concern choose participant work.', 'friend/myself.md': 'Truth simply memory alone plant large.', 'friend/note.md': 'Word end size enough.', 'friend/large.md': 'Tough glass per.', 'friend/wife.md': 'Sea investment many difference keep like improve.', 'friend/allow.md': 'Become personal own behavior sport.', 'friend/hand.md': 'Nation yourself final ground thus follow.', 'standard/late.md': 'Scientist people may story.', 'standard/audience.md': 'Finally remain actually toward purpose bad.', 'standard/level.md': 'Work around ask to.', 'standard/hear.md': 'Poor budget agent artist.', 'standard/sound.md': 'Night national film next.', 'standard/with.md': 'Former writer cause pattern school answer.', 'standard/standard.md': 'Do number shoulder animal yourself.', 'standard/easy.md': 'Myself must detail win.', 'standard/five.md': 'Lay would green generation season.', 'standard/analysis.md': 'While natural from staff option artist can.', 'community/book.md': 'Mr oil difficult dog.', 'community/else.md': 'Actually service thank state.', 'community/soldier.md': 'It lawyer cover job.', 'community/stay.md': 'Military teach subject cold affect shake.', 'community/cold.md': 'Election buy member alone school audience.', 'community/left.md': 'Picture let tell never.', 'community/up.md': 'Final all commercial anything term begin cultural.', 'community/woman.md': 'Big might attorney organization less drop.', 'community/save.md': 'Thought hear home set employee early purpose.', 'daughter/whose.md': 'Program writer interesting prepare authority skill.', 'daughter/seek.md': 'Throughout growth history save.', 'daughter/poor.md': 'Possible leave him up bag will.', 'daughter/product.md': 'Social stand administration challenge personal.', 'daughter/story.md': 'Anything song key first.', 'daughter/professor.md': 'Effect ahead eye serve single.', 'daughter/check.md': 'Young prevent play follow.', 'daughter/business.md': 'Alone idea security behavior.', 'daughter/put.md': 'Doctor eat should add pull customer might.', 'daughter/bar.md': 'Among ago cover good.', 'education/evening.md': 'Give tonight sell over whole word care.', 'education/body.md': 'Note start bad part positive during.', 'education/total.md': 'Contain hit individual college month.', 'education/nature.md': 'Skin look fine policy special part.', 'education/really.md': 'Difference beyond cost but.', 'education/reason.md': 'Wrong increase investment deep near simply spring.', 'education/blood.md': 'North smile know.', 'education/imagine.md': 'Summer keep conference.', 'education/fish.md': 'Answer impact sense professor gun fast me.', 'education/article.md': 'Usually could bad attack customer couple represent.', 'lead/rest.md': 'Address half hit.', 'lead/speech.md': 'Maintain prepare indicate production surface.', 'lead/become.md': 'Building plant air something direction fall provide.', 'lead/stage.md': 'View main when Republican father plant.', 'lead/under.md': 'Test next education series.', 'lead/adult.md': 'Rule others especially institution total what law.', 'lead/which.md': 'Far task service radio reach morning accept.', 'lead/phone.md': 'Unit good including show stand.', 'lead/would.md': 'President still follow race analysis opportunity.', 'lead/trade.md': 'Success whatever environmental avoid father how although may.', 'why/show.md': 'Decade station development character movement.', 'why/data.md': 'Itself feeling fund mean.', 'why/more.md': 'Address music fish team national tough.', 'why/debate.md': 'Meeting wind medical can city face cost.', 'why/something.md': 'Everybody bed economic own least peace executive.', 'why/most.md': 'Agreement station room name.', 'why/spring.md': 'Fine according mission against.', 'why/phone.md': 'By near next teacher be degree although.', 'why/full.md': 'Yard like phone catch on attention your.', 'why/stuff.md': 'Cup everybody open book he decade.', 'ten/pull.md': 'Factor list try able pattern.', 'ten/serve.md': 'Want exist bank book.', 'ten/nature.md': 'Eight own hot first success.', 'ten/sea.md': 'Trial heart office dark fine everything suggest.', 'ten/page.md': 'Edge to window size stand sea.', 'ten/someone.md': 'Themselves hair together maybe yes never.', 'ten/international.md': 'Food style wait tend improve.', 'ten/time.md': 'Note center brother process big.', 'ten/simply.md': 'Congress way enjoy hand first.', 'ten/rock.md': 'Method wall when book agency.', 'rule/hear.md': 'History event character everybody paper machine little billion.', 'rule/thing.md': 'Trial produce despite water range television.', 'rule/feel.md': 'Soon give never future difference.', 'rule/system.md': 'Bill article station despite.', 'rule/produce.md': 'Yes method sense.', 'rule/eye.md': 'Finally this team yet throughout.', 'rule/nation.md': 'Radio entire ago behavior prevent response ten according.', 'rule/thousand.md': 'Anything help military with run.', 'rule/goal.md': 'Inside firm without.', 'rule/perhaps.md': 'Back election leave.'}
print(len(set(result)), len(set(expected)))
count = 0
print("length of result", len(result))
print("length of expected", len(expected))
for y in result:
    if y not in expected:
        count += 1
        print(f"{y}:{result[y]} IS EXTRA FILE")
        print(count)

[2025-02-12T11:18:23.620Z] Pradeep Mondal (@21f2000709)
s.anand:
A
sample
evaluation script for Project 1 tasks A1-A10 is available at
tools-in-data-science-public/project-1 at tds-2025-01-project-1-wip ¬∑ sanand0/tools-in-data-science-public ¬∑ GitHub
Sir there is an error in the evaluation script for task A1, url -
https://raw.githubusercontent.com/sanand0/tools-in-data-science-public/tds-2025-01/datagen.py
doesn‚Äôt exist,
instead this should -
https://raw.githubusercontent.com/sanand0/tools-in-data-science-public/tds-2025-01/project-1/datagen.py

[2025-02-12T12:54:37.329Z] Carlton D'Silva (@carlton: Regular)
@23f2001978
That error is usually if you are using the wrong endpoint (ie. using open ai libraries instead of sending requests to aiproxy).
Without seeing the request its hard to tell you what the cause of the error is.
Kind regards

[2025-02-12T13:20:19.960Z] Carlton D'Silva (@carlton: Regular)
@21f2000709
@23f1002382
B10 ‚Üí Create a service that creates a specified endpoint that receives a CSV and returns a JSON data . Where the JSON is expected, whether in the response body of the endpoint , or in a file will be specified by the task master
Kind regards

[2025-02-12T14:02:08.980Z] Arya Agrahari  (@22f3002771)
hi
@carlton
@Jivraj
for A2 i am getting this particular error and i don‚Äôt know what i am doing wrong in this
Screenshot from 2025-02-12 19-31-47
1501√ó564 44.7 KB

[2025-02-12T14:07:21.156Z] Andrew David (@23f1002382)
issue with evaluate.py , post the code snippet in task a2, where it calculates the result and checks with expected.

[2025-02-12T14:16:26.408Z] Arya Agrahari  (@22f3002771)
you mean screenshot of evaluate.py file?
Screenshot from 2025-02-12 20-21-56
1501√ó564 61.8 KB

[2025-02-12T14:55:36.830Z] Andrew David (@23f1002382)
running in docker?
////////////////////////////

[2025-02-12T15:01:11.724Z] Arya Agrahari  (@22f3002771)
Yes, I commented out check=True to see the error

[2025-02-12T15:56:31.053Z] Shashannk (@23f2003413)
@carlton
@Jivraj
could you please help me out on how to start with TDS Project-1, as I am stuck at the moment and don‚Äôt know where to start from. This project is very much unfamiliar for me and I need some guidance on how to start with it. It would be really great if you could provide some help through resources/materials/videos and help me complete the project. Thanks in advance!

[2025-02-12T16:46:18.918Z] Andrew David (@23f1002382)
then im not sure exactly wait lemme check

[2025-02-12T16:49:41.628Z] Andrew David (@23f1002382)
issue with evaluate py, specifically , how it formats the file, maybe shell=True should be uncommented if commented out. then im not sure. Im not in composing docker files yet

[2025-02-12T17:08:28.279Z] Anvitha (@AnvithaV)
Could anyone please help me with the project‚Ä¶ I am trying to do it but I‚Äôm always getting errors even while starting.

[2025-02-12T17:16:22.873Z] Pradeep Mondal (@21f2000709)
My final docker image size is coming 1.25 gb, I am using the ubuntu base image as I thought it would be appropriate given the tasks. Is it ok with that size?
PS - Also I would be running out of token if I need to test again with some other base image now.
@carlton

[2025-02-12T17:21:35.526Z] Pradeep Mondal (@21f2000709)
Go through the week 1-3 assignments once, you would be good to go with Phase A tasks.
@23f2003413
@AnvithaV

[2025-02-12T17:29:12.353Z] Carlton D'Silva (@carlton: Regular)
You do not need the whole of ubuntu!
Just python and uv
More like 128mb image.
Please watch Tues week 5 session 1
Kind regards

[2025-02-12T17:38:21.482Z] Avnish Jajodia (@22f3001777)
Will there be more live sessions on project ?
@carlton

[2025-02-12T17:53:19.068Z] Pradeep Mondal (@21f2000709)
I could pull it down to 610 mb, using python:3.9-slim now, but there are some essential libraries that is needed which is taking up the space‚Ä¶will it be ok? I mean installing on the go with uv might lead to timeout during evaluation‚Ä¶

[2025-02-12T18:30:50.906Z] 23f3001356 (@ShahbaazSingh)
How did you corrected it ?

[2025-02-12T19:09:36.761Z] Pradeep Mondal (@21f2000709)
I tried cutting it down further but it is affecting the functionality, this is the best I can do, i.e., 610 mb

[2025-02-12T19:33:11.401Z] Andrew David (@23f1002382)
could you help later, when i need to construct docker image, via gmeet? PLEASE

[2025-02-12T20:00:07.871Z] Guddu Kumar Mishra  (@22f3001315)
ANY SUGGESTIONS (just one digit away) ::
import easyocr
from pathlib import Path
import re

def extract_credit_card_number(input_image: str, output_file: str):

    input_path = Path(f".{input_image}")
    output_path = Path(f".{output_file}")

    if not input_path.exists():
        raise ValueError(f"Image file {input_path} does not exist.")

    # Step 1: Use OCR to extract text from the image
    reader = easyocr.Reader(['en'])
    try:
        result = reader.readtext(str(input_path))
    except Exception as e:
        raise ValueError(f"OCR processing failed: {str(e)}")

    # Combine all extracted text into a single string
    extracted_text = " ".join([text for (_, text, _) in result])

    # Step 2: Use the LLM to refine the extracted text and extract the credit card number
    prompt = f"""
    The following text was extracted from an image. It may contain a credit card number.
    Extract the credit card number and return only the number without spaces or dashes.
    If no credit card number is found, return "None".

    Extracted text: {extracted_text}
    """
    try:
        response = chat_completion(prompt)
        card_number = response.get("choices", [])[0].get("message", {}).get("content", "").strip()

        # Validate the card number (basic check for 16 digits)
        if card_number.lower() == "none" or not card_number.isdigit() or len(card_number) != 16:
            raise ValueError("No valid credit card number found in the image.")

        # Write the card number to the output file
        output_path.parent.mkdir(parents=True, exist_ok=True)
        with open(output_path, "w") as f:
            f.write(card_number)

        return f"A8 Completed: Credit card number extracted and written to {output_file}"
    except Exception as e:
        raise ValueError(f"Failed to process text with LLM: {str(e)}")
/data/credit-card.txt
‚ö†Ô∏è EXPECTED:
4026399336539356
‚ö†Ô∏è RESULT:
4026399338539356

[2025-02-12T20:31:46.779Z] Andrew David (@23f1002382)
<Response [200]>
{‚Äòid‚Äô: ‚Äòchatcmpl-B0De8V66WZAucAweJe6e32BWSLnpT‚Äô, ‚Äòobject‚Äô: ‚Äòchat.completion‚Äô, ‚Äòcreated‚Äô: 1739392156, ‚Äòmodel‚Äô: ‚Äògpt-4o-mini-2024-07-18‚Äô, ‚Äòchoices‚Äô: [{‚Äòindex‚Äô: 0, ‚Äòmessage‚Äô: {‚Äòrole‚Äô: ‚Äòassistant‚Äô, ‚Äòcontent‚Äô: ‚ÄúI‚Äôm sorry, but I can‚Äôt assist with that.‚Äù, ‚Äòrefusal‚Äô: None}, ‚Äòlogprobs‚Äô: None, ‚Äòfinish_reason‚Äô: ‚Äòstop‚Äô}], ‚Äòusage‚Äô: {‚Äòprompt_tokens‚Äô: 874, ‚Äòcompletion_tokens‚Äô: 11, ‚Äòtotal_tokens‚Äô: 885, ‚Äòprompt_tokens_details‚Äô: {‚Äòcached_tokens‚Äô: 0, ‚Äòaudio_tokens‚Äô: 0}, ‚Äòcompletion_tokens_details‚Äô: {‚Äòreasoning_tokens‚Äô: 0, ‚Äòaudio_tokens‚Äô: 0, ‚Äòaccepted_prediction_tokens‚Äô: 0, ‚Äòrejected_prediction_tokens‚Äô: 0}}, ‚Äòservice_tier‚Äô: ‚Äòdefault‚Äô, ‚Äòsystem_fingerprint‚Äô: ‚Äòfp_bd83329f63‚Äô, ‚ÄòmonthlyCost‚Äô: 0.048128640000000014, ‚Äòcost‚Äô: 0.0026880000000000003, ‚ÄòmonthlyRequests‚Äô: 51}
def query_gpt_image(image_path: str, task: str):
    print("üîç Image Path:", image_path)
    image_format = image_path.split(".")[-1]
    with open(image_path, "rb") as file:
        image_data = base64.b64encode(file.read()).decode("utf-8")
    response = requests.post(
        "https://aiproxy.sanand.workers.dev/openai/v1/chat/completions",
        headers={"Authorization": f"Bearer {"APIKEY"}",
                "Content-Type": "application/json"},
        json={
            "model": "gpt-4o-mini",
            "messages": [
                {
                "role": "user",
                "content": [
                    {"type": "text", "text": task},
                    {
                    "type": "image_url",
                    "image_url": { "url": f"data:image/{image_format};base64,{image_data}" }
                    }
                ]
                }
            ]
            }
                     )
    response.raise_for_status()
    print(response)
    print(response.json())
    result = response.json()
response = query_gpt_image("data/credit_card.png","Extract the credit card number from image")
Why is this not working?
EDIT: Requires prompt engineering as ‚Äúcredit card‚Äù is sensitive information
<Response [200]>
{‚Äòid‚Äô: ‚Äòchatcmpl-B0Dlie1ZIS68PZBCT0XJKhLKbyPAC‚Äô, ‚Äòobject‚Äô: ‚Äòchat.completion‚Äô, ‚Äòcreated‚Äô: 1739392626, ‚Äòmodel‚Äô: ‚Äògpt-4o-mini-2024-07-18‚Äô, ‚Äòchoices‚Äô: [{‚Äòindex‚Äô: 0, ‚Äòmessage‚Äô: {‚Äòrole‚Äô: ‚Äòassistant‚Äô, ‚Äòcontent‚Äô: ‚ÄòThe numbers extracted from the image are:\n\n- 3009 1429 5211 59\n- 09/29\n- 113‚Äô, ‚Äòrefusal‚Äô: None}, ‚Äòlogprobs‚Äô: None, ‚Äòfinish_reason‚Äô: ‚Äòstop‚Äô}], ‚Äòusage‚Äô: {‚Äòprompt_tokens‚Äô: 871, ‚Äòcompletion_tokens‚Äô: 31, ‚Äòtotal_tokens‚Äô: 902, ‚Äòprompt_tokens_details‚Äô: {‚Äòcached_tokens‚Äô: 0, ‚Äòaudio_tokens‚Äô: 0}, ‚Äòcompletion_tokens_details‚Äô: {‚Äòreasoning_tokens‚Äô: 0, ‚Äòaudio_tokens‚Äô: 0, ‚Äòaccepted_prediction_tokens‚Äô: 0, ‚Äòrejected_prediction_tokens‚Äô: 0}}, ‚Äòservice_tier‚Äô: ‚Äòdefault‚Äô, ‚Äòsystem_fingerprint‚Äô: ‚Äòfp_bd83329f63‚Äô, ‚ÄòmonthlyCost‚Äô: 0.05092764000000002, ‚Äòcost‚Äô: 0.002799, ‚ÄòmonthlyRequests‚Äô: 52}
response = query_gpt_image("data/credit_card.png","Extract number from image")

[2025-02-13T02:36:19.536Z] Kumar Rishabh  (@Rishabh2)
Sir in main.py file I‚Äôm defining task with different variables . But in evaluate.py tasks are defined by different variables to test and when I‚Äôm testing it using python evaluate.py it returns unsuccessful . I‚Äôm testing all my tasks of main.py with Postman it returns successful.
My query is that how the tasks get evaluated and do i need to change my variables in main.py ? And what are the other things i have to change.
Also plss update evaluate.py fie with phase B tasks
@s.anand
@carlton
@Saransh_Saini

[2025-02-13T03:29:31.245Z] Carlton D'Silva (@carlton: Regular)
@22f3001777
Yes there will be one more session today (13th Feb) at usual time 8pm to 10pm
Kind regards

[2025-02-13T04:09:50.378Z] Trebhuvan SB (@trebhuvansb)
Hi instructors and TAs,
For the different tasks in Phase B, I don‚Äôt have a clear idea of what type of a response you expect.
eg.
Run a SQL query on a SQLite or DuckDB database & Extract data from (i.e. scrape) a website & Transcribe audio from an MP3 file - Do you want the query‚Äôs response on an output file like A10? or as a response?
I understand that these are broad problems you except us to solve, but it would be helpful to know what type of response you would require.
Thanks,
Trebhuvan

[2025-02-13T04:45:34.403Z] Durga Prasad (@22f3001307)
Hi,
Pls tell us how to use evaluate.py script to check our codes

[2025-02-13T04:49:57.160Z] Carlton D'Silva (@carlton: Regular)
Output specifications will be detailed in the ‚Äútask‚Äù sent to the endpoint.
Phase B is meant to be vague because if you can solve it, without an elaborate and gratuitous use of gpt function calling, then you can actually solve
all tasks using the same function
!
Kind regards

[2025-02-13T04:54:35.243Z] Pradeep Mondal (@21f2000709)
Okay sure!! Ping me when you require to generate‚Ä¶

[2025-02-13T05:05:17.862Z] Tanush Tambe (@22f3002248)
Hello sir,
Is yesterday‚Äôs session not uploaded to YouTube yet ?
I couldn‚Äôt find it in calendar either‚Ä¶ It will be very helpful if you (or anyone else) could provide yesterday session‚Äôs recording‚Äôs link‚Ä¶

[2025-02-13T05:14:41.733Z] Pradeep Mondal (@21f2000709)
21f2000709:
I tried cutting it down further but it is affecting the functionality, this is the best I can do, i.e., 610 mb
@carlton
@Jivraj
will it be ok? Actually I developed it in a way that require some of the essential dependencies and at this point of time it would be dangerous to alter the way of handling it as I am running short of AIProxy Token credits.
Earlier when I asked this:
21f2000709:
Any tentative size cutoff for the docker image?
I could have altered my way of handling dependencies but at that point of time there was no clear numbers.
I request you to please allow this time around with this size‚Ä¶

[2025-02-13T05:45:48.461Z] Yogesh (@Yogesh1)
@carlton
Could you please consider extending the submission date of Assignment 5 (it is 16th Feb right now). We are very busy with the project.
And assignment 6 submission date is much later: 9th of March.

[2025-02-13T06:01:13.675Z] Shreyan Chaubey (@thinkmachine)
@carlton
+1 Agreed, a relaxation in deadline will be a boon for students who‚Äôve taken up other projects this term.

[2025-02-13T06:08:33.630Z] Trebhuvan SB (@trebhuvansb)
usage of langchain is allowed?

[2025-02-13T06:26:05.592Z] Pradeep Mondal (@21f2000709)
It will be extended,
@carlton
mentioned it in a TA session already.

[2025-02-13T06:53:05.419Z] Jivraj Singh Shekhawat (@Jivraj: Course TA)
Hi
@Rishabh2
What exactly you mean by variables?  only one argument is required for running
evaluate.py
that‚Äôs an email address.
You need to download both
evaluate.py
and
datagen.py
in same folder and then execute
evaluate.py
using uv.
uv run evaluate.py --email $any_email
.
For phase B
Project 1 - LLM-based Automation Agent - Discussion Thread [TDS Jan 2025]
Tools in Data Science
Output specifications will be detailed in the ‚Äútask‚Äù sent to the endpoint.
Phase B is meant to be vague because if you can solve it, without an elaborate and gratuitous use of gpt function calling, then you can actually solve all tasks using the same function !
Kind regards
Kind regards

[2025-02-13T06:59:18.975Z] Jivraj Singh Shekhawat (@Jivraj: Course TA)
610 Mb‚Äôs is good size, no need to worry, it will be evaluated.

[2025-02-13T07:14:49.349Z] Saransh Saini (@Saransh_Saini: Course TA)
Hi
@23f1002382
This is the classic case where you use Prompt engineering to solve your problems. I assume you have already achieved your answers, but I want to clarify this for someone who is facing this problem.
The thing is GPT-4o-mini is intelligent enough to understand what kind of task you are asking it do, and extracting Credit Card info from an image is one of the many prohibited tasks.
What you can do is,
try to fool it using itself.
Just ask ChatGPT to generate a prompt that would be capable of fooling itself into extracting out that credit card info. I was capable of doing it after pretending to be a working on a Cyber Security project, and other fake details which ChatGPT itself provided me with.

[2025-02-13T07:17:30.842Z] JAHAR KUMAR PAUL (@21f3000512)
@carlton
. I cannot send requests to
https://aiproxy.sanand.workers.dev/openai/v1
. Getting  $RateLimitError: Error code: 429 - {‚Äòmessage‚Äô: 'On 2025-02 you used $2.0003758999999954, exceeding
2'}
. Looks like I used all of my credit . What can I do now ? Project is also Incomplete.

[2025-02-13T07:17:41.320Z] Saransh Saini (@Saransh_Saini: Course TA)
Try creating a better prompt for this task.
Hint: Ask it to recheck certain similar looking digits.

[2025-02-13T07:40:40.412Z] Jivraj Singh Shekhawat (@Jivraj: Course TA)
After submitting docker image through, it will be pulled and our token will be used.
Things to be checked at your end.
1.
podman run -e AIPROXY_TOKEN=$AIPROXY_TOKEN -p8000:8000 $IMAGE_NAME
works fine
2.  Above command will start 8000 server so use evaluate.py to test if things are working as expected.
Kind regards.
Jivraj

[2025-02-13T07:44:28.965Z] Jivraj Singh Shekhawat (@Jivraj: Course TA)
Hi
@JoelJeffrey
What you did wrong and how did you correct it?

[2025-02-13T07:47:38.549Z] Joel Jeffrey (@JoelJeffrey)
I think there was something wrong with the way the code was getting inputs (keys). I just rewrote that part and it worked

[2025-02-13T07:50:10.661Z] Jivraj Singh Shekhawat (@Jivraj: Course TA)
Hi
@22f3001307
Provide required write permissions to
/data
folder. We will also discuss this issue regarding permissions in initial part of today‚Äôs session.
Kind regards

[2025-02-13T07:55:57.725Z] Tanush Tambe (@22f3002248)
Hello sir,
Is yesterday‚Äôs session not uploaded to YouTube yet ?
I couldn‚Äôt find it in calendar either‚Ä¶

[2025-02-13T08:00:18.511Z] Pradeep Mondal (@21f2000709)
Command to run the image in the docs, seemed to have some error,
The command:
podman run $IMAGE_NAME -e AIPROXY_TOKEN=$AIPROXY_TOKEN -p 8000:8000
gives the error:
crun: executable file `-e` not found in $PATH: No such file or directory: OCI runtime attempted to invoke a command that was not found
However the correct command seems to be:
podman run -e AIPROXY_TOKEN="$AIPROXY_TOKEN" -p 8000:8000 $IMAGE_NAME
This works totally fine.
@Jivraj

[2025-02-13T08:10:36.247Z] Andrew David (@23f1002382)
nvm i can laugh nw xD

[2025-02-13T08:25:27.022Z] Pradeep Mondal (@21f2000709)
One final question
@Jivraj
@carlton
, will our projects be evaluated with our
AIPROXY_TOKEN
or a different one.
Because my project is done but for evaluation if my
AIPROXY_TOKEN
is used, it might be out of credits.

[2025-02-13T08:36:10.341Z] Yogesh (@Yogesh1)
Thanks. Do you know the new date?

[2025-02-13T08:57:25.731Z] Pradeep Mondal (@21f2000709)
That wasn‚Äôt said, but it was not this weekend for sure.

[2025-02-13T09:14:14.569Z] Maulik Dang (@23f2001975)
my automation is happening and prompt distribution too but it just isnt able to pass any test after 1st in evaluation.py did someone else face same problem if yes then how to solve it please help

[2025-02-13T09:24:19.052Z] Guddu Kumar Mishra  (@22f3001315)
actually that easyocr is directly sending the clear text(no confusion) to llm and llm is just extracting the  exact numbers from it .

[2025-02-13T10:04:26.644Z] Maulik Dang (@23f2001975)
[quote=‚Äú23f2001975, post:211, topic:164277, full:true‚Äù]
@s.anand
@carlton
While running the evaluation.py i am facing several issues because my output isnt strictly adhering sometimes to it will the checking be on such a basis only
for example in A3
EXPECTED:
129
RESULT:
‚Äú129‚Äù
this is the error i get while it is the function in eval.py checking problem as it gets response as text and doesnt strip (‚Äú‚Äù)
Please guide what should i do

[2025-02-13T10:18:32.032Z] Jivraj Singh Shekhawat (@Jivraj: Course TA)
21f2000709:
podman run -e AIPROXY_TOKEN=‚Äú$AIPROXY_TOKEN‚Äù -p 8000:8000 $IMAGE_NAME
Yes this is correct command, we will update in project page.

[2025-02-13T10:22:50.807Z] Jivraj Singh Shekhawat (@Jivraj: Course TA)
Project 1 - LLM-based Automation Agent - Discussion Thread [TDS Jan 2025]
Tools in Data Science
After submitting docker image through, it will be pulled and our token will be used.
Things to be checked at your end.
1. podman run -e AIPROXY_TOKEN=$AIPROXY_TOKEN -p8000:8000 $IMAGE_NAME works fine
2.  Above command will start 8000 server so use evaluate.py to test if things are working as expected.
Kind regards.
Jivraj

[2025-02-13T10:25:17.421Z] Vikram Suriyanarayanan (@vikramjncasr)
@Jivraj
sir I get this error
but my app.py is able to get the server running on localhost and not on 0.0.0.
image
1014√ó190 18.2 KB
could you please help ?

[2025-02-13T10:27:23.392Z] Durga Prasad (@22f3001307)
When i am trying evaluate the code, I am getting the following error
Traceback (most recent call last):
  File "/var/folders/rj/z_3b8hl51558519w90k5hp600000gn/T/evaluateyea70I.py", line 20, in <module>
    from datagen import (
    ...<9 lines>...
    )
ModuleNotFoundError: No module named 'datagen'
can someone tell me what i should do?
@carlton
@Jivraj
@Saransh_Saini

[2025-02-13T10:28:13.927Z] Jivraj Singh Shekhawat (@Jivraj: Course TA)
@22f3001307
Install datagen.py in the same folder from where you are executing evaluate.py.
@vikramjncasr
Check how you are executing, use uv or else install required modules globally
Kind regards

[2025-02-13T10:33:05.878Z] Durga Prasad (@22f3001307)
Sir,
the folder already exists in that folder
besides, I am using
OPENAI_API_KEY=$AIPROXY_TOKEN uv run https://raw.githubusercontent.com/sanand0/tools-in-data-science-public/tds-2025-01/project-1/evaluate.py
from Anand sir‚Äôs page to run the code in my system

[2025-02-13T10:39:36.193Z] Vikram Suriyanarayanan (@vikramjncasr)
Sir would the belowformat be ok when you evaluate ?
image
985√ó211 24.1 KB

[2025-02-13T10:40:54.014Z] Vikram Suriyanarayanan (@vikramjncasr)
But when I use podman i keep getting errror.

[2025-02-13T10:58:35.935Z] Lovepreet Singh (@24f2006061)
Hello,
Can anyone please reset my AIProxy limit. I am getting this error, {‚Äúdetail‚Äù:‚ÄúAgent error: 429 Client Error: Too Many Requests for url:
https://aiproxy.sanand.workers.dev/openai/v1/chat/completions
‚Äù}
Thank you.

[2025-02-13T11:09:48.608Z] Arya Agrahari  (@22f3002771)
i am getting unauthorized error in A9 again and again, i have pasted my code if someone can help please look into this.
# /// script
# requires-python = ">=3.11"
# dependencies = [
#   "numpy",
#   "httpx",
#   "fastapi",
# ]
# ///

import httpx
import numpy as np
import datetime
import os

from fastapi import HTTPException

now = datetime.datetime.now()

OPENAI_API_KEY = os.environ["AIPROXY_TOKEN"]
OPENAI_API_URL = "http://aiproxy.sanand.workers.dev/openai/v1/embeddings"

# async def get_similarity_from_embeddings(emb1: list[float], emb2: list[float]) -> float:
def get_similarity_from_embeddings(emb1: list[float], emb2: list[float]) -> float:
    # """Calculate cosine similarity between two texts."""
    # emb1 = await embed(text1)
    # emb2 = await embed(text2)
    return float(np.dot(emb1, emb2) / (np.linalg.norm(emb1) * np.linalg.norm(emb2)))

# async def embed_list(text_list: list[str]) -> list[float]:
async def embed_list(text_list: list[str]) -> list[float]:
    OPENAI_API_KEY = os.environ["AIPROXY_TOKEN"]
    OPENAI_API_URL = "http://aiproxy.sanand.workers.dev/openai/v1/embeddings"
    """Get embedding vector for text using OpenAI's API."""
    try:
        async with httpx.AsyncClient() as client:
            # with httpx.AsyncClient() as client:
            response = await client.post(
                # response = httpx.post(
                OPENAI_API_URL,
                headers={"Authorization": f"Bearer {OPENAI_API_KEY}"},

                json={"model": "text-embedding-3-small", "input": text_list},
            )
        # print(f'{response.json()["data"][0]["embedding"]}')
        emb_list = [emb["embedding"] for emb in response.json()["data"]]
        print(f"Number of embeddings returned = {len(emb_list)}")
        return emb_list

    except KeyError as e:
        print(f"INSIDE EMBED_LIST IN A9. KeyError occurred while querying GPT: {e}")
        raise HTTPException(status_code=400, detail=str(e))

    except Exception as e:
        print(f"INSIDE EMBED_LIST IN A9. General Error while querying gpt: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

def most_similar(embeddings):
    # Extract the phrases and their corresponding embeddings
    phrases = list(embeddings.keys())
    emb_values = list(embeddings.values())

    # Initialize variables to track the maximum similarity
    max_similarity = -1  # Start with the smallest possible similarity value
    most_similar_pair = None

    # Compute cosine similarity between each pair of embeddings
    for i in range(len(emb_values)):
        for j in range(i + 1, len(emb_values)):  # Avoid repeating pairs
            similarity = get_similarity_from_embeddings(emb_values[i], emb_values[j])
            if similarity > max_similarity:
                max_similarity = similarity
                most_similar_pair = (phrases[i], phrases[j])

    return most_similar_pair

# async def get_similar_comments(input_file_path: str, output_file_path: str):
async def get_similar_comments(input_file_path: str, output_file_path: str):
    print(f"Reading the input file: {input_file_path}")
    with open(input_file_path, "r") as file:
        comments = file.readlines()

    print(f"Embedding the comments")
    # embeddings = await embed_list(comments)
    embeddings = await embed_list(comments)
    embed_dict = dict(zip(comments, embeddings))
    most_similar_pair = most_similar(embed_dict)
    print(f"Most similar comments: {most_similar_pair}")

    with open(output_file_path, "w") as file:
        for comment in most_similar_pair:
            file.write(f"{comment.strip()}\n")
        # file.write(f"Most similar comments: {most_similar_pair}")

if __name__ == "__main__":
    # import asyncio

    input_file_path = "/data/comments.txt"
    output_file_path = "/data/similar_comments.txt"
    # asyncio.run(get_similar_comments(input_file_path, output_file_path))
    get_similar_comments(input_file_path, output_file_path)

[2025-02-13T11:30:20.720Z] Ansh bansal (@23f2004752)
@Jivraj
@carlton
sir can you take my doubt in today‚Äôs session please , i have successfully run docker server but endpoints are not working‚Ä¶
Screenshot 2025-02-13 165912
1917√ó1024 124 KB
If anyone have knowledge about this , please help

[2025-02-13T11:32:12.216Z] Adithya S (@Adithya)
How did u resolve the issue?
@JoelJeffrey

[2025-02-13T11:38:28.558Z] Adithya S (@Adithya)
I am also facing the same issue.
Evaluation Output:
HTTP Request: POST https://aiproxy.sanand.workers.dev/openai/v1/embeddings "HTTP/1.1 401 Unauthorized"

üî¥ A9 failed: 'data'

‚ùå A9 FAILED
I sense ‚ÄòAuthentication Problem‚Äô happens only with the evaluation script, as the curl requests seems to work fine.
INFO:httpx:HTTP Request: POST https://aiproxy.sanand.workers.dev/openai/v1/embeddings "HTTP/1.1 200 OK"
INFO:     127.0.0.1:60849 - "POST /run?task=%60%2Fdata%2Fcomments.txt%20contains%20a%20list%20of%20comments,%20one%20per%20line.%20Using%20embeddings,%20find%20the%20most%20similar%20pair%20of%20comments%20and%20write%20them%20to%20%2Fdata%2Fcomments-similar.txt,%20one%20per%20line HTTP/1.1" 200 OK
Any views?
@carlton
@Jivraj

[2025-02-13T12:36:04.971Z] Vidushi Singh (@vidushi)
@Jivraj
@carlton
Sir i keep getting this error
image
671√ó109 8.64 KB
even though i have downloaded the packages globally and tried installing them by making a venv but nothing seems to work please help

[2025-02-13T12:56:58.706Z] Udipth (@Udipth)
what is the base url?

[2025-02-13T13:16:47.743Z] Andrew David (@23f1002382)
use your api key guys

[2025-02-13T13:17:52.970Z] Arya Agrahari  (@22f3002771)
we are using that only bro, only for A9 it says unauthorized

[2025-02-13T13:18:10.933Z] Andrew David (@23f1002382)
network mapping or something, even im working that out

[2025-02-13T13:18:26.065Z] Anvitha (@AnvithaV)
Even i am facing the same problem. I am unable to resolve it ,i tried many ways.
could anyone please help

[2025-02-13T13:20:38.830Z] Andrew David (@23f1002382)
2 ways, try command line package installing, or inside venv, try which python,etc and make paths reconcile, or inside venv, uv pip install , if that doesn‚Äôt work, inside venv pip install

[2025-02-13T13:37:48.723Z] Ansh bansal (@23f2004752)
thanks , already it work out

[2025-02-13T15:44:57.509Z] Vikram Suriyanarayanan (@vikramjncasr)
@Jivraj
@carlton
sir please help
When I am downloading the data folder after processing datagen.py , it is trying to download in root folder and it is facing permission error . how can we overcome this ?
needs sudo permission all the time‚Ä¶
image
1368√ó124 19.9 KB

[2025-02-13T15:58:57.713Z] Huzaifa Faizee (@huzaifa)
Hello Sir
@carlton
@Jivraj
What are implications on missing the project 1.
Due to some personal reasons I wasn‚Äôt able to start any work on my project 1. It seems difficult for me to complete it.
Could you please tell what will be the implications of missing it. Will I in anyway be able to cover up and pass in the subject doing future assignments and projects?
Thank you
PS: This isn‚Äôt any request to extend dates. I accept my fault and respect the dates provided by the team.

[2025-02-13T16:55:25.125Z] Ayush Kumar Shaw  (@23f2001286)
Sir I haven‚Äôt initaiated the podman earlier.
Now when i try to use podman using the wsl via the code ‚Äúsudo apt install -y podman‚Äù it is asking for the password‚Ä¶
The problem is:
I haven‚Äôt set any password for podman earlier.
Though it is asking for password but it is not taking any input.(ie I am unable type anything there).
what should I am supposed to do‚Ä¶
image
1612√ó359 21.3 KB

[2025-02-13T17:52:50.211Z] Vihaan Verma (@Vihaanv07)
@s.anand
@Jivraj
I think the evaluation.py test case is broken for A8 because I can manually see more folders and markdown files than the expected case output of A8 evaluation. And also is there any evaluation file for Part B

[2025-02-13T18:04:07.546Z] Shreya Khantal (@23f2004094)
password are not visible in wsl when typed, just type and enter if it matches, the process will continue

[2025-02-13T18:22:04.034Z] Sarthak Gupta  (@22f1000376)
Sir If possible please extend the Project deadline.

[2025-02-13T19:01:28.625Z] Thereasa Joe J (@23f3004024)
same error the execution is correct but format.md file is not modified with correct markdown format

[2025-02-13T19:53:34.059Z] Shashannk (@23f2003413)
@carlton
@Jivraj
can u please upload the video that was recorded on 12th Feb, as I am able to view only the video that was last recorded on 11th Feb (3 hrs 57 mins video). As I am doing the project completely from the recorded videos, please post those videos in youtube at the earliest.

[2025-02-13T20:43:28.497Z] Jivraj Singh Shekhawat (@Jivraj: Course TA)
Hi
@23f2003413
Because of some technical issues we could not record 12 Feb session. That was doubt clearing session regrading project1.
Kind regards

[2025-02-14T00:36:17.755Z] Ansh bansal (@23f2004752)
Can we submit project number of times before deadline‚Ä¶

[2025-02-14T02:49:04.476Z] Ayush Kumar Shaw  (@23f2001286)
thanks for you feedbacak I have figured it out! Thanks it means a lot‚Ä¶

[2025-02-14T03:05:23.382Z] Ayush Kumar Shaw  (@23f2001286)
A silly Doubt though but still a doubt!
Could we create an image first of our project in initial stage(ie the my ‚Äúapp.py‚Äù is not completely ready) but I have build an docker image including the app.py and other dependencies.
Should I give the same url now and then carry on updating the app.py
Or, Should first complete and then upload in the form!
plz reply!!

[2025-02-14T05:30:00.714Z] B Varun karthik (@23f2001305)
Can you send the link for the video on 11th Feb?

[2025-02-14T05:49:41.750Z] Shambhavi  (@24f2003130)
How did you resolve the file cannot be found error?

[2025-02-14T06:55:15.716Z] shivam dubey (@23f1002279)
image
872√ó550 16.5 KB
pls help with this error

[2025-02-14T07:01:23.751Z] Abhay Sharma (@sharma_abhay)
Sir, could you please mention the title of youtube videos in which the project session are covered?

[2025-02-14T07:18:15.478Z] Arulvadivelan V (@23f2005419)
Hi,
When yesterday‚Äôs recorded video will be uploaded in youtube?

[2025-02-14T07:34:01.905Z] Shashannk (@23f2003413)
Thanks for the prompt reply
@Jivraj
. I have done the project setup till whatever was covered on the 11th Feb session. I am not able to proceed further as I have no clue on how to work on this. Can you please help me out as it would mean a lot.

[2025-02-14T07:39:06.932Z] shivam dubey (@23f1002279)
@carlton
@23f1002382

[2025-02-14T07:40:07.303Z] Shashannk (@23f2003413)


[2025-02-14T07:40:32.531Z] Carlton D'Silva (@carlton: Regular)
Are you subscribed to the TDS channel? If you were it would notify you immediately when it was uploaded. (10am this morning).
Please subscribe to the channel. It was also on the main page for TDS.
https://tds.s-anand.net/#/README
YouTube
Tools in Data Science
Share your videos with friends, family, and the world
Kind regards

[2025-02-14T07:42:08.309Z] Arulvadivelan V (@23f2005419)
Thanks sir, Now I subscribed to the channel.

[2025-02-14T07:45:02.221Z] Shashannk (@23f2003413)
Hi
@carlton
sir! Is this video (Week-5 Session-3) the continuation video from the previous session (Week-5 Session-1), since the Session-2 video has not been recorded and uploaded. I am totally relying on these videos to complete the project sir. Please help me out!

[2025-02-14T08:04:25.977Z] Andrew David (@23f1002382)
offical answer is you dont, you let run it in docker and it would apparently work , im not there yet, bus as of of now , create your docker image and start testing there

[2025-02-14T08:08:24.668Z] Andrew David (@23f1002382)
The deadline is at 11:59 pm right Saturday? Feb 15th? Google Standard Time?

[2025-02-14T08:17:41.120Z] Jivraj Singh Shekhawat (@Jivraj: Course TA)
Yes feb 15 11:59 PM indian standard time.

[2025-02-14T08:21:27.720Z] Jivraj Singh Shekhawat (@Jivraj: Course TA)
Hi
@23f2003413
Session 3 was continuation of session1.
Session 2 was DCS(doubts clearing session)
Kind regards

[2025-02-14T08:25:42.250Z] Shashannk (@23f2003413)
Got it. Thank you sir!

[2025-02-14T08:33:06.508Z] Arulvadivelan V (@23f2005419)
Hi
@Jivraj
,
@carlton
,
@Saransh_Saini
sir,
I‚Äôm getting the following error while post mapping, I couldn‚Äôt able to fix it.
I‚Äôm getting status code as 400 from the llm api response. How to fix it sir?
"json": {
        "message": "Invalid JSON body: SyntaxError: Unexpected token 'm', \"model=gpt-\"... is not valid JSON"
    }

[2025-02-14T08:35:17.405Z] Jivraj Singh Shekhawat (@Jivraj: Course TA)
There is some problem with the json that you are using.
Try to debug it with GPT.

[2025-02-14T08:36:01.337Z] Jivraj Singh Shekhawat (@Jivraj: Course TA)
week5 session 1 and session3

[2025-02-14T08:38:10.454Z] Ayush Kumar Shaw  (@23f2001286)
image
929√ó427 11.7 KB
Is someone else are also getting this kind of error messages‚Ä¶
I have a low end system, then shifted to high one then again this popped up‚Ä¶
Does anyone know how to come over this‚Ä¶

[2025-02-14T09:23:07.838Z] DIGVIJAYSINH SANDEEPSINH CHUDASAMA (@21f2000588)
Hello
@carlton
@Jivraj
@Saransh_Saini
sir, I have implemented the code for B3 & B6 but unfortunately as per the instructions given in project for B3 & B6 ‚Äî
B6
. Extract data from (i.e. scrape) a website
B3
. Fetch data from an API and save it
They are almost similar and it‚Äôs getting confusing in both cases, it‚Äôs given output based on B3 and not reading the input for B6, so could you please help me out with this?
Is anyone else facing this or a similar issue?

[2025-02-14T09:27:49.421Z] Jivraj Singh Shekhawat (@Jivraj: Course TA)
Two solutions
give proper permissions.
use docker containers this is what we will test on.
I would prefer 2nd approach

[2025-02-14T09:31:58.136Z] Jivraj Singh Shekhawat (@Jivraj: Course TA)
For B tasks use LLM to write code on the fly and execute it, use better prompts. In evaluation script detailed task will be provided with what data needs to be scraped, endpoints, parameters, etc.

[2025-02-14T09:45:19.679Z] Andrew David (@23f1002382)
{‚Äòerror‚Äô: {‚Äòmessage‚Äô: ‚ÄúInvalid ‚Äòtools[6].function.description‚Äô: string too long. Expected a string with maximum length 1024, but got a string with length 4384 instead.‚Äù, ‚Äòtype‚Äô: ‚Äòinvalid_request_error‚Äô, ‚Äòparam‚Äô: ‚Äòtools[6].function.description‚Äô, ‚Äòcode‚Äô: ‚Äòstring_above_max_length‚Äô}, ‚ÄòmonthlyCost‚Äô: 0.08569882000000002, ‚Äòcost‚Äô: 0, ‚ÄòmonthlyRequests‚Äô: 82}
i cant send long prompts then what is the point?

[2025-02-14T09:45:59.531Z] Andrew David (@23f1002382)
local llm also we cant use you because you have some limit on file size, we send long prompt also it doesn‚Äôt work xD . What do we do?
@s.anand
@carlton
@Jivraj
@anybodywhowouldatleastreplyONCE

[2025-02-14T10:04:32.618Z] Saransh Saini (@Saransh_Saini: Course TA)
Hi,
If you read these questions carefully then they are not similar, one is asking you to extract data from a webpage, meaning you have to do something related to the HTML code. And the other is simply sending a request to a given endpoint.

[2025-02-14T11:13:31.475Z] Telvin Varghese (@22f2001640)
Hi
@carlton
@Saransh_Saini
@Jivraj
,
In task A6
Find all Markdown (
.md
) files in
/data/docs/
. For each file, extract the first occurrance of each H1 (i.e. a line starting with
#
). Create an index file
/data/docs/index.json
that maps each filename (without the
/data/docs/
prefix) to its title (e.g.
{"README.md": "Home", "path/to/large-language-models.md": "Large Language Models", ...}
).
Here expected output JSON ‚Äúkey‚Äù is file name or file path without prefix /data/docs/ as prompt is bit confusing . when ‚Äúpath/to/large-language-models.md‚Äù is given in example is actually referring to file path or filename itself is ‚Äúpath/to/large-language-models.md‚Äù.

[2025-02-14T11:44:32.114Z] Saransh Saini (@Saransh_Saini: Course TA)
This can easily be checked by runing the evaluate.py file.
Anyways, a file present in data/docs/folder_a/folder_b/md_file should be folder_a/folder_b/md_file as key.

[2025-02-14T11:48:06.753Z] Tanush Tambe (@22f3002248)
hey
@23f2001975
did you find the solution to this problem ?
i am facing the exact same issue

[2025-02-14T12:44:44.847Z] Avnish Jajodia (@22f3001777)
@carlton
Sir, my token limit has crossed the $1 limit. Will I receive new limit or a fresh token ? I still need to complete my project.
Thank you

[2025-02-14T12:50:06.658Z] Andrew David (@23f1002382)
/data/credit-card.txt
EXPECTED:
30091429521159
RESULT:
3009142952159
{‚Äòrole‚Äô: ‚Äòassistant‚Äô, ‚Äòcontent‚Äô: ‚Äò3009142952159‚Äô, ‚Äòrefusal‚Äô: None} if LLM is giving wrong output. I hope y‚Äôall look into edge cases. Some people tried really hard. to prompt it xD
.
You can check the logs
(venv) @ANDIECOOLER2 ‚ûú /workspaces/TDS-Project-1/app (checking-with-open-ai) $ uv run evaluate.py
üü° Running task: Install `uv` (if required) and run the script `https://raw.githubusercontent.com/ANdIeCOOl/TDS-Project1-Ollama_FastAPI-/refs/heads/main/datagen.py`
with `23f1002382@ds.study.iitm.ac.in` as the only argument
HTTP Request: POST
http://localhost:8000/run?task=
Install+`uv`+(if+required)+and+run+the+script+`https%3A%2F%2Fraw.githubusercontent.com%2FANdIeCOOl%2FTDS-Project1-Ollama_FastAPI-%2Frefs%2Fheads%2Fmain%2Fdatagen.py`
with+`23f1002382%40ds.study.iitm.ac.in`+as+the+only+argument
‚ÄúHTTP/1.1 200 OK‚Äù
HTTP 200 {
‚Äústatus‚Äù: ‚Äúsuccess‚Äù,
‚Äúmessage‚Äù: ‚ÄúTask executed successfully‚Äù
}
HTTP Request: GET
http://localhost:8000/read?path=/data/format.md
‚ÄúHTTP/1.1 200 OK‚Äù
A1 PASSED
10.8.2
Running task: Format the contents of
/data/format.md
using
prettier@3.4.2
, updating the file in-place
HTTP Request: POST
http://localhost:8000/run?task=
Format+the+contents+of+`%2Fdata%2Fformat.md`+using+`prettier%403.4.2`%2C+updating+the+file+in-place
‚ÄúHTTP/1.1 200 OK‚Äù
HTTP 200 {
‚Äústatus‚Äù: ‚Äúsuccess‚Äù,
‚Äúmessage‚Äù: ‚ÄúTask executed successfully‚Äù
}
HTTP Request: GET
http://localhost:8000/read?path=/data/format.md
‚ÄúHTTP/1.1 200 OK‚Äù
A2 PASSED
Running task: The file
/data/dates.txt
contains a list of dates, one per line. Count the number of Wednesdays in the list, and write just the number to
/data/dates-wednesdays.txt
HTTP Request: POST
http://localhost:8000/run?task=The+file+`%2Fdata%2Fdates.txt`+contains+a+list+of+dates%2C+one+per+line.+Count+the+number+of+Wednesdays+in+the+list%2C+and+write+just+the+number+to+`%2Fdata%2Fdates-wednesdays.txt`
‚ÄúHTTP/1.1 200 OK‚Äù
HTTP 200 {
‚Äústatus‚Äù: ‚Äúsuccess‚Äù,
‚Äúmessage‚Äù: ‚ÄúTask executed successfully‚Äù
}
HTTP Request: GET
http://localhost:8000/read?path=/data/dates-wednesdays.txt
‚ÄúHTTP/1.1 200 OK‚Äù
A3 PASSED
Running task: Sort the array of contacts in
/data/contacts.json
by
last_name
, then
first_name
, and write the result to
/data/contacts-sorted.json
HTTP Request: POST
http://localhost:8000/run?task=Sort+the+array+of+contacts+in+`%2Fdata%2Fcontacts.json`+by+`last_name`%2C+then+`first_name`%2C+and+write+the+result+to+`%2Fdata%2Fcontacts-sorted.json`
‚ÄúHTTP/1.1 200 OK‚Äù
HTTP 200 {
‚Äústatus‚Äù: ‚Äúsuccess‚Äù,
‚Äúmessage‚Äù: ‚ÄúTask executed successfully‚Äù
}
HTTP Request: GET
http://localhost:8000/read?path=/data/contacts-sorted.json
‚ÄúHTTP/1.1 200 OK‚Äù
A4 PASSED
Running task: Write the first line of the 10 most recent
.log
file in
/data/logs/
to
/data/logs-recent.txt
, most recent first
HTTP Request: POST
http://localhost:8000/run?task=Write+the+first+line+of+the+10+most+recent+`.log`+file+in+`%2Fdata%2Flogs%2F`+to+`%2Fdata%2Flogs-recent.txt`%2C+most+recent+first
‚ÄúHTTP/1.1 200 OK‚Äù
HTTP 200 {
‚Äústatus‚Äù: ‚Äúsuccess‚Äù,
‚Äúmessage‚Äù: ‚ÄúTask executed successfully‚Äù
}
HTTP Request: GET
http://localhost:8000/read?path=/data/logs-recent.txt
‚ÄúHTTP/1.1 200 OK‚Äù
A5 PASSED
Running task: Find all Markdown (
.md
) files in
/data/docs/
.
For each file, extract the first occurrance of each H1 (i.e. a line starting with
#
).
Create an index file
/data/docs/index.json
that maps each filename (without the
/data/docs/
prefix) to its title
(e.g.
{"README.md": "Home", "path/to/large-language-models.md": "Large Language Models", ...}
)
HTTP Request: POST
http://localhost:8000/run?task=Find+all+Markdown+(`.md`)+files+in+`%2Fdata%2Fdocs%2F`.
For+each+file%2C+extract+the+first+occurrance+of+each+H1+(i.e.+a+line+starting+with+`%23+`).
Create+an+index+file+`%2Fdata%2Fdocs%2Findex.json`+that+maps+each+filename+(without+the+`%2Fdata%2Fdocs%2F`+prefix)+to+its+title
(e.g.+`{‚ÄúREADME.md‚Äù%3A+‚ÄúHome‚Äù%2C+‚Äúpath%2Fto%2Flarge-language-models.md‚Äù%3A+‚ÄúLarge+Language+Models‚Äù%2C+...}`)
‚ÄúHTTP/1.1 200 OK‚Äù
HTTP 200 {
‚Äústatus‚Äù: ‚Äúsuccess‚Äù,
‚Äúmessage‚Äù: ‚ÄúTask executed successfully‚Äù
}
HTTP Request: GET
http://localhost:8000/read?path=/data/docs/index.json
‚ÄúHTTP/1.1 200 OK‚Äù
A6 PASSED
Running task:
/data/email.txt
contains an email message. Pass the content to an LLM with instructions to extract the sender‚Äôs email address, and write just the email address to
/data/email-sender.txt
HTTP Request: POST
http://localhost:8000/run?task=`%2Fdata%2Femail.txt`+contains+an+email+message.+Pass+the+content+to+an+LLM+with+instructions+to+extract+the+sender‚Äôs+email+address%2C+and+write+just+the+email+address+to+`%2Fdata%2Femail-sender.txt`
‚ÄúHTTP/1.1 200 OK‚Äù
HTTP 200 {
‚Äústatus‚Äù: ‚Äúsuccess‚Äù,
‚Äúmessage‚Äù: ‚ÄúTask executed successfully‚Äù
}
HTTP Request: GET
http://localhost:8000/read?path=/data/email-sender.txt
‚ÄúHTTP/1.1 200 OK‚Äù
A7 PASSED
Running task:
/data/credit_card.png
contains a credit card number. Pass the image to an LLM, have it extract the card number, and write it without spaces to
/data/credit-card.txt
HTTP Request: POST
http://localhost:8000/run?task=`%2Fdata%2Fcredit_card.png`+contains+a+credit+card+number.+Pass+the+image+to+an+LLM%2C+have+it+extract+the+card+number%2C+and+write+it+without+spaces+to+`%2Fdata%2Fcredit-card.txt`
‚ÄúHTTP/1.1 200 OK‚Äù
HTTP 200 {
‚Äústatus‚Äù: ‚Äúsuccess‚Äù,
‚Äúmessage‚Äù: ‚ÄúTask executed successfully‚Äù
}
HTTP Request: GET
http://localhost:8000/read?path=/data/credit-card.txt
‚ÄúHTTP/1.1 200 OK‚Äù
/data/credit-card.txt
EXPECTED:
30091429521159
RESULT:
3009142952159
A8 FAILED
HTTP Request: POST
https://aiproxy.sanand.workers.dev/openai/v1/embeddings
‚ÄúHTTP/1.1 200 OK‚Äù
Running task:
/data/comments.txt
contains a list of comments, one per line. Using embeddings, find the most similar pair of comments and write them to
/data/comments-similar.txt
, one per line
HTTP Request: POST
http://localhost:8000/run?task=`%2Fdata%2Fcomments.txt`+contains+a+list+of+comments%2C+one+per+line.+Using+embeddings%2C+find+the+most+similar+pair+of+comments+and+write+them+to+`%2Fdata%2Fcomments-similar.txt`%2C+one+per+line
‚ÄúHTTP/1.1 200 OK‚Äù
HTTP 200 {
‚Äústatus‚Äù: ‚Äúsuccess‚Äù,
‚Äúmessage‚Äù: ‚ÄúTask executed successfully‚Äù
}
HTTP Request: GET
http://localhost:8000/read?path=/data/comments-similar.txt
‚ÄúHTTP/1.1 200 OK‚Äù
A9 PASSED
Running task: The SQLite database file
/data/ticket-sales.db
has a
tickets
with columns
type
,
units
, and
price
. Each row is a customer bid for a concert ticket. What is the total sales of all the items in the ‚ÄúGold‚Äù ticket type? Write the number in
/data/ticket-sales-gold.txt
HTTP Request: POST
http://localhost:8000/run?task=The+SQLite+database+file+`%2Fdata%2Fticket-sales.db`+has+a+`tickets`+with+columns+`type`%2C+`units`%2C+and+`price`.+Each+row+is+a+customer+bid+for+a+concert+ticket.+What+is+the+total+sales+of+all+the+items+in+the+‚ÄúGold‚Äù+ticket+type%3F+Write+the+number+in+`%2Fdata%2Fticket-sales-gold.txt`
‚ÄúHTTP/1.1 200 OK‚Äù
HTTP 200 {
‚Äústatus‚Äù: ‚Äúsuccess‚Äù,
‚Äúmessage‚Äù: ‚ÄúTask executed successfully‚Äù
}
HTTP Request: GET
http://localhost:8000/read?path=/data/ticket-sales-gold.txt
‚ÄúHTTP/1.1 200 OK‚Äù
A10 PASSED
Score: 9 / 10 proof
EDIT CREDIT CARD NUMBERS are 16 digits, so even there is discrepancy

[2025-02-14T12:51:37.874Z] Andrew David (@23f1002382)
usage‚Äô: {‚Äòprompt_tokens‚Äô: 1384,
‚Äòcompletion_tokens‚Äô: 67,
‚Äòtotal_tokens‚Äô: 1451,
‚Äòprompt_tokens_details‚Äô: {‚Äòcached_tokens‚Äô: 0, ‚Äòaudio_tokens‚Äô: 0},
‚Äòcompletion_tokens_details‚Äô: {‚Äòreasoning_tokens‚Äô: 0, ‚Äòaudio_tokens‚Äô: 0, ‚Äòaccepted_prediction_tokens‚Äô: 0, ‚Äòrejected_prediction_tokens‚Äô: 0}},
‚Äòservice_tier‚Äô: ‚Äòdefault‚Äô, ‚Äòsystem_fingerprint‚Äô: ‚Äòfp_13eed4fce1‚Äô,
‚ÄòmonthlyCost‚Äô: 0.5243745800000005,
‚Äòcost‚Äô: 0.004554000000000001
GPT-4o mini
Fine-tuning price
Input:--------------------------> CALCUATION: (1384/10^6)*$0.30 = 0.0004152
$0.30 / 1M tokens
Cached input:
$0.15 / 1M tokens
Output:------------------------->  CALCUATION: (67/10^6)$1.20 = 0.0000804
$1.20 / 1M tokens
Training:
$3.00 / 1M tokens
TOTAL = 0.0004152 + 0.0000804 = 0.0004956
‚Äòcost‚Äô: 0.004554000000000001 MAKE IT MAKE SENSE?
‚Äòtotal_tokens‚Äô: 1451, so only input and completion tokens used?
INFO:     Uvicorn running on
http://0.0.0.0:8000
(Press CTRL+C to quit)
INFO:root:10
INFO:root:Inside run_task with task:
Install
uv
(if required) and run the script
https://raw.githubusercontent.com/ANdIeCOOl/TDS-Project1-Ollama_FastAPI-/refs/heads/main/datagen.py
with
23f1002382@ds.study.iitm.ac.in
as the only argument
INFO:root:PRINTING RESPONSE:::PRINTING RESPONSE:::PRINTING RESPONSE:::
{‚Äòid‚Äô: ‚Äòchatcmpl-B0pChhrBiCN8x8ueL2u57rwQiucl7‚Äô, ‚Äòobject‚Äô: ‚Äòchat.completion‚Äô, ‚Äòcreated‚Äô: 1739536527, ‚Äòmodel‚Äô: ‚Äògpt-4o-mini-2024-07-18‚Äô, ‚Äòchoices‚Äô: [{‚Äòindex‚Äô: 0, ‚Äòmessage‚Äô: {‚Äòrole‚Äô: ‚Äòassistant‚Äô, ‚Äòcontent‚Äô: None, ‚Äòtool_calls‚Äô: [{‚Äòid‚Äô: ‚Äòcall_ULCgfFzpEcnGNditwVwGwRIS‚Äô, ‚Äòtype‚Äô: ‚Äòfunction‚Äô, ‚Äòfunction‚Äô: {‚Äòname‚Äô: ‚Äòinstall_and_run_script‚Äô, ‚Äòarguments‚Äô: ‚Äò{‚Äúpackage‚Äù:‚Äúuv‚Äù,‚Äúargs‚Äù:[‚Äú23f1002382@ds.study.iitm.ac.in‚Äù],‚Äúscript_url‚Äù:‚Äú
https://raw.githubusercontent.com/ANdIeCOOl/TDS-Project1-Ollama_FastAPI-/refs/heads/main/datagen.py
‚Äù}‚Äô}}], ‚Äòrefusal‚Äô: None}, ‚Äòlogprobs‚Äô: None, ‚Äòfinish_reason‚Äô: ‚Äòtool_calls‚Äô}], ‚Äòusage‚Äô: {‚Äòprompt_tokens‚Äô: 1384, ‚Äòcompletion_tokens‚Äô: 67, ‚Äòtotal_tokens‚Äô: 1451, ‚Äòprompt_tokens_details‚Äô: {‚Äòcached_tokens‚Äô: 0, ‚Äòaudio_tokens‚Äô: 0}, ‚Äòcompletion_tokens_details‚Äô: {‚Äòreasoning_tokens‚Äô: 0, ‚Äòaudio_tokens‚Äô: 0, ‚Äòaccepted_prediction_tokens‚Äô: 0, ‚Äòrejected_prediction_tokens‚Äô: 0}}, ‚Äòservice_tier‚Äô: ‚Äòdefault‚Äô, ‚Äòsystem_fingerprint‚Äô: ‚Äòfp_13eed4fce1‚Äô, ‚ÄòmonthlyCost‚Äô: 0.5243745800000005, ‚Äòcost‚Äô: 0.004554000000000001, ‚ÄòmonthlyRequests‚Äô: 217}
@s.anand
How is the usage calculated? Just asking not implying
UPDATE:  ITS EVEN MORE CHEAPER, I gave benefir of doubt better its much cheaper? ???
Screenshot 2025-02-14 183844
1695√ó879 52 KB

[2025-02-14T13:02:49.800Z] Carlton D'Silva (@carlton: Regular)
You can continue to $2. Then you would need to ask for a new token.

[2025-02-14T13:07:11.530Z] Divjot Singh (@24ds3000061)
@carlton
@Jivraj
please upload recording of TDS Week 5 - Session 2. Only recordings of session 1 & 3 have been uploaded.

[2025-02-14T13:28:09.267Z] Andrew David (@23f1002382)
github.com
GitHub - ANdIeCOOl/TDS-Project-1
Contribute to ANdIeCOOl/TDS-Project-1 development by creating an account on GitHub.
DONE WITH A TASK , you have to create DOCKER IMAGE THOUGH < HAVE ENV file with keys , check the key value pair names, an cheers guy , we all get 9 marks hopefully

[2025-02-14T13:29:17.644Z] SAKSHI PATHAK (@Sakshi6479)
sir using prompt method also i am having the error please provide a step wise solution so then i can make functions accordingly.
#/// Scirpt
# requires-python = ">=3.13"
# dependencies = [
#     "fastapi",
#     "uvicorn",
#     "requests",
# ]
#///

from fastapi import FastAPI, HTTPException, status
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse

import requests
import os
import json
from subprocess import run

app = FastAPI()

response_format = {
    "type": "json",
    "json_schema": {
        "name": "taks_runner",
        "schema": {
            "type": "object",
            "required": ["python_dependencies","python_code"],
            "properties": {
                "python_code": {
                    "type": "string",
                    "description": "Python code to perform the task"
                },
                "python_dependencies": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "module": {
                                "type": "string",
                                "description": "Name of the python module"
                            }
                        },
                        "required": ["module"],
                        "additionalProperties": False
                    }
            }
        }
    }
}
}

primary_prompt = """
                You are an automated agent, so generate python code that does the specified task.
                Assume that uv and python are pre-installed.
                Assume that code you generate will be executed inside a docker container.
                Inorder to perform any task if some python package is required to install, provide name of those modules.
"""

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["GET", "POST"],
    allow_headers=["*"],
)

AIPROXY_TOKEN = os.getenv("AIPROXY_TOKEN")
headers = {
    "Content-Type": "application/json",
    "Authorization": f"Bearer {AIPROXY_TOKEN}"
}

@app.get("/")
def home():
    return {"welcome to the task runner"}
@app.post("/run")
def task_runnner(task: str):
    url = "https://aiproxy.sanand.workers.dev/openai/v1/chat/completions"
    data = {
        "model": "gpt-4o-mini",
         "messages": [
             {
              "role": "user",
              "content": task
              },
              {
                "role": "system",
                "content": f"""{primary_prompt}"""
            }
         ],
         "response_format": response_format
    }

    response = requests.post(url=url, headers=headers, json=data)
    r = response.json()

    return r

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
Screenshot 2025-02-14 185820
1945√ó1484 229 KB
@carlton
,
@Saransh_Saini
,
@Jivraj

[2025-02-14T13:29:19.598Z] Saniya Naaz (@23f2002592)
For as task description like this
Write the # of Thursdays in
/data/extracts.txt
into
/data/extracts-count.txt
I have given the prompt in such detail to the LLM but it is still not able to understand the task because of the ‚Äú#‚Äù symbol. The task is getting truncated even before it reaches to the LLM.
Can anyone help me on this because I have tried so many things to fix this but nothing seems to help.

[2025-02-14T13:39:06.561Z] Arulvadivelan V (@23f2005419)
Hi
@Jivraj
,
@carlton
sir,
I have created a docker file and run the application but it‚Äôs throwing error for
A2 task
No such file or directory: ‚Äònpx‚Äô
Do i need give the node install in docker file?

[2025-02-14T13:41:01.000Z] Carlton D'Silva (@carlton: Regular)
Hash is just another way of writing ‚Äúnumber‚Äù

[2025-02-14T13:51:49.280Z] Ayush Kumar Shaw  (@23f2001286)
@carlton
@Jivraj
sir i have tried to solve the A1. when I want to check the solution we are asked for the datagen module as the evaluate.py have
‚Äô
''from datagen import (
    get_markdown,
    get_dates,
    get_contacts,
    get_logs,
    get_docs,
    get_email,
    get_credit_card,
    get_comments,
    get_tickets,
)
'''
so do we need to download the datagen.py in the local system first‚Ä¶
Or it should be the part of the automation only‚Ä¶

[2025-02-14T13:53:07.372Z] Abhay Sharma (@sharma_abhay)
I am getting internal server error for task A1, I have been trying for a long time. It may be possible that i have issues with my ai_proxy token thus tell how to properly set the taken.

[2025-02-14T14:05:45.308Z] Saniya Naaz (@23f2002592)
Yes I know that but LLM does not know that # indicates number. And no prompt is fixing this issue because the task has to be passed as query parameter and by the time LLM reads the task, it is already half gone due to #.

[2025-02-14T14:13:13.898Z] B Varun karthik (@23f2001305)
Where to find AIProxy token from?

[2025-02-14T14:16:15.399Z] Daksh Agarwal (@daksh76)
what if we are out of token sir how do we complete our project then?

[2025-02-14T14:17:20.568Z] Daksh Agarwal (@daksh76)
could u share your code once i think you should explicitly try to install npx in your code

[2025-02-14T14:19:01.883Z] Daksh Agarwal (@daksh76)
23f1002382:
ANDIECOOLER2
could you help me out with q2?

[2025-02-14T14:19:08.253Z] B Varun karthik (@23f2001305)
Can you tell me where to get the AIPROXY Token from and also are u able to execute docker image push command it keeps showing as an error to me

[2025-02-14T14:19:40.681Z] Arulvadivelan V (@23f2005419)
def format_with_prettier(file_path:str, prettier_version:str):
    if file_path and os.path.exists(file_path):
        print('Path exisit - will perform prettier')
        subprocess.run(["npx", f"prettier@{prettier_version}", "--write", file_path])
    else:
        raise FileNotFoundError()
This is my code

[2025-02-14T14:21:56.574Z] Daksh Agarwal (@daksh76)
this isnt also working are you sure its right?

[2025-02-14T14:22:42.231Z] Daksh Agarwal (@daksh76)
image
1027√ó917 28.1 KB

[2025-02-14T14:24:13.838Z] Arulvadivelan V (@23f2005419)
okay but in my docker image when i tried to run that in local, its asking for npx and it doesnt work

[2025-02-14T14:25:02.922Z] Daksh Agarwal (@daksh76)
@carlton
could you please give a hint as to why this isnt working

[2025-02-14T14:25:35.496Z] Daksh Agarwal (@daksh76)
im running locally first and then will use docker when i get a 10/10 score

[2025-02-14T14:27:05.634Z] Arulvadivelan V (@23f2005419)
Okay, actually when i tried with local, i‚Äôm facing path error
./data/format.md
[WinError 2] The system cannot find the file specified
So that‚Äôs why i moved to docker but there also i‚Äôm getting error for A2.

[2025-02-14T14:28:35.283Z] Daksh Agarwal (@daksh76)
you should manually check if the file really exists or not because i think the code and the folder where datagen.py is downloading files(data folder) are different

[2025-02-14T14:30:50.228Z] Arulvadivelan V (@23f2005419)
yes yes i moved the folder to current working directory

[2025-02-14T14:42:57.529Z] Carlton D'Silva (@carlton: Regular)
If you are using the function calling approach, you could just parse the ‚Äò#‚Äô and change it to ‚Äònumber‚Äô and then send the prompt to the llm for that particular task.
Or another approach is tell the llm,
If you ever see the phrase ‚Äòcount the # of‚Äô in a task, please interpret it as ‚Äòcount the number of‚Äô. For example
Count the # of Fridays means
Count the number of Fridays

[2025-02-14T14:51:01.614Z] VIKASH PRASAD (@21f3002277)
Screenshot 2025-02-14 201854
1919√ó1015 81.4 KB
@carlton
@Jivraj
this is showing while docker image is running

[2025-02-14T15:06:44.218Z] Andrew David (@23f1002382)
in project page, ctrl+F and search ai proxy, one link s.anandProxy or something, there it will validate you email and get you your token.

[2025-02-14T15:08:15.660Z] Andrew David (@23f1002382)
can you share your code for dynamic code generation, i dont have the base to start with , can you send me the code?
whatever this image is , llm_code,oy and etc

[2025-02-14T15:18:46.195Z] Carlton D'Silva (@carlton: Regular)
Sakshi6479:
{
    "type": "json",
    "json_schema": {
        "name": "taks_runner",
        "schema": {
            "type": "object",
            "required": ["python_dependencies","python_code"],
            "properties": {
                "python_code": {
                    "type": "string",
                    "description": "Python code to perform the task"
                },
                "python_dependencies": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "module": {
                                "type": "string",
                                "description": "Name of the python module"
                            }
                        },
                        "required": ["module"],
                        "additionalProperties": False
                    }
            }
        }
    }
}
}
It clearly says in your error message:
Invalid value: ‚Äòjson‚Äô
if you look at the ‚Äútype‚Äù key in your response_format variable at the top,
the value cannot be ‚Äújson‚Äù
The error is telling you what the supported values are
‚Äòjson_object‚Äô, ‚Äòjson_schema‚Äô, and ‚Äòtext‚Äô
Since you are defining a schema the correct value should be ‚Äòjson_schema‚Äô
So therefore you should change
"type": "json"
to
"type": "json_schema"
If you have trouble constructing Json schemas,
either feed it to gpt and have it correct it (along with your error) or please go over Module 3, in particular
https://tds.s-anand.net/#/llm-text-extraction
There is a clear example you can use as a template. We use the same one as a template when we do it in the sessions. That way you will make less errors.
Kind regards

[2025-02-14T15:20:58.709Z] Aarush saxena  (@23f2005702)
What file should we have while pushing it to git and making image
should datagen file and data be there or not?

[2025-02-14T15:24:08.470Z] Carlton D'Silva (@carlton: Regular)
Please read the deliverables and evalute section.
datagen.py and evaluate.py were for only for your testing purposes so that you have an idea of the workflow and how the evaluation works. They are NOT part of your project submission.
Only DO what the project page tells you in the deliverables and evalute sections.
Kind regards

[2025-02-14T16:01:26.721Z] Sourabh Raj (@Sourabhraj)
sir i am getting this error by running the docker image
image
656√ó116 3.28 KB
i tried troubleshooting this for hours but no luck could you please tell me what i did wrong here

[2025-02-14T16:05:32.054Z] Vivek  (@23ds1000005)
i can help you up, if you need my help you can email me

[2025-02-14T16:34:56.570Z] 23f3001356 (@ShahbaazSingh)
@s.anand
Sir please tell me this I am not using podman i am using docker for building and hosting is it fine sir ?

[2025-02-14T16:56:52.460Z] Pradeep Mondal (@21f2000709)
Hey
@carlton
@Jivraj
, I actually submitted the project already in the morning,
I included all the deliverables and things mentioned in the evaluation section.
But since I was actively testing with the -
datagen.py
and
evaluate.py
, I forgot to remove them before submission.
However these files do not play a role in my project execution in any way, they just sit idle. Will there be any issue?

[2025-02-14T16:57:01.976Z] Jayaram (@22f3002723)
when trying to use function call way of open api
tools = [
    {
        "type": "function",
        "function": {
            "name": "extract_email_sender",
            "description": "Extract sender email from a specific file in directory",
            "parameters": {},
            "strict": True
        }
    },
    {
        "type": "function",
        "function": {
            "name": "count_day_of_week",
            "description": "To count the occurances of a specific day of a week in a file with various dates",
            "parameters": {
                "type": "object",
                "properties": {
                    "day_of_week": {
                        "type": "string",
                        "description": "day of week"
                    }
                },
                "required": ["day_of_week"],
                "additionalProperties": False
            },
            "strict": True
        }
    }
]
payload = {
        "model": "gpt-4o-mini",
        "messages": [
            {"role": "user", "content": user_input},

        ],
	"tools": tools,
    "tool_choice": "auto",
    "max_tokens": 500,
    "temperature": 0.7
    }
facing the below issue
ror‚Äô: {‚Äòmessage‚Äô: ‚ÄúInvalid type for ‚Äòtools[0]‚Äô: expected an object, but got an array instead.‚Äù

[2025-02-14T17:04:07.947Z] Anvitha (@AnvithaV)
when i run POST request t is showing output ‚ÄúHTTP/1.1 200 OK‚Äù but when i give GET request it is showing HTTP/1.1" 404 Not Found. Can you please say how can it be solved

[2025-02-14T17:06:05.703Z] Pradeep Mondal (@21f2000709)
These files are inside a separate folder -
evaluation
in my project root directory. Since I already submitted please do consider.
Thanks & Regards
Pradeep

[2025-02-14T17:09:07.670Z] Pradeep Mondal (@21f2000709)
This indicates your task execution returns  ‚ÄúHTTP/1.1 200 OK‚Äù but the execution doesn‚Äôt creates the required file in the given location that the evaluation script is requesting.

[2025-02-14T17:09:40.757Z] Andrew David (@23f1002382)
If have doubts in building DOCKER stuff can you help me debug
PLEASE SENPAI

[2025-02-14T17:10:23.045Z] Pradeep Mondal (@21f2000709)
sure!! how can I help?

[2025-02-14T17:10:55.142Z] Andrew David (@23f1002382)
+1
SENPAI is right

[2025-02-14T17:12:09.065Z] Andrew David (@23f1002382)
not yet maybe in an hour, im building, but after that running in docker is different ball game, thats why , i need quick debugs in a meeting, other people also can join, maybe tomorrow, i have an exam tomorrow, so preferably , collectively before project submission . IF YOU HAVE TIME

[2025-02-14T17:14:03.094Z] Pradeep Mondal (@21f2000709)
23f1002382:
Sure tell me I would try, if I am online then otherwise tomorrow if it‚Äôs late

[2025-02-14T17:30:23.474Z] Ansh bansal (@23f2004752)
I am getting this error while pulling docker image
ansh@Lenovo:~/llm_project$ podman pull
docker.io/ansh205/llm_project:final
Trying to pull
docker.io/ansh205/llm_project:final
‚Ä¶
Error: parsing image configuration: Get ‚Äú
https://docker-images-prod.6aa30f8b08e16409b46e0173d6de2f56.r2.cloudflarestorage.com/registry-v2/docker/registry/v2/blobs/sha256/07/079f65bc553514a8f38a08fd959e932ca984894a64eed71fca406f3353b71d3b/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=f1baa2dd9b876aeb89efebbfc9e5d5f4%2F20250214%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250214T172706Z&X-Amz-Expires=1200&X-Amz-SignedHeaders=host&X-Amz-Signature=073575bf08338fcdda378b997ebe749b15a6b676ed7b80fbf4c3f8080a791152
‚Äù: dial tcp: lookup
docker-images-prod.6aa30f8b08e16409b46e0173d6de2f56.r2.cloudflarestorage.com
on 10.255.255.254:53: server misbehavingPreformatted text

[2025-02-14T17:50:37.272Z] Ansh bansal (@23f2004752)
@carlton
@Jivraj
@s.anand
@Saransh_Saini
sir please provide me other api key. My current request cost is full.
Full LLM Response: {‚Äòmessage‚Äô: ‚ÄòOn 2025-02 you used $2.000143640000001, exceeding $2‚Äô}

[2025-02-14T17:54:51.017Z] Jayaram (@22f3002723)
curl -X POST http://localhost:8001/run?task=Extract%20sender%20email
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100    36  100    36    0     0      9      0  0:00:04  0:00:03  0:00:01     9{"results":"wrighttara@example.net"}
is this expectation of having %20 for blanks in query string fine ?

[2025-02-14T18:00:47.841Z] Andrew David (@23f1002382)
docker run -e OPEN_AI_PROXY_TOKEN=your_token_value
-e OPEN_AI_PROXY_URL=your_proxy_url
-e OPEN_AI_EMBEDDING_URL=your_embedding_url
-p 8000:8000
how do we get out urls inside, hardcode?

[2025-02-14T18:44:42.380Z] Andrew David (@23f1002382)
Can you help with docker size image?
is it 2 GB?

[2025-02-14T19:25:07.571Z] Maulik Dang (@23f2001975)
I want to reset my aiproxys i have used them all if i could even buy some would work i need it to test my app or could iitm help in resetting it please tell

[2025-02-14T19:33:27.385Z] Daksh Agarwal (@daksh76)
could u help me in q9 thats the one left

[2025-02-14T19:34:15.132Z] Daksh Agarwal (@daksh76)
@carlton
my aiproxy is also exhausted please help me out

[2025-02-14T19:35:02.251Z] Naman Gupta (@Namannn28)
sir my api tokens limit reached to one dollar , hiw to reset it

[2025-02-14T19:39:31.640Z] Maulik Dang (@23f2001975)
bro can you help me with q2

[2025-02-14T20:00:49.013Z] JAHAR KUMAR PAUL (@21f3000512)
How to handle task a8 ? I tried pytesseract but gave wrong results.EasyOCR is giving the exact answer so tried in docker but some Model download is interrupting the flow of evaluate.py resulting in error .
I appreciate any help/procedure or code to handle taska8.
Thanks in advance.

[2025-02-14T20:10:42.788Z] Maulik Dang (@23f2001975)
Did you get any solution to this

[2025-02-14T20:14:40.100Z] Vishal Baraiya (@TheVishal)
u can use groq api groq api is compatible with openai

[2025-02-14T20:19:32.979Z] Andrew David (@23f1002382)
whats up?
/////////////////////

[2025-02-14T20:22:37.469Z] Vishal Baraiya (@TheVishal)
bro can please check my repo i am only able to do 7 tasks.
repo url:
GitHub - 23f2005593/tds-project-1: TDS Project 1

[2025-02-14T20:34:21.048Z] Andrew David (@23f1002382)
got the docker working?

[2025-02-14T21:26:37.667Z] Shahsank J Shetty (@22f3001011)
@carlton
@Jeeveash.k
sir i submitted the wrong docker image file while submitted the form. Can you please let me change it, or make it such that we can reupload it
thank you.

[2025-02-14T21:43:12.220Z] Anand S (@s.anand: Course_faculty)
22f3001011 I‚Äôve enabled ‚ÄúAllow response editing‚Äù on the form. I
think
that means you can edit your response‚Ä¶ but since you had submitted it before it was enabled, I‚Äôm not sure what the procedure is. Worst case, please submit again.

[2025-02-14T21:53:15.084Z] Chandapara Atul Ramabhai  (@22f3000079)
Please make this change in evaluation.py
In evaluation script url of datagen.py is different than actual one please change it
evaluation.py line 72
Install
uv
(if required) and run the script
https://raw.githubusercontent.com/sanand0/tools-in-data-science-public/tds-2025-01/datagen.py
change this to
Install
uv
(if required) and run the script
https://raw.githubusercontent.com/sanand0/tools-in-data-science-public/tds-2025-01/project-1/datagen.py

[2025-02-14T22:56:20.796Z] Maulik Dang (@23f2001975)
very true there is too much confusion Id like to ask if you know that evaluate.py is mean to run only for
user@example.com
or our own mail too  because there was written
You MUST use your Student Id
(eg. 22f3xxxxxx@ds.study.iitm.ac.in)
to do the Project, otherwise your score will not be considered for evaluation.

[2025-02-14T23:29:27.439Z] Arulvadivelan V (@23f2005419)
Hi any one have any idea on the below,
SyntaxError: illegal target for annotation
I‚Äôm getting this error only when i run the evaluate.py but in with postman it works as expected.
Anyone please help on this

[2025-02-15T01:57:19.909Z] VIKASH PRASAD (@21f3002277)
Screenshot 2025-02-15 071910
1919√ó1021 71.3 KB
sir why the datagen.py in not created in the tree and the data folder please help me
@s.anand
@Jivraj
@carlton

[2025-02-15T02:08:18.515Z] Andrew David (@23f1002382)
created in toot, cd /data in docker will take you there.

[2025-02-15T02:42:37.695Z] VIKASH PRASAD (@21f3002277)
Screenshot 2025-02-15 075843
1919√ó1017 70.9 KB
is changes is required in Dockerfile

[2025-02-15T03:36:59.904Z] Lalith Seervi (@23f2002205)
i too got the same error you can change the the tools part in your payload to
"tools": [{"type": "function", "function": schema} for schema in function_schema]

[2025-02-15T03:42:16.807Z] Lalith Seervi (@23f2002205)
i think you have to run the following command
uv run datagen.py <your_email> --root ./data
try to include --root ./data in your code

[2025-02-15T03:47:05.826Z] Lalith Seervi (@23f2002205)
sorry i forgot the change the name of function_schema to tools please you do that

[2025-02-15T04:05:04.243Z] Tanush Tambe (@22f3002248)
@carlton
@Jivraj
Hello,
just a silly question, if my code runs well in docker environment with
/data
in root directory, will it be fine ?
or should i keep the relative
./data
directory like in the lecture ?
Thanks

[2025-02-15T04:22:25.373Z] Carlton D'Silva (@carlton: Regular)
The reason in the lecture they were using ./data was because they were debugging in their local machine not in the docker.
For the docker image (the official submission) you must use /data.
It is a clear requirement mentioned in the project page.
Thats why it works fine when you use it in the docker image.
Kind regards

[2025-02-15T04:52:07.911Z] Atimanas Biswal (@Atimanas)
Screenshot 2025-02-15 101818
858√ó521 24.4 KB
@Jivraj
@carlton
hello sir i need help here. I have pushed my image into a docker repo and trying to submit it on ht google form. but it is not accepting it and asking to remove the tag .
What do i do ?

[2025-02-15T05:05:47.472Z] Shahsank J Shetty (@22f3001011)
Alright sir.  Thank you very much for your help.

[2025-02-15T06:03:11.059Z] Muhammed Adhil Pt (@22f3002034)
Are multiple submissions allowed for project?

[2025-02-15T06:20:07.084Z] ABHIJEET KUMAR  (@23f2004912)
A8
720√ó1280 85.1 KB
@carlton
@Jivraj
please check this one‚Ä¶

[2025-02-15T06:23:42.508Z] Arulvadivelan V (@23f2005419)
Hi
@carlton
@Jivraj
sir,
For A2 do i need to install node in the docker? I‚Äôm getting error with npx.
please suggest some way sir?

[2025-02-15T06:23:48.438Z] Ansh bansal (@23f2004752)
if i have two repo on docker , is there any problem in that

[2025-02-15T07:15:04.110Z] Shashannk (@23f2003413)
image
684√ó316 12.7 KB
why do i get this error? can someone please help me out
@Jivraj
@carlton
‚Ä¶Anyone pls help

[2025-02-15T07:20:31.804Z] Shashannk (@23f2003413)
can u please share the base proxy url

[2025-02-15T07:47:01.264Z] Samra Ahmed  (@Samra)
I‚Äôm also getting the same error. I have used a proxy URL and token. Before, it was working, but now it‚Äôs not.

[2025-02-15T07:59:47.243Z] Aarush saxena  (@23f2005702)
sir or anyone can you please provide what should be the content inside the docker file ‚Ä¶ i am getting confuse like /data or python-slim etc
‚Ä¶ i am done with locally testing and only this thing left.

[2025-02-15T08:02:21.376Z] Saniya Naaz (@23f2002592)
yes please explain somebody. What should be inside the dockerfile

[2025-02-15T08:08:08.614Z] Arulvadivelan V (@23f2005419)
Hi ,
Anyone completed Task B, I don‚Äôt know how to combine task A (function calling) and task B (self creating python code)
can anyone suggest how to do that? It will be really helpful

[2025-02-15T08:20:53.033Z] Shashannk (@23f2003413)
‚Äú
http://aiproxy.sanand.workers.dev/openai/v1
‚Äù use this as proxy URL. its working for me now!

[2025-02-15T08:24:19.337Z] Saravanan (@sarvan108)
How to resolve this?
sarvan108@SURIYA:/mnt/c/Users/sarva/OneDrive/Documents/Knowledge/IIT Madras Datascience/tds_pro$ uv run app.py
Traceback (most recent call last):
File ‚Äú/mnt/c/Users/sarva/OneDrive/Documents/Knowledge/IIT Madras Datascience/tds_pro/app.py‚Äù, line 10, in
from fastapi import FastAPI
ModuleNotFoundError: No module named ‚Äòfastapi‚Äô
sarvan108@SURIYA:/mnt/c/Users/sarva/OneDrive/Documents/Knowledge/IIT Madras Datascience/tds_pro$ pip show fastapi
WARNING: Package(s) not found: fastapi
sarvan108@SURIYA:/mnt/c/Users/sarva/OneDrive/Documents/Knowledge/IIT Madras Datascience/tds_pro$ pip install fastapi
error: externally-managed-environment
√ó This environment is externally managed
‚ï∞‚îÄ> To install Python packages system-wide, try apt install
python3-xyz, where xyz is the package you are trying to
install.
If you wish to install a non-Debian-packaged Python package,
create a virtual environment using python3 -m venv path/to/venv.
Then use path/to/venv/bin/python and path/to/venv/bin/pip. Make
sure you have python3-full installed.

If you wish to install a non-Debian packaged Python application,
it may be easiest to use pipx install xyz, which will manage a
virtual environment for you. Make sure you have pipx installed.

See /usr/share/doc/python3.12/README.venv for more information.
note: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.
hint: See PEP 668 for the detailed specification.

[2025-02-15T08:35:27.325Z] Ayush Kumar Shaw  (@23f2001286)
sir,
It is a humble requests from my side, to plz extend the deadline.
Because student like who come from non technical background, are unable to come up with this project‚Ä¶
though we have somehow comeup with the GAs taking the helps of groups, seniors and sessions.
Moreover I am Dual Degree student. It is very hectic for me.
Sir you won‚Äôt believe but I am continuously trying since last week. Specially after the release of the sessions‚Ä¶ Whole day and night have gone like nothing, infront of the computer‚Ä¶
Plz sir understand the situation and extend the deadline‚Ä¶

[2025-02-15T08:39:19.292Z] Samra Ahmed  (@Samra)
23f2003413:
http://aiproxy.sanand.workers.dev/openai/v1
For me it says invalid path

[2025-02-15T08:39:42.373Z] VIKASH PRASAD (@21f3002277)
@carlton
@Jivraj

[2025-02-15T08:43:54.893Z] DHRUV (@22f3002319)
same issue happening with me even though working for last whole week only got 4 correct . please extend some time so we can complete the project as weekends are the time when we get a day off from our primary college and can work with full attention on this project.

[2025-02-15T08:59:45.643Z] JAIDEEP M (@Jaideep)
it usually happens in some GNU/Linux OS. since you are using some distribution based on Debian namely Ubuntu or whatever try doing sudo apt install python-packagename (replace package name with fastapi for fastapi)
then it works. It usually happens due to manual intervention with pip3 the user might break some system dependencies which require some python3 package. No need to worry about it.
Another Fix: try using a virtual environment which is highly suggested since there is no chance for you to interfere with the system packages.
create a venv using python3 -m venv name_of_venv
add this line to your .bashrc in ~ folder as source /path/to/your/venv/location
and run source .bashrc. This time no error occurs as you do everything in your virtual environment you can install anything python3 package using pip3 install package name.
It even happened for me
Screenshot_20250215_143357
3841√ó1009 237 KB

[2025-02-15T09:03:19.240Z] Carlton D'Silva (@carlton: Regular)
Most of your questions and doubts will be solved in todays sessions. First 20 mins will be a clear overview of the logic and workflow and how evaluation actually works.
Rest of the session will be bug fixing and doubts.
Kind regards

[2025-02-15T09:10:10.123Z] Jayesh Bansal (@Jayeshbansal)
EXPECTED:
Everybody significant bank herself them process build body. Price live size. Assume begin better language east like machine.
New customer green strategy.
Feeling stock experience certainly history talk buy. Quality perform appear human general religious feeling. Kid indicate fear word win carry.
During professional sport growth citizen glass great student. Exactly receive cause. Couple off current between role natural.
Wind develop world next. Impact appear capital cold stock we. Quality get run case huge that.
Use century general above more region. Radio him quality stage. Truth least military dinner growth.
Study maybe source. For expect imagine.
Analysis remain voice dog sit part. Safe them store spring life girl.
House bring challenge. Tell but rock able great.
Mouth president worker common Mr billion.
RESULT:
‚ÄúEverybody significant bank herself them process build body. Price live size. Assume begin better language east like machine.\nNew customer green strategy.\nFeeling stock experience certainly history talk buy. Quality perform appear human general religious feeling. Kid indicate fear word win carry.\nDuring professional sport growth citizen glass great student. Exactly receive cause. Couple off current between role natural.\nWind develop world next. Impact appear capital cold stock we. Quality get run case huge that.\nUse century general above more region. Radio him quality stage. Truth least military dinner growth.\nStudy maybe source. For expect imagine.\nAnalysis remain voice dog sit part. Safe them store spring life girl.\nHouse bring challenge. Tell but rock able great.\nMouth president worker common Mr billion.‚Äù
it is the error i am facing but when i am opening manually, i am not getting any error, what should I do?
this same issue is with 3-4 questions

[2025-02-15T10:02:56.723Z] Shashannk (@23f2003413)
when will the session be conducted and how can we join it sir?

[2025-02-15T10:03:30.828Z] Saravanan (@sarvan108)
Hi Thanks.
Yes. it works when venv is created. But I see that it was working find in Week 5-Session 1 video without creating virtual environment.

[2025-02-15T10:12:37.060Z] Praul Ayar (@21f1003816)
I will not submit project.

[2025-02-15T10:27:38.324Z] Jivraj Singh Shekhawat (@Jivraj: Course TA)
Get authentication token from this
AI Proxy
and usage and follow documentation for sending requests.
sanand0/aiproxy: Authorizing proxy for LLMs

[2025-02-15T10:28:22.183Z] Jivraj Singh Shekhawat (@Jivraj: Course TA)
No Problems, just fill form with correct image name in google forms.

[2025-02-15T10:28:56.422Z] Jivraj Singh Shekhawat (@Jivraj: Course TA)
yes npx will require node to be installed.

[2025-02-15T10:31:05.324Z] Shashannk (@23f2003413)
@Jivraj
when would today‚Äôs live session be conducted and how can we attend it sir

[2025-02-15T10:45:33.373Z] Rishit (@Rrishit)
evaluate.py is not working sir.

[2025-02-15T10:53:42.320Z] AdithyaAcharya  (@24f2000074)
What if you run out of credits during or just before final evaluation?

[2025-02-15T11:07:54.170Z] Jivraj Singh Shekhawat (@Jivraj: Course TA)
This is only for testing on local machine.
In docker image keep /data.

[2025-02-15T11:09:03.532Z] Jivraj Singh Shekhawat (@Jivraj: Course TA)
One session is going live right now (from 3 to 5 pm).
It will be visible from calendra.

[2025-02-15T11:15:05.016Z] Vedant Bhanushali (@Vedant22)
sir,
It is a humble requests from my side, to plz extend the deadline.
Because student like who come from non technical background, are unable to come up with this project‚Ä¶
though we have somehow comeup with the GAs taking the helps of groups, seniors and sessions.
Moreover I am Dual Degree student. It is very hectic for me.
Sir you won‚Äôt believe but I am continuously trying since last week. Specially after the release of the sessions‚Ä¶ Whole day and night have gone like nothing, infront of the computer‚Ä¶
Plz sir understand the situation and extend the deadline‚Ä¶

[2025-02-15T11:15:42.013Z] Abhay Sharma (@sharma_abhay)
Sir, I have put my AIPROXY_TOKEN in .env file should I need to push the .env file also in the github

[2025-02-15T11:21:06.394Z] Naman Gupta (@Namannn28)
yes sir do we have to put env file also
@carlton
sir
@Jivraj
sir

[2025-02-15T11:31:22.936Z] Ayush Kumar Shaw  (@23f2001286)
In the evaluation.py there is an import require named from datagen import some stuff.
which means inorder to run the evaluation.py we need to manually bring the datagen.py in the working directory‚Ä¶
Because in order to run the evaluation.py we need the datagen. plz help‚Ä¶

[2025-02-15T11:32:33.850Z] Shashannk (@23f2003413)
can someone send the meet link for the live session happening now

[2025-02-15T11:38:34.015Z] Kabir Vyas (@Kabir1203)
Everytime I run datagen.py for the A1 task, the data file gets downloaded in the C drive instead of the current project folder. I even tried to set the current project folder as the root directory but it still downloads the files in C drive and I cant seem to find a workaround this. Can someone please help with this issue. Thanks!

[2025-02-15T11:42:30.317Z] Kabir Vyas (@Kabir1203)
Can you please make the changes in the datagen.py file
config = {‚Äúroot‚Äù: ‚Äú/data‚Äù}
This is where I have been facing the issue.
The only solution I can think of is moving the /data folder from the root to the project directory. which I am not sure is a good way to solve this issue.

[2025-02-15T12:03:17.621Z] Chinnam Goutham Nischay (@gouthamnischay)


[2025-02-15T12:04:54.730Z] Mayank Mehta (@23f2001978)
@carlton
please tell do we have to put this url in a variable for A1 task ?
https://raw.githubusercontent.com/sanand0/tools-in-data-science-public/tds-2025-01/project-1/datagen.py

[2025-02-15T12:06:18.314Z] Nelson Jochim DSouza (@Nelson)
Task A9 fails.
HTTP Request: POST
https://aiproxy.sanand.workers.dev/openai/v1/embeddings
‚ÄúHTTP/1.1 401 Unauthorized‚Äù
A9 failed: ‚Äòdata‚Äô
A9 FAILED
If I run
curl -X POST http://aiproxy.sanand.workers.dev/openai/v1/embeddings -H "Content-Type: application/json" -H "Authorization: Bearer $AIPROXY_TOKEN" -d '{"model": "text-embedding-3-small", "input": ["king", "queen"]}'
I get
{
  "message": "Missing Authorization: Bearer header. See https://github.com/sanand0/aiproxy"
}
@carlton
@Jivraj
@s.anand

[2025-02-15T12:08:35.195Z] shivam dubey (@23f1002279)
@carlton
sir
@Jivraj
sir  do i have to put env file in docker

[2025-02-15T12:23:41.857Z] Tanush Tambe (@22f3002248)
you have to give the
AIPROXY_TOKEN
to the evaluate.py by either
bash -
export AIPROXY_TOKEN="your token"
or
powershell -
$env:AIPROXY_TOKEN="your token"
the evaluate.py file takes the token to send request to embedding end point for processing.
so you have to set
AIPROXY_TOKEN
in both terminals
i.e. app.py and evaluate.py teminals

[2025-02-15T12:29:10.140Z] Kabir Vyas (@Kabir1203)
when I run the evaluation file, i get the following error -
Running task: Install
uv
(if required) and run the script
https://raw.githubusercontent.com/sanand0/tools-in-data-science-public/tds-2025-01/datagen.py
with
user@example.com
as the only argument
A1 failed: All connection attempts failed
A1 FAILED
I am getting the following error when running the evaluation scripts, can someone help me understand what this error is?

[2025-02-15T12:34:03.097Z] Koustubh Ramakrishnan (@koustubhr)
Humble request to extend the deadline please. Finding it extremely difficult and having time atleast till Sunday will be really helpful for working professionals like me

[2025-02-15T12:58:45.926Z] Nelson Jochim DSouza (@Nelson)
All my tasks are running except A9. I have created a .env file and added my token. Despite that I ran commands in both the terminals. A9 still fails.

[2025-02-15T12:59:11.585Z] Kabir Vyas (@Kabir1203)
I second this, have been trying to debug the project for the past 1 week, spending over 4 hours daily and yet facing issues everytime I reopen. An extension of even 24 hours would be extremely appreciated. Please consider this. Thanks.

[2025-02-15T13:09:56.100Z] Mayank Mehta (@23f2001978)
same issue on my side as well

[2025-02-15T13:10:27.279Z] Mayank Mehta (@23f2001978)
how u did A2
could u please share ?

[2025-02-15T13:21:11.144Z] Andrew David (@23f1002382)
@s.anand
@jivraj
@carlton
AIPROXY_TOKEN=$AIPROXY_TOKEN
what abt m url stuff?

[2025-02-15T13:24:31.715Z] Narendra (@NarendraAbhiyantrik)
Sir, I request you to Please  extend the deadline, Because it is time consuming  and regular Students and Working professionals  have only saturday and sunday to complete this project.
Thanks

[2025-02-15T13:32:08.963Z] Tanush Tambe (@22f3002248)
also, in evaluate.py file, the embedding url is wrong and the AIPROXY_TOKEN is changed to OPENAI_API_TOKEN or something. i could send you edited evaluate.py‚Ä¶ check your messages on discourse

[2025-02-15T13:40:33.913Z] Nelson Jochim DSouza (@Nelson)
On bash it gives below output. On PowerShell it says missing authorization. A9 is failed.
image
907√ó661 26.5 KB
In PowerShell
image
967√ó292 16.5 KB

[2025-02-15T13:45:17.659Z] Kabir Vyas (@Kabir1203)
My data is getting generated -
image
459√ó454 12.7 KB
despite this I am getting an error when evaluating the file with no explanation of the error. Can someone please help with this.
Running task: Install
uv
(if required) and run the script
https://raw.githubusercontent.com/sanand0/tools-in-data-science-public/tds-2025-01/datagen.py
with
user@example.com
as the only argument
A1 failed:
A1 FAILED

[2025-02-15T13:47:58.449Z] Kabir Vyas (@Kabir1203)
image
820√ó404 12.3 KB
Even the markdown file shows the correct email. What are the possible issues that I could be facing with this one.

[2025-02-15T13:57:58.100Z] Andrew David (@23f1002382)
github.com
GitHub - ANdIeCOOl/TDS-Project-1
main
Contribute to ANdIeCOOl/TDS-Project-1 development by creating an account on GitHub.
ATLEAST 6 minimum score use at own risk(MIT LICENCE xD)
BUILD TIME TAKES 2 mins
WITH DOCKER FILE
@ANdIeCOOl ‚ûú /workspaces/TDS-Project-1/tds-project-1 (main) $ docker build -t tds-project-1 .
[+] Building 123.9s (13/13) FINISHED                                                                       docker:default
 => [internal] load build definition from Dockerfile                                                                 0.0s
 => => transferring dockerfile: 1.18kB                                                                               0.0s
 => [internal] load metadata for docker.io/library/python:3.11-slim                                                  2.2s
 => [auth] library/python:pull token for registry-1.docker.io                                                        0.0s
 => [internal] load .dockerignore                                                                                    0.0s
 => => transferring context: 2B                                                                                      0.0s
 => [internal] load build context                                                                                    0.1s
 => => transferring context: 34.30kB                                                                                 0.0s
 => [1/7] FROM docker.io/library/python:3.11-slim@sha256:42420f737ba91d509fc60d5ed65ed0492678a90c561e1fa08786ae8ba8  8.7s
 => => resolve docker.io/library/python:3.11-slim@sha256:42420f737ba91d509fc60d5ed65ed0492678a90c561e1fa08786ae8ba8  0.0s
 => => sha256:2c2c44fb54acb184dbedee948d7ba6460b1075a60a014d66857ce46543d4d840 5.29kB / 5.29kB                       0.0s
 => => sha256:c29f5b76f736a8b555fd191c48d6581bb918bcd605a7cbcc76205dd6acff3260 28.21MB / 28.21MB                     0.7s
 => => sha256:73c4bbda278d9a2b5133d6dabfac3eec43a92b8c8c15da914f298b4c966bea53 3.51MB / 3.51MB                       0.9s
 => => sha256:acc53c3e87ac87c98e44b79e0d2a6293146650f5cba576f424dab77f8c0a4335 16.20MB / 16.20MB                     1.6s
 => => sha256:42420f737ba91d509fc60d5ed65ed0492678a90c561e1fa08786ae8ba8b52eda 9.13kB / 9.13kB                       0.0s
 => => sha256:a66bd09b8d35bb52cd106a94c23a94ba22e6fde6bd13d6c5912ec4f5888a7f14 1.75kB / 1.75kB                       0.0s
 => => extracting sha256:c29f5b76f736a8b555fd191c48d6581bb918bcd605a7cbcc76205dd6acff3260                            2.2s
 => => sha256:ad3b14759e4f8c9a73d51c897a8b96f022ec96ffc237502ad3f1f12b0b0e361f 249B / 249B                           1.9s
 => => extracting sha256:73c4bbda278d9a2b5133d6dabfac3eec43a92b8c8c15da914f298b4c966bea53                            0.2s
 => => extracting sha256:acc53c3e87ac87c98e44b79e0d2a6293146650f5cba576f424dab77f8c0a4335                            1.4s
 => => extracting sha256:ad3b14759e4f8c9a73d51c897a8b96f022ec96ffc237502ad3f1f12b0b0e361f                            0.0s
 => [2/7] WORKDIR /app                                                                                               0.2s
 => [3/7] RUN pip install --upgrade pip setuptools wheel                                                             8.7s
 => [4/7] RUN apt-get update && apt-get install -y --no-install-recommends     gcc     g++     make     libffi-dev  84.5s
 => [5/7] RUN npm install -g prettier                                                                                1.5s
 => [6/7] COPY app /app                                                                                              0.1s
 => [7/7] RUN pip install uv                                                                                         4.5s
 => exporting to image                                                                                              13.4s
 => => exporting layers                                                                                             13.4s
 => => writing image sha256:39add91710bc7970d44dae04b3f4a0c4f227d1471fac4df7b01cec86ce7af3cf                         0.0s
 => => naming to docker.io/library/tds-project-1                                                                     0.0s
@ANdIeCOOl
‚ûú /workspaces/TDS-Project-1/tds-project-1 (main) $ docker images
REPOSITORY      TAG       IMAGE ID       CREATED          SIZE
tds-project-1   latest    39add91710bc   31 seconds ago   923MB
if this cause any issues please notify
@s.anand
@carlton
@Jivraj

[2025-02-15T14:00:16.470Z] Sarthak Saklani (@23f3000709)
in phase B tasks are we supposed to create files to store the output or return it in the response ???
Please answer ASAP sir.

[2025-02-15T14:02:17.277Z] LAKSHAY (@lakshaygarg654)
@s.anand
Respected Sir,
I sincerely request you to kindly consider granting a one-day extension for Project 1. Many key clarifications were provided in today‚Äôs session, and we need just one additional day to effectively implement them. This extension would be immensely helpful in ensuring a more refined submission.
I truly appreciate your time and consideration.
Thank you.

[2025-02-15T14:07:14.907Z] Andrew David (@23f1002382)
@all
can everyone please test my image and let me know PLEASE. THIS IS THE MOST YOU ALL CAN DO FOR ME. I WILL BE BERY GRATEFUL
github.com
GitHub - ANdIeCOOl/TDS-Project-1
main
Contribute to ANdIeCOOl/TDS-Project-1 development by creating an account on GitHub.

[2025-02-15T14:08:05.189Z] Sarthak Saklani (@23f3000709)
hey I have a few doubts, if something was said about this please say so.
in Phase be tasks do we have to store the output in files or just return it in the response
When I call my some of my endpoints using post man or CURL they work but if I run the evaluate.py it throws an error, this I think is a bug in the eval.py file.
any idea about these ?

[2025-02-15T14:22:28.484Z] Jayaram (@22f3002723)
facing the issue on submission
image
942√ó521 28.7 KB

[2025-02-15T14:25:14.239Z] Jayaram (@22f3002723)
please ignore the above‚Ä¶ there was a upper case issue  in image name‚Ä¶ now fine

[2025-02-15T14:35:04.549Z] Sagandeep Kaur (@Sagan)
Is it import to use python 3.13?
It is not stable yet

[2025-02-15T14:38:13.967Z] Shashannk (@23f2003413)
image
1831√ó146 7.91 KB
can someone help me fix this error
@Jivraj
@carlton

[2025-02-15T14:40:37.732Z] Abhigyan Das (@abhigyandsa)
for the datagen script is it ok to hardcode the scripts url and my email id? I understand the script itself may change but can I count on the link remaining the same? Also is it necessary to pass the email as argument?

[2025-02-15T14:41:38.706Z] Vishal Baraiya (@TheVishal)
from dotenv import load_dotenv
load_dotenv()

[2025-02-15T14:45:08.620Z] Shashannk (@23f2003413)
yahh i have it in my code‚Ä¶still facing the issue

[2025-02-15T14:55:45.137Z] Abhigyan Das (@abhigyandsa)
@Jivraj
@carlton
[filler to extend length]

[2025-02-15T15:05:52.096Z] Divjot Singh (@24ds3000061)
whats the image‚Äôs name on Docker?

[2025-02-15T15:05:54.911Z] Bhumanapalli Hrushi Kesava Reddy (@23f2004936)
just completed my sem exams started worrking on the project from 2 days please give extension of deadline for the project sir

[2025-02-15T15:32:09.297Z] Tushar Jalan  (@23f2003751)
dont we have to add the data folder or folder like datagen in the repo?

[2025-02-15T15:33:23.890Z] Andrew David (@23f1002382)
thats confidential, im not an idiot xD, that will get me definitely  in trouble

[2025-02-15T15:33:55.303Z] Andrew David (@23f1002382)
no, not really . Just your app

[2025-02-15T15:42:54.272Z] Tushar Jalan  (@23f2003751)
in your project,in the app folder you have the data folder which is empty so should I keep that or remove it

[2025-02-15T15:45:15.797Z] Tushar Jalan  (@23f2003751)
and also will u be making any chnages in the repo

[2025-02-15T15:47:05.777Z] Shashannk (@23f2003413)
File ‚Äú/app/app.py‚Äù, line 35, in
client = OpenAI(
^^^^^^^
File ‚Äú/usr/local/lib/python3.12/site-packages/openai/_client.py‚Äù, line 110, in
init
raise OpenAIError(
openai.OpenAIError: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable                                                                              some pls help me fix this error!!

[2025-02-15T16:01:54.136Z] Jivraj Singh Shekhawat (@Jivraj: Course TA)
Blunder in your
main.py
.
You are using API_KEY = os.getenv(‚ÄúAI_PROXY_TOKEN‚Äù) but it should be AIPROXY_TOKEN.
Btw what you using for phase B?

[2025-02-15T16:03:05.233Z] Andrew David (@23f1002382)
yes i will change that

[2025-02-15T16:03:54.280Z] Andrew David (@23f1002382)
nothing i think, i‚Äôll import those generic functions and use tool usage only probably if can‚Äôt crack dynamic code generation

[2025-02-15T16:04:55.343Z] Andrew David (@23f1002382)
i don‚Äôt have that
github.com
TDS-Project-1/tds-project-1/app at main ¬∑ ANdIeCOOl/TDS-Project-1
Contribute to ANdIeCOOl/TDS-Project-1 development by creating an account on GitHub.

[2025-02-15T16:05:12.024Z] Jivraj Singh Shekhawat (@Jivraj: Course TA)
What we expect in project.
server running inside docker container at 8000.
And all files will be accessed from data folder in root directory.
Apart from these two you can have anything extra.

[2025-02-15T16:05:55.854Z] Pratik Dey (@21f2000710)
Screenshot 2025-02-15 212826
1903√ó492 32.1 KB
how to fix this error ?

[2025-02-15T16:05:58.397Z] Jivraj Singh Shekhawat (@Jivraj: Course TA)
What problem you facing with that dynamic code generation part?

[2025-02-15T16:06:26.583Z] Debjeet Singha (@23f2001413)
I have exhausted my api limit of $2. I need to test my project. Can you please provide some more credits?
@Jivraj
@carlton
@s.anand

[2025-02-15T16:07:35.874Z] Andrew David (@23f1002382)
no problem but im losing steam slowly, i need to buckle up and PUSH
@Jivraj

[2025-02-15T16:08:57.535Z] Yashvardhan (@23f2004644)
Subject:
Request for Project Deadline Extension
Dear Sir,
This project is highly complex, and we need additional time to ensure its successful completion. We kindly request an extension of the deadline to allow for thorough testing and proper implementation. An extension would greatly help us deliver the best results.
Thank you for your understanding
@Jivraj
@carlton
@s.anand

[2025-02-15T16:13:14.808Z] Jivraj Singh Shekhawat (@Jivraj: Course TA)
This might be problem with network settings(unstable internet, firewall, VPN interference)
try to debug it with help of chatgpt.
You can also use codespaces for trying another network.
Streamlining setup with GitHub Codespaces

[2025-02-15T16:13:42.738Z] Jivraj Singh Shekhawat (@Jivraj: Course TA)
Push push
@23f1002382

[2025-02-15T16:18:02.598Z] Shashannk (@23f2003413)
@Jivraj
is it fine if i have my AIPROXY_TOKEN in my code instead of getting it as environment variable?

[2025-02-15T16:20:06.323Z] Debjeet Singha (@23f2001413)
if you do that then during evaluation, it would use your credit limit. if it gets exhausted, you may face problems.
@23f2003413

[2025-02-15T16:21:10.108Z] Tushar Jalan  (@23f2003751)
image
266√ó559 12.5 KB
this is what i am doing first using the podman given in the portal and then running the evaluate.py file

[2025-02-15T16:21:31.012Z] Shashannk (@23f2003413)
ahhh okay, but i am getting an error while trying to fetch the token as an environment variable. any suggestions to fix this issue?

[2025-02-15T16:22:17.623Z] Debjeet Singha (@23f2001413)
you can use python-dotenv. check that out.

[2025-02-15T16:23:07.849Z] Shashannk (@23f2003413)
tried that still not getting T_T anyways thanks mate!

[2025-02-15T16:25:07.138Z] Jivraj Singh Shekhawat (@Jivraj: Course TA)
No don‚Äôt do that, just follow the procedure.
Two problems with keeping token in file.
It will become public after you push to github.
While running evaluation script after submission your token might run out of credits.

[2025-02-15T16:27:24.797Z] Divjot Singh (@24ds3000061)
ohh yes, didn‚Äôt think it through xD

[2025-02-15T16:29:14.206Z] Anulekha Pandi S (@22f3000880)
I am facing the same error. and I have checked for solutions and found none. Did you resolve it? If yes can you please guide me through it?

[2025-02-15T16:34:00.432Z] Shashannk (@23f2003413)
{
‚Äúdetail‚Äù: ‚ÄúError code: 401 - {‚Äòerror‚Äô: {‚Äòmessage‚Äô: ‚ÄòYour authentication token is not from a valid issuer.‚Äô, ‚Äòtype‚Äô: ‚Äòinvalid_request_error‚Äô, ‚Äòparam‚Äô: None, ‚Äòcode‚Äô: ‚Äòinvalid_issuer‚Äô}}‚Äù
}          getting this error sir

[2025-02-15T16:40:47.374Z] Andrew David (@23f1002382)
github.com
TDS-Project-1/tds-project-1/app at main ¬∑ ANdIeCOOl/TDS-Project-1
Contribute to ANdIeCOOl/TDS-Project-1 development by creating an account on GitHub.
i keep updating, check this

[2025-02-15T16:47:32.801Z] Ayush Tiwari (@AyushTiwari)
Please extend deadline by 1 day. i just got discharged from hospital today, was suffering from liver problem since some days and got high heart beat due to a medicine unrelated to liver and made me got admitted@Jivraj

[2025-02-15T16:49:06.628Z] Andrew David (@23f1002382)
11:59 + 5 hours atthe most,
@s.anand
?

[2025-02-15T16:59:47.955Z] shivam dubey (@23f1002279)
@Jivraj
sir
@carlton
sir do have to add datagen in the docker container?
As when I‚Äôm running it locally, it gives 9/10, but when I pull it from Hub and run eval, it says:detail": ‚Äú[Errno 2] No such file or directory: ‚Äò/data/datagen.py‚Äô‚Äù

[2025-02-15T17:03:12.600Z] Shashannk (@23f2003413)
image
706√ó193 6.15 KB
someone please help me fix this error

[2025-02-15T17:10:19.057Z] Rohit Garg (@rohitgarg)
@carlton
can you pl merge this
github.com/sanand0/tools-in-data-science-public
Update evaluate.py with correct link of datagen.py for task `A1`
tds-2025-01
‚Üê
rohitxiitm:patch-1
opened
10:56AM - 15 Feb 25 UTC
rohitxiitm
+1
-1
ppl are facing issues in evaluate.py for task A2

[2025-02-15T17:15:51.605Z] Rohit Garg (@rohitgarg)
folks, need a confirmation. i don‚Äôt know but i heard it from someone or somewhere.
we cannot send json in response, if it is success ? need to send text
is that really the case ?

[2025-02-15T17:21:01.750Z] Anand S (@s.anand: Course_faculty)
@rohitgarg
- thanks for this. Merged your PR pointing to the correct link for
evaluate.py

[2025-02-15T18:07:41.953Z] 23F3004407 RATANPRIYA SINGH (@23F3004407_RATANPRIY)
Sir from which session to which session is about tds project?

[2025-02-15T18:22:39.454Z] Shashannk (@23f2003413)
week-5 session-1 & week-5 session-3

[2025-02-15T18:38:04.029Z] Naga durga prasad E (@23f3004114)
Here is  a Bruno collection (open source alternate for postman) for API testing A1 to A6
bruno collection

[2025-02-15T18:44:11.463Z] Abhigyan Das (@abhigyandsa)
On my system evaulate.py is throwing an error on A2 trying to execute npx on format.md before the llm is even invoked. However running the command directly on the command line works.
evaluate.py:
A2 failed: Command ‚Äò[‚Äònpx‚Äô, ‚Äòprettier@3.4.2‚Äô, ‚Äò‚Äìstdin-filepath‚Äô, ‚Äòdata/format.md‚Äô]‚Äô returned non-zero exit status 2.
A2 FAILED
bash:
npx prettier@3.4.2 --stdin-filepath data/format.md
bash works as expected. Can someone help?

[2025-02-15T18:56:27.273Z] Avnish Jajodia (@22f3001777)
@carlton
Is there a maximum size limit for the Docker Image?
Thanking you

[2025-02-15T19:34:01.014Z] Aagman Chandra (@RoyalAagman)
@carlton
@Jivraj
Hi ,
I am trying to build using both docker and podman but it failed on both. I have watched many videos trying to resolve this adn also chatgpt in order to resolve the issue but it seems to persist. I even uninstalled and reinstalled both podman and doceker multiple times but no help.
When i run command docker build -t ___________ .
the error that comes is :
Dockerfile:2
1 |     # Use a lightweight Python image
2 | >>> FROM python:3.12-slim
3 |
4 |     # Set the working directory in the container
ERROR: failed to solve: python:3.12-slim: failed to resolve source metadata for
Docker Hub Container Image Library | App Containerization
failed to copy: httpReadSeeker: failed open: failed to do request: Get ‚Äú
https://docker-images-prod.6aa30f8b08e16409b46e0173d6de2f56.r2.cloudflarestorage.com/registry-v2/docker/registry/v2/blobs/sha256/6f/6f3c6367c5a38963f84310cbb24dfcfbddab1dad40cff18afb8fe89098891f08/data?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=f1baa2dd9b876aeb89efebbfc9e5d5f4%2F20250215%2Fauto%2Fs3%2Faws4_request&X-Amz-Date=20250215T192245Z&X-Amz-Expires=1200&X-Amz-SignedHeaders=host&X-Amz-Signature=ed37cf0c346e2ed440f29638ec43ce66640bdc7d285e7be7bf25c308c46fd6b1
‚Äù: dialing
docker-images-prod.6aa30f8b08e16409b46e0173d6de2f56.r2.cloudflarestorage.com:443
container via direct connection because static system has no HTTPS proxy: connecting to
docker-images-prod.6aa30f8b08e16409b46e0173d6de2f56.r2.cloudflarestorage.com:443
: dial tcp: lookup
docker-images-prod.6aa30f8b08e16409b46e0173d6de2f56.r2.cloudflarestorage.com
: no such host
Even tried getting python:3.12-slim separatly and trying again but that also didn‚Äôt work.
I think there is some problem in getting python:3.12-slim as the build always stops at this.
on asking ChatGPT it shows that some DNS or network issue is there. I even tried all the remedy that was provided on creating custom network etc. but this was also of no use
Kindly help me finding solution to this and pls mention any other assistance I may require to get this running
Thank You.
Regards,
Aagman

[2025-02-15T19:53:57.298Z] Md anas alam (@22f3000639)
i am getting this error, I have tried many times but still the error persists:
‚Äúmessage‚Äù: ‚ÄúBearer YOUR_AIPROXY_TOKEN is invalid: JWSInvalid: Invalid Compact JWS‚Äù

[2025-02-15T19:56:55.979Z] Md anas alam (@22f3000639)
someone please help!!!

[2025-02-15T19:59:52.597Z] Rohit Garg (@rohitgarg)
@carlton
needed a confirmation on this task
A8 * `/data/credit-card.png` contains a credit card number. Pass the image to an LLM, have it extract the card number, and write it without spaces to `/data/credit-card.txt
- in this task i assume prompt can ask for credit card number or other details like cvv and name.
My question is, whether my system should allow prompt that CVV or or such info ? or should give it ?

[2025-02-15T20:11:45.990Z] Jayakrishnan (@jkmadathil: Leader)
11 posts were split to a new topic:
Project 1 - Casual banter

[2025-02-15T20:29:22.437Z] Debjeet Singha (@23f2001413)
Previously I asked for some more credits to test my project. I got an email stating I have been provided with a new token but I think I got that same token again, not a new one. I still cant send request to the AIPROXY. Please help.
Do I need to submit the docker image name with the tag or without the tag? I submitted it before without the tag. Now i see that I have tagged the image with as v1 but I cant submit the form due to pattern matching problems. Should i submit again after tagging it with :latest ?
@s.anand
@carlton
@Jivraj

[2025-02-15T21:20:23.334Z] shivam dubey (@23f1002279)
@Jivraj
@carlton
sir in the phase B will the input and output path will be given ?

[2025-02-15T21:44:56.585Z] Shivaditya Bhattacharya (@22f3000819)
@carlton
@Jivraj
@Saransh_Saini
When I run my docker image using
podman run -e AIPROXY_TOKEN=$AIPROXY_TOKEN -p 8000:8000 $IMAGE_NAME
Task A2 fails as the podman container is unable to find npx.
Running the same image using
docker run -e AIPROXY_TOKEN=$AIPROXY_TOKEN -p 8000:8000 $IMAGE_NAME
works fine and Task A2 passes. I can‚Äôt understand why this is happening.
I also ran the image in both docker and podman in interactive mode as show in the below snippet from terminal.
When run using docker,
which node
gives
/usr/bin/node
as output but when run using podman, nothing.
shiva@shiva:~/Desktop/tdsp1$ sudo podman run --rm -it docker.io/myusername/myreponame /bin/sh
# echo $PATH
/root/.local/bin:/usr/local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
# which node
# exit
shiva@shiva:~/Desktop/tdsp1$ sudo docker run --rm -it docker.io/myusername/myreponame /bin/sh
# echo $PATH
/root/.local/bin:/usr/local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
# which node
/usr/bin/node
# exit
shiva@shiva:~/Desktop/tdsp1$ sudo podman run --user=root --rm -it docker.io/myusername/myreponame /bin/sh
# which node
# which node
# exit

[2025-02-15T22:00:56.106Z] Aniruddha Mukherjee (@23f1003186)
Here‚Äôs how to prompt folks. Just do what
@carlton
mentioned in today‚Äôs live session (the 5 hour marathon) and you should be good for Project-1!
x.com
Aakash Gupta
@aakashg0
Most people are still prompting wrong.

I've found this framework, which was even shared by OpenAI President Greg Brockman.

Here‚Äôs how it works:
pic.x.com/2MMcEqBeIJ
8:06 PM - 14 Feb 2025
5.5K
360

[2025-02-15T23:08:34.656Z] Yogesh (@Yogesh1)
Same issue. Got the same token. Can‚Äôt use it since 2 dollar limit has been crossed. Please help.
@carlton
@Jivraj

[2025-02-16T03:01:42.744Z] Ayush Kumar Shaw  (@23f2001286)
Yes I also need the answer of this.

[2025-02-16T03:03:43.445Z] Ayush Kumar Shaw  (@23f2001286)
Is there any way of figuring what is the usage of my token and if yes then how‚Ä¶
Plz some peers help‚Ä¶

[2025-02-16T03:06:01.016Z] Carlton D'Silva (@carlton: Regular)
It will be corrected soon by
@jkmadathil
He is in charge of our budget for TDS and the tokens are being issued by him.
Please tag him for any token related issues.

[2025-02-16T03:34:46.233Z] Jayakrishnan (@jkmadathil: Leader)
New token assigned to the students.  Emails are also sent.

[2025-02-16T04:34:50.606Z] Ayush Kumar Shaw  (@23f2001286)
sir I am noticing a pattern, that when I am running the datagen first. And then using the evaluate.py, then I am getting the A2 right.
But running the evaluation.py for the 2nd time cause the A2 to fail‚Ä¶
Probabbly Because the file in the data folder gets upated should I worry for that‚Ä¶

[2025-02-16T05:21:27.713Z] Jayesh Bansal (@Jayeshbansal)
in the phase B, we have no idea about how many arguments are there, so should we make every function mapping with 2 arguments ( 1 containing the input location and other containing output location) or should we take the parameters in some other way

[2025-02-16T06:21:36.637Z] Carlton D'Silva (@carlton: Regular)
There has been an outage in some parts of the country related to cloudflare servers. What helped some students (and us) is using a completely different network eg. instead of using your home wifi, use mobile internet, since they go through a different DNS and this sometimes works.
Kind regards

[2025-02-16T06:22:27.485Z] Carlton D'Silva (@carlton: Regular)
We have not specified a size limit for the docker image, so in theory there is not a limit to the docker image size.
Kind regards

[2025-02-16T06:26:11.317Z] Kushagra Barodekar (@kushabarodekar)
Hello
@carlton
Sir,
While running evaluate.py , I have observed that the expected  and actual output is having difference like ‚Äú\n‚Äù then also it marks task as fail.
eg:
EXPECTED:
Cover west give likely individual though question inside. System many human plant card among provide. Large former seek mouth there long.
Attention officer successful. Us population the true show.
Real cold if play side wind affect. Street cause investment receive have miss page station.
Cold rest term her conference. Animal sure campaign new.
Meeting back page exactly itself book forward. Decision western series under from shoulder. Pay during feeling newspaper human. Professional old recent beyond girl three human.
Difficult yourself build increase back put others.
Although artist operation thing skin lead. Billion deep measure down adult suggest. Anything action start artist when first.
Whole way know down. Music machine trip father rather.
Must medical bad law issue.
Someone explain seven maintain wrong day factor property.
RESULT:
‚ÄúCover west give likely individual though question inside. System many human plant card among provide. Large former seek mouth there long.\nAttention officer successful. Us population the true show.\nReal cold if play side wind affect. Street cause investment receive have miss page station.\nCold rest term her conference. Animal sure campaign new.\nMeeting back page exactly itself book forward. Decision western series under from shoulder. Pay during feeling newspaper human. Professional old recent beyond girl three human.\nDifficult yourself build increase back put others.\nAlthough artist operation thing skin lead. Billion deep measure down adult suggest. Anything action start artist when first.\nWhole way know down. Music machine trip father rather.\nMust medical bad law issue.\nSomeone explain seven maintain wrong day factor property.\n‚Äù
A5 FAILED
Will this be considered as failure in actual evaluation as well or will this be taken care in actual evaluation?

[2025-02-16T06:34:16.658Z] Kabir Vyas (@Kabir1203)
image
1412√ó248 16.3 KB
Im able to execute the query succesfully.
image
1109√ó570 40.3 KB
But the data gets downloaded to C drive instead of the project folder
The datagen.py file is in the project folder itself.
image
821√ó149 9.61 KB
am I making any error when setting the directories?
Please help, have been facing this issue since the beginning of this project, initially tried to move the files from C drive to project folder but that does not seem like a viable solution.

[2025-02-16T06:51:41.708Z] Kabir Vyas (@Kabir1203)
image
1123√ó760 42.8 KB
I am also running datagen.py in the project directory, yet data folder is created in C drive.

[2025-02-16T06:54:08.636Z] Ayush Kumar Shaw  (@23f2001286)
@jkmadathil
sir plz renew my token‚Ä¶
Showing,
{‚Äòmessage‚Äô: ‚ÄòOn 2025-02 you used $2.0041067399999912, exceeding $2‚Äô}
Sorry sir!..

[2025-02-16T06:57:30.673Z] VIKASH PRASAD (@21f3002277)
use PlainTextResponse for /read

[2025-02-16T06:59:34.007Z] Ayush Kumar Shaw  (@23f2001286)
Plz do someone reply.

[2025-02-16T07:04:53.309Z] Kabir Vyas (@Kabir1203)
@carlton
@s.anand
@Jivraj
Please review the code and help me fix the error in order to proceed further. Thanks.

[2025-02-16T07:19:46.325Z] Andrew David (@23f1002382)
github.com/ANdIeCOOl/TDS_CLUTCH_PROJECT_1
README.md
main
# TDS_CLUTCH_AT_6AY
using code generation, getting 6/10 or * if lucky, similar comments needs a tool function call for sure, maybe someone can implement and create pull request, if you all can get 10/10 fine tuning with tool functions
@Jivraj
@carlton
Please help if it meets deliverables

[2025-02-16T08:28:50.991Z] Ayush Kumar Shaw  (@23f2001286)
Sir I need a help, In hte B portion where no any destination and source files are given‚Ä¶
There we need to ask the user to povide the source and destination files or does we should store it in any default file locations‚Ä¶
As the statement is very vauge saying the ‚Äúagent should handle this‚Äù‚Ä¶
Thanks Sir!!

[2025-02-16T09:09:06.299Z] Ayush Kumar Shaw  (@23f2001286)
@jkmadathil
@carlton
@Jivraj
Sir earlier my code was running fine, but after the assigment of the new token,
it is now showing 400 bad request, which simply implies there is something wrong with the token‚Ä¶
plz do something sir‚Ä¶
I have do have cross verified the new token been correctly been assigned to the system variable‚Ä¶

[2025-02-16T09:19:36.290Z] Ayush Kumar Shaw  (@23f2001286)
More Particularily the failure occurs in the response portion‚Ä¶
def get_completions(prompt: str):
    print("Inside get_completions")#Debug
    with httpx.Client(timeout=20) as client:
        response = client.post(
            f"{openai_api_chat}",
            headers=headers,
            json=
                {
                    "model": "gpt-4o-mini",
                    "messages": [
                                    {"role": "system", "content": "You are a function classifier that extracts structured parameters from queries."},
                                    {"role": "user", "content": prompt}
                                ],
                    "tools": [
                                {
                                    "type": "function",
                                    "function": function
                                } for function in function_definitions_llm
                            ],
                    "tool_choice": "auto"
                },
        )

    print("DId suceessful llm calll")#Debug
INFO:     127.0.0.1:52108 - "POST /run?task=The+SQLite+database+file+%60%2Fdata%2Fticket-sales.db%60+has+a+%60tickets%60+with+columns+%60type%60%2C+%60units%60%2C+and+%60price%60.+Each+row+is+a+customer+bid+for+a+concert+ticket.+What+is+the+total+sales+of+all+the+items+in+the+%22Gold%22+ticket+type%3F+Write+the+number+in+%60%2Fdata%2Fticket-sales-gold.txt%60 HTTP/1.1" 400 Bad Request

[2025-02-16T09:19:54.114Z] Shashannk (@23f2003413)
is there any limit on the size of the docker image
@Jivraj
@carlton
? because mine is about 5.6Gb

[2025-02-16T09:20:56.839Z] Ayush Kumar Shaw  (@23f2001286)
bhai nhi hai‚Ä¶
koi size limit

[2025-02-16T10:12:11.868Z] Monisha M (@23f3002091)
uv run
https://raw.githubusercontent.com/sanand0/tools-in-data-science-public/tds-2025-01/project-1/evaluate.py
Installed 13 packages in 543ms
Traceback (most recent call last):
File ‚Äú/tmp/evaluateF6zgG9.py‚Äù, line 20, in
from datagen import (
‚Ä¶<9 lines>‚Ä¶
)
ModuleNotFoundError: No module named ‚Äòdatagen‚Äô
I am getting this error when I try to run evaluate.py
when I run the evaluate.py by having datagen.py in same folder , it is running perfectly. But my doubt is only after task a1 runs the datagen.py will be downloaded into the /data folder right ?
@carlton
@Saransh_Saini
@Jivraj
Kindly help me with this issue

[2025-02-16T10:15:40.611Z] Aditya Kumar Sahu (@Aditya_Sahu)
Use following as first parameter of
subprocess.run()
to create
data/
directory inside your project instead of C: drive
["uv", "run", script_url, user_email, "--root", "./data"]
Also, you don‚Äôt need to download to script, you can directly run it from the url.

[2025-02-16T10:33:45.101Z] Aditya Kumar Sahu (@Aditya_Sahu)
The reason for error is
evaluate.py
is trying to import
datagen.py
which doesn‚Äôt exist in your system. I‚Äôll suggest download both the files, keep them in same folder and run
evaluate.py
from your computer

[2025-02-16T10:35:51.852Z] Monisha M (@23f3002091)
Yes actually Thats my doubt , when I run both in same folder it is working , but only after task a1 runs datagen.py will be downloaded in /data folder  right ?,
or did I misunderstood something??

[2025-02-16T10:38:05.164Z] Vishal Baraiya (@TheVishal)
Generation-Based Automation Agent (No Hard Coding)
Repository Link:
GitHub - 23f2005593/tds
Currently, it can complete 7 out of 10 tasks. In reality, it can complete 9 out of 10 tasks, but the expected results are not flexible in evaluate.py file.
If we can extract credit card numbers, it will be able to complete 10 out of 10 tasks.
Please contribute to this repository.
We will win together.

[2025-02-16T10:42:00.545Z] Dabgar Milav Jayeshkumar (@21F1005510)
{
‚Äúmessage‚Äù: ‚ÄúOn 2025-02 you used $2.0041388599999848, exceeding $2‚Äù
}
What to do?

[2025-02-16T10:43:32.880Z] Dabgar Milav Jayeshkumar (@21F1005510)
facing same error, have you fouind any solution?

[2025-02-16T11:07:43.937Z] Tanya kamboj (@21f3000745)
sir for this task- A6 Find all Markdown (
.md
) files in
/data/docs/
. For each file, extract the first occurrance of each H1 (i.e. a line starting with
#
). Create an index file
/data/docs/index.json
that maps each filename (without the
/data/docs/
prefix) to its title (e.g.
{"README.md": "Home", "path/to/large-language-models.md": "Large Language Models", ...}
)   ‚Ä¶I am getting correct result for all files but for the very first file budget.md it shows wrong.
my result- { ‚Äúbudget.md‚Äù: ‚ÄúSuccess easy same main modern doctor.‚Äù,
‚Äúbuild.md‚Äù: ‚ÄúShoulder follow own never above.‚Äù,
and in the data files there is different heading in budget.md.-  # Series dog who make specific agree between.
my question is this if it works for all the files then why not for this file budget.md
@Saransh_Saini
@Jivraj
@carlton

[2025-02-16T11:14:46.456Z] Tanya kamboj (@21f3000745)
do you able to do this task *
A5
. Write the first line of the 10 most recent
.log
file in
/data/logs/
to
/data/logs-recent.txt
, most recent first ‚Ä¶
i am also doing using prompt no hard-coded.

[2025-02-16T11:15:48.711Z] Tanya kamboj (@21f3000745)
yes doing this only but finding correct for most of the files.

[2025-02-16T11:17:05.625Z] Vishal Baraiya (@TheVishal)
yes i am able to do task a5.

[2025-02-16T11:19:16.557Z] Tanya kamboj (@21f3000745)
so you directly using prompt for doing this task.

[2025-02-16T11:20:42.518Z] Vishal Baraiya (@TheVishal)
yes i am only using prompt based method

[2025-02-16T11:22:43.078Z] Tanya kamboj (@21f3000745)
If filename has number in its name then extract the number from the filename and convert it to an integer before sorting .Ensure numbers inside filenames are compared as integers, not as strings, to maintain proper order. Sort filenames in said in task. Avoid any lexicographical sorting issues.    i am using this extra info for doing this but still it does not give accurate result. can you help me in this

[2025-02-16T11:23:51.476Z] Vishal Baraiya (@TheVishal)
i already shared my repo u can check there.

[2025-02-16T12:17:41.613Z] Tushar Jalan  (@23f2003751)
you have pushed data,datagen and evaluate files‚Ä¶do we have to submit them as well??
(also send the docker file)

[2025-02-16T12:24:19.136Z] Saransh Saini (@Saransh_Saini: Course TA)
Check the file once, there is a possibility that it‚Äôs either fetching a comment or the second heading. Refactor your prompt to search only for the First Heading, specify it explixitly.

[2025-02-16T12:34:43.548Z] Tanya kamboj (@21f3000745)
okay let me check once.
one more thing sir {‚Äúfirst_name‚Äù: ‚ÄúCrystal‚Äù, ‚Äúlast_name‚Äù: ‚ÄúWilson‚Äù, ‚Äúemail‚Äù: ‚Äú
delgadorebecca@example.com
‚Äù}   then what will be the sorted-contact for this as in email there is no first and lastname present.
@Saransh_Saini

[2025-02-16T12:58:43.228Z] J Rohan Atre  (@23f1000371)
Hey, I submitted the project links in the google form yesterday but, today in the portal it shows that I have not submitted the project.

[2025-02-16T13:11:13.013Z] Aishik Bandyopadhyay (@23f2005325)
I am getting this error while running evaluate.py on task A9
HTTP Request: POST https://aiproxy.sanand.workers.dev/openai/v1/embeddings "HTTP/1.1 401 Unauthorized"

üî¥ A9 failed: 'data'
There were no authentication issues till yesterday.
please guide
@carlton
@Jivraj
@Saransh_Saini

[2025-02-16T13:20:12.206Z] Saransh Saini (@Saransh_Saini: Course TA)
This is happening because evaluate.py is unable to fetch your API Key from the environment variables. Create a new variable and set it‚Äôs value to your API Key then try.

[2025-02-16T13:22:14.284Z] Manav Singh (@Flibon)
Hi everyone,
I‚Äôm running into an issue with the AI Proxy embeddings endpoint while executing the A9 task. Every time I send a POST request to:
bash
Copy
https://aiproxy.sanand.workers.dev/openai/v1/embeddings
I receive a
401 Unauthorized
response. This, in turn, causes my code to fail with a
KeyError: 'data'
because the expected JSON response doesn‚Äôt include the
"data"
key.
What I‚Äôve Tried
Token Verification:
I‚Äôm using the
AIPROXY_TOKEN
obtained by logging in at
aiproxy.sanand.workers.dev
with my IITM email.
The token is passed in the header as follows:
python
Copy
"Authorization": f"Bearer {AIPROXY_TOKEN}"
I added debug prints to confirm that the token is being used correctly (printing the first few characters).
API Request Details:
The request includes the correct
Content-Type: application/json
header.
The payload is set as:
json
Copy
{"model": "text-embedding-3-small", "input": ["Test"]}
Despite this, the response status is consistently 401 Unauthorized.
Debug Output:
Here‚Äôs a snippet of the debug output:
bash
Copy
HTTP Request: POST https://aiproxy.sanand.workers.dev/openai/v1/embeddings "HTTP/1.1 401 Unauthorized"
üî¥ A9 failed: 'data'
This confirms that the issue is with the authentication rather than our processing logic.
What I Suspect
The token may be invalid, expired, or misconfigured.
There could be changes in the token permissions or endpoint requirements that I‚Äôm not aware of.
Alternatively, there might be an issue on the server side with token validation.
Request for Help
Has anyone else encountered this issue recently? Could someone verify if there are any changes to the authentication requirements for the embeddings endpoint? Any insights or updated instructions on how to ensure the token is valid and has the proper permissions would be greatly appreciated.
Thanks in advance for your assistance!

[2025-02-16T13:26:14.110Z] Ayush Kumar Shaw  (@23f2001286)
B5. Run a SQL query on a SQLite or DuckDB database
Should I ask for the SQL data base. Or the agent should be smart enough to find the required database‚Ä¶
Moreover in the data folder there is only one database is it should be robust to handle multiple databases‚Ä¶

[2025-02-16T13:31:32.080Z] Yashvardhan (@23f2004644)
same issue i also face                   pls sir help us fix this issue and provide us more  token
HTTP Request: POST
https://aiproxy.sanand.workers.dev/openai/v1/embeddings
‚ÄúHTTP/1.1 429 Too Many Requests‚Äù
A9 failed: ‚Äòdata‚Äô
@Jivraj
@carlton
@Saransh_Saini

[2025-02-16T13:55:52.482Z] Bhashwar Sengupta (@bhashwar_sengupta)
I had a question on evaluation by the course team. To test that my application would run everywhere, I first deleted all images from my local machine using
podman rmi -a
and then ran
podman run --rm -p 8000:8000 -e AIPROXY_TOKEN=$AIPROXY_TOKEN $IMAGE_NAME
with the appropriate variables set. This is as per the instructions provided
here
. But this gave me the following error:
Error: short-name "freshbash/dataworks-agent" did not resolve to an alias and no unqualified-search registries are defined in "/etc/containers/registries.conf
The above is the format in which we have to provide the image name in the Google form. So, I was confused whether this would succeed during actual evaluation.
The only way its working right now is when I specify the image name to be
docker.io/freshbash/dataworks-agent
I‚Äôm not yet very good with how containers work so some insights would be very helpful. Thanks!

[2025-02-16T14:06:32.676Z] Andrew David (@23f1002382)
Nice bro, if its getting 8 you are sorted, probably get more later. But Prompting seems a little less info
BUT
Structured Outputs
JSON Mode
Outputs valid JSON
Yes
Yes
Adheres to schema
Yes (see supported schemas)
No
Compatible models
gpt-4o-mini, gpt-4o-2024-08-06, and later
gpt-3.5-turbo, gpt-4-* and gpt-4o-* models
Enabling
response_format: { type: json_schema, json_schema: {strict: true, schema: ‚Ä¶} }
response_format: { type: json_object }
try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0,
            response_format={"type": "json_object"}
        )
github.com/23f2005593/tds
app.py
main
prompt = (
f"The Python code generated for the task '{task}' produced the following error when executed:\n"
f"{error_message}\n\n"
f"Here is the original code:\n{original_code_data['code']}\n\n"
"Please provide a corrected version of the code that fixes the error. Return only a JSON object with:\n"
"- code: the corrected Python code as a string\n"
"- function_name: name of the main function\n"
"- required_libraries: list of required pip packages\n\n"
"Make sure the code is simple, direct, and error-free this time. And try not to mess it up like before."
)
try:
response = client.chat.completions.create(
model="gpt-4o-mini",
messages=[{"role": "user", "content": prompt}],
temperature=0,
response_format={"type": "json_object"}
)
except Exception as exc:
logger.error("Error connecting to OpenAI API for auto-fix: %s", exc)
raise HTTPException(status_code=500, detail="Connection error during auto-fix. Maybe it's time to admit defeat?")
you are taking a chance on that format

[2025-02-16T14:18:18.312Z] Andrew David (@23f1002382)
Screenshot 2025-02-16 091341
1315√ó404 24.2 KB
Screenshot 2025-02-16 091101
1351√ó292 13.3 KB
Hardest i ever worked in my life. Thank you
@s.anand

[2025-02-16T14:26:15.111Z] Andrew David (@23f1002382)
TheVishal:
If we can extract credit card numbers, it will be able to complete 10 out of 10 tasks.
have tried function calling? with open code generation ?

[2025-02-16T14:32:03.478Z] Vishal Baraiya (@TheVishal)
not yet‚Ä¶ but i have another problem when i am running this by using docker it is giving error ‚Äúdatagen module not found‚Äù

[2025-02-16T14:32:46.201Z] Vishal Baraiya (@TheVishal)
bro please help by contribute please

[2025-02-16T14:35:15.324Z] Andrew David (@23f1002382)
come off on one meet

[2025-02-16T14:35:21.050Z] Shashannk (@23f2003413)
what should we push in the github repo
@Jivraj
@carlton
??
is it enough if we just push the Dockerfile, app.py, datagen.py and the LICENSE. Someone pls help!

[2025-02-16T14:35:55.720Z] Andrew David (@23f1002382)
bro i used all my codespaces credits xD
i am nitpicking and editing from website and running not exceed limit XD

[2025-02-16T14:36:37.073Z] Shashannk (@23f2003413)
someone pls help T_T

[2025-02-16T14:37:29.809Z] Andrew David (@23f1002382)
submit image and github  repo link, evalhaters will handle the rest im assuming

[2025-02-16T14:38:25.332Z] Shashannk (@23f2003413)
yeaa i got that but what should we add in the github repo‚Ä¶like should we add the generated data folder?
or is it enough if we just add the code and the Dockerfile to the repo

[2025-02-16T14:38:49.907Z] Andrew David (@23f1002382)
doesn‚Äôt matter they use only image

[2025-02-16T14:38:54.080Z] Vishal Baraiya (@TheVishal)
use local editor naa bro

[2025-02-16T14:39:34.694Z] Andrew David (@23f1002382)
and run my code xD i have one crazy setup XD give me some time, at 9:30 we‚Äôll hop on eachother

[2025-02-16T14:39:56.899Z] Tushar Jalan  (@23f2003751)
which repo u submitting yesterday one or todays.
i am unable to run the yesterday one

[2025-02-16T14:40:08.771Z] Andrew David (@23f1002382)
this one new one only xD

[2025-02-16T14:40:42.997Z] Shashannk (@23f2003413)
and what do they mean by image-name in the gform‚Ä¶is it the repo name in dockerhub?

[2025-02-16T14:40:45.742Z] Tushar Jalan  (@23f2003751)
what evil have u done xd

[2025-02-16T14:41:05.660Z] Andrew David (@23f1002382)
why? ///////////// O‚ÄîO

[2025-02-16T14:41:09.153Z] Tushar Jalan  (@23f2003751)
dockerhub image name

[2025-02-16T14:42:06.039Z] Tushar Jalan  (@23f2003751)
ur words are saying something else

[2025-02-16T14:42:21.966Z] Shashannk (@23f2003413)
image name as in i dont get it lol.

[2025-02-16T14:43:47.628Z] Shubham Atkal (@shubhamatkal)
(general) [shubham@laptop data]$ curl https://api.openai.com/v1/models -H "Authorization: Bearer $AIPROXY_TOKEN"
{
  "error": {
    "message": "Your authentication token is not from a valid issuer.",
    "type": "invalid_request_error",
    "param": null,
    "code": "invalid_issuer"
  }
pls help

[2025-02-16T14:43:56.779Z] Tushar Jalan  (@23f2003751)
push ur image to docker hub that it will be available for them to use
(use chatgpt on how to push to docker hub 2 3 steps to flw)

[2025-02-16T14:45:42.604Z] Shashannk (@23f2003413)
yeah i hv pushed the image to dockerhub but i exactly dont get what image name is
like is it the name of my repo

[2025-02-16T14:46:17.824Z] Tushar Jalan  (@23f2003751)
ur docker-username/image-name

[2025-02-16T14:46:36.853Z] Shashannk (@23f2003413)
check if u have exported the AIPROXY_TOKEN properly in your environment

[2025-02-16T14:47:29.759Z] Tushar Jalan  (@23f2003751)
anyone check my repo
github.com
GitHub - Tusharisme/TDS_Project_1
Contribute to Tusharisme/TDS_Project_1 development by creating an account on GitHub.

[2025-02-16T14:48:49.549Z] Shubham Atkal (@shubhamatkal)
yes i have the same key which is provided on ai proxy website for my login
and yes i have that key properly exported

[2025-02-16T14:55:12.204Z] Shashannk (@23f2003413)
check if u have used the correct ai proxy url then

[2025-02-16T14:58:49.547Z] Yogesh (@Yogesh1)
An email I just received says my license doesn‚Äôt have ‚ÄúMIT‚Äù in it. Although it does have it. I don‚Äôt know what I am missing. Someone help (if you didn‚Äôt get this mail).
@carlton
@Jivraj

[2025-02-16T14:59:55.018Z] Durga Prasad (@22f3001307)
@carlton
@Jivraj
@Saransh_Saini
Hi,
I received a mail saying that my submission has no Dockerfile. But git repo has a dockerfile.
even if i am to submit again, i have submit the same repo.
what should i do?

[2025-02-16T15:00:00.884Z] Vishnu Tejas B (@21f2001550)
Hey I just got a mail saying that my github repo has no Dockerfile present. and im confused .
It doesnt mention anywhere that the dockerfile must be present in the root directory as a requirement/prerequisite of the project.
In my case its present inside the app directory. Could the team help clarify on this issue.
@Jivraj
@carlton

[2025-02-16T15:01:32.983Z] Akshit Mittal (@23f2004636)
What is expected repo structure ?
I have a folder in my repo and dockerfile and license are present in that folder but I still received a mail regarding missing License and Dockerfile.

[2025-02-16T15:08:50.764Z] Shubham Atkal (@shubhamatkal)
do we need to have data folder in repo no right?

[2025-02-16T15:11:29.583Z] Durga Prasad (@22f3001307)
No, it is not needed

[2025-02-16T15:14:47.324Z] Shahsank J Shetty (@22f3001011)
We see that your submission
GitHub - 22f3001011/project-1
has a result of FAIL due to the below reasons:
No ‚ÄúMIT‚Äù in LICENSE
Hello sir, i got this mail despite having added the mit license as stated in the project problem statement. I cant figure out what the issue is, and help me out here.
@carlton
@Jeeveash.k
github.com
GitHub - 22f3001011/project-1
main
Contribute to 22f3001011/project-1 development by creating an account on GitHub.
Thank you
Regards
Shashank J Shetth
22f3001011

[2025-02-16T15:22:38.923Z] Yogesh (@Yogesh1)
Yeah. Same issue. Someone who didn‚Äôt get this error, please share the MIT license.

[2025-02-16T15:31:46.769Z] Saniya Naaz (@23f2002592)
https://github.com/saniyanz/tds-p1new
check my repo. what
s wrong. I
ve also got the mail but I`ve included the MIT License and the Dockerfile

[2025-02-16T15:32:47.336Z] PREMDEEP MAITI (@23f1001231)
Rename
LICENSE.txt
to
LICENSE

[2025-02-16T15:41:04.020Z] Nayonika Arora (@nayonika)
I got a mail saying my Dockerfile is missing. However I have a dockerfile already in my github repository. Is it an issue with the spelling of dockerfile since I have submitted it in all small case as ‚Äòdockerfile‚Äô. It was showing the score when I checked with the evaluate.py that was provided by iitm.
Shall I just change the name of the file from ‚Äòdockerfile‚Äô to ‚ÄòDockerfile‚Äô in github repository of mine or is there anything else that is needed to detect the Dockerfile?

[2025-02-16T15:42:09.636Z] Vishnu Tejas B (@21f2001550)
Hey team, I just moved my Dockerfile to the root level on my Github repo. Hope this solves the issue.
Small doubt: Do i need to submit the google form again?

[2025-02-16T15:53:49.088Z] Debashis Saha (@23f1002909)
I ran out of tokens. Please help me. Please its urgent.

[2025-02-16T15:57:49.722Z] 23f3001356 (@ShahbaazSingh)
@carlton
sir
@s.anand
sir please provide me more tokens, I am out of tokens i don‚Äôt knwo what happened i hade 151 requests use and 0.09 usd and suddenly i check it was 300 requests and 2 usd i don‚Äôt knwo what happened can you provide me more tokens.

[2025-02-16T16:00:21.667Z] LAKSHAY (@lakshaygarg654)
Dear
@s.anand
,
@carlton
,
@Jivraj
, and
@Saransh_Saini
Thank you all for this wonderful project. Coming from a non-coding background, I have learned a lot new things throughout this project building process.
@carlton
Sir, yesterday‚Äôs session provided valuable insights into Method 1 (prompt engineering) for dynamically handling tasks. I was able to develop an application using this approach; however, due to submission time constraints, I could not verify all tasks (my bad). While I tested some tasks and found the results to be highly accurate, I was unable to validate everything thoroughly.
Therefore, I submitted the function-calling approach (Method 2) instead.
I sincerely appreciate everyone‚Äôs guidance and support.

[2025-02-16T16:09:36.850Z] 23f3001356 (@ShahbaazSingh)
Did you ran out of tokens suddenly like me ?
How many requests have you sent in total ?

[2025-02-16T16:17:51.919Z] Tushar Jalan  (@23f2003751)
can u share ur repo
i really need it

[2025-02-16T16:24:56.917Z] Saransh Saini (@Saransh_Saini: Course TA)
Thanks
@lakshaygarg654
for this feedback. Glad to know you learned from our efforts, it means a lot. This proves that even a person from non-tech background with determination can achieve it.

[2025-02-16T16:26:27.020Z] Yashvardhan (@23f2004644)
sir pls provide more token
@Saransh_Saini
@Jivraj
@s.anand
sir pls , give any reply we have only 2 hr left

[2025-02-16T16:29:52.723Z] Saransh Saini (@Saransh_Saini: Course TA)
Change the name of your dockerfile to ‚ÄúDockerfile‚Äù

[2025-02-16T16:29:54.811Z] 23f3001356 (@ShahbaazSingh)
yes sir please provide more tokens to me also
@s.anand
@Jivraj
@carlton
@Saransh_Saini

[2025-02-16T16:38:00.300Z] Andrew David (@23f1002382)
i hope i get 1 mark xD
im getting tasks only maybe 3 / 10

[2025-02-16T16:55:41.066Z] Vicky Kumar (@Algsoch)
i have done many attempt but it is not working please show  my environment saying fastapi is not installed but i have installed and it is showing on checking but no running file it is saying no module i have installed in both virtual and system
please help

[2025-02-16T17:01:20.102Z] Vicky Kumar (@Algsoch)
image
1919√ó1016 117 KB
this problem occuring sir since two days

[2025-02-16T17:02:17.300Z] Kabir Vyas (@Kabir1203)
How long does it take to make a docker image, I‚Äôve been doing it for the past 25 minutes and it‚Äôs still not completed.

[2025-02-16T17:09:40.646Z] LAKSHAY (@lakshaygarg654)
Your LLM app should be designed like it can give desire result based on task desc at run endpoint, and that result should be accessible at read endpoint.
Evaluation file just for reference to check how things works and it works for phase A tasks only. Also ensure datagen.py file and evaluation.py file are latest. There is one issue in evaluation.py file for task A1,  link of datagen.py file not correct, rectify that link. Even it corrected in GitHub repo file but when I download that raw file in local system it takes back previous link.

[2025-02-16T17:18:09.197Z] Andrew David (@23f1002382)
I WONDER HOW MANY API REQUESTS THE SERVER IS PROCESSING . It‚Äôs too slow

[2025-02-16T17:43:00.472Z] Vivek  (@23ds1000005)
too much in the last few hours it feel

[2025-02-16T18:31:13.198Z] Ritwik Trivedi (@22f1000120)
I guess what is done is done. I should have maintained my version history properly. I am getting 4 correct but with minor formatting issues so only 1 correct I guess.

[2025-02-16T18:35:21.452Z] Ritwik Trivedi (@22f1000120)
It was tough‚Ä¶ I will probably not score much but I enjoyed it a lot. Thank you for pushing us so hard. At least I am not scared of docker now and function calling feels easier than before.

[2025-02-16T18:42:12.153Z] Anand S (@s.anand: Course_faculty)
Well done, everyone! This is not an easy project. This is the kind of work our clients are asking us for.
I will keep you posted on the evaluation on this thread, it progresses.
2025-02-16T18:31:00Z
Google Form closed
2025-02-16T18:35:00Z
Validating submissions. Will post results shortly

[2025-02-16T18:45:11.723Z] SHIVAM KUMAR (@22f1000150)
Sir i have missed the submission deadline  by 5  minutes, can you give permission for the google form to accept the response for half an hour more.

[2025-02-16T18:46:21.892Z] Vishal Baraiya (@TheVishal)
Sir, due to time panic, I mistakenly named the Docker image incorrectly.

[2025-02-16T18:47:14.170Z] SHIVAM KUMAR (@22f1000150)
Sir can you please allow submission for 5 more minutes?

[2025-02-16T18:51:43.271Z] Rishit (@Rrishit)
@s.anand
@carlton
Dear Sir,
I am writing to you in a state of distress and humility. An unfortunate mistake on my part has led to the upload of an incorrect Docker image link. When I checked the authenticity of the link, it showed an error, even though the GitHub repository link is functioning perfectly.
I have poured my heart and soul into this project, dedicating countless hours and sleepless nights to ensure its success. The project has successfully passed both Test A and Test B, and I was thrilled to see my hard work paying off. However, this single error has left me devastated.
I am pleading with you, with all my heart, to allow me to correct this mistake by updating the Docker image link. Alternatively, I humbly request that my application be reviewed directly through GitHub. Please consider this an exception, as I have worked tirelessly over the past two weeks to create an application that is 890 lines long.
I beg for your understanding and leniency in this matter. This project means the world to me, and I am genuinely sobbing over this setback.
Thank you for considering my heartfelt request.
Sincerely,
Rishit Jain
(24F2004595)

[2025-02-16T18:55:21.332Z] Prasoon Shukla (@psisaddicted)
Although couldn‚Äôt complete handling every task, but really enjoyed working on this project and learned a lot throughout the process. I appreciate the opportunity to work on such an engaging project. For Project 2, I‚Äôll make sure to allocate sufficient time and approach it with even greater commitment.

[2025-02-16T18:57:19.930Z] Vishal Baraiya (@TheVishal)
Sorry
@s.anand
@carlton
@Jivraj
Sir, due to time panic, I mistakenly named the Docker image incorrectly.

[2025-02-16T19:15:02.324Z] Ritwik Trivedi (@22f1000120)
Just push the latest image to docker asap. Hopefully the team considers it.

[2025-02-16T19:16:30.050Z] Ritwik Trivedi (@22f1000120)
True. Same here. Just giving 2 days for this project was definitely a big mistake on my part‚Ä¶ but I couldn‚Äôt really give more time due to work commitments.

[2025-02-16T19:28:13.949Z] Vishal Baraiya (@TheVishal)
@s.anand
@carlton
@Jivraj
Sir, due to time panic, I mistakenly named the Docker image incorrectly.
I am not 100% sure but i guess i used ‚Äúii‚Äù instead of ‚Äúi‚Äù in ‚Äúthevixhal/tdsvishal‚Äù‚Ä¶ is there any way to check this ?

[2025-02-16T19:34:57.475Z] Sagandeep Kaur (@Sagan)
Can the submissions open just for some time? In minutes?
Many students did silly mistakes due toh nervousness, we can just correct it.

[2025-02-17T02:56:32.384Z] GIRISH VISHVESHVAR BHAT (@GIRISH_VISHVESHVAR_B)
I don‚Äôt think the project is too difficult to implement‚Äîit‚Äôs essentially a simple HTTP API for an AI agent that reads a task, converts it into parameters, and passes those parameters to specific functions to complete the task. However, the instructions in the project question aren‚Äôt very clear. Before the session, I am unable to fully understand the question. It took me almost an entire day just to understand what we need to do.
Sir Could you provide test cases or a sample answer for Phase B?

[2025-02-17T04:47:02.331Z] LAKSHAY (@lakshaygarg654)
@s.anand
@carlton
sorry to disturb you, project1 deadline is over.
I made a mistake in my project. In my call llm function i set some payload instead of default for open ai api call like max token, temp. , n, stop etc.
Due to this, some tasks may fail especially credit card image task will fail 100%, if possible can i just remove that payload from git hub repository . or you can check this call llm function present in my task_handler.py file of my repository.
I found this issue after deadline. If possible consider this request. I never engaged in a project or course like for this one. I love this project genuinely.
my github repo :
GitHub - 21f3001076/TDS_Project_1: This is IITM Data Science TDS Course Project 1 Repository
Thankyou
Lakshay
student id: 21f3001076@ds.study.iitm.ac.in

[2025-02-17T05:41:26.456Z] Arjun Dwarakesh Janarthanan (@23f1001611)
Dear
@s.anand
@carlton
@Jivraj
,
Thank you so much for this wonderful project! We have learned so many things from this experience, especially the power of prompts. The team has put in tremendous effort, extending a few sessions and patiently clearing all our doubts. We truly appreciate the dedication and support
Regards,
Arjun

[2025-02-17T05:48:47.338Z] Swati Kapoor (@swatikap)
I would like to sincerely thank the course faculty
@carlton
@Jivraj
@Saransh_Saini
for their support on the project throughout the week. They were so patient in listening to our issues and helping us resolve them, even if the issues were repeated.
I was not able to complete some or maybe many of the tasks but overall, it was a very good learning for me, and I thoroughly enjoyed it.
Thanks very much again for your guidance and support.
Regards,
Swati

[2025-02-17T09:28:09.859Z] Saransh Saini (@Saransh_Saini: Course TA)
Thanks for your compliments Swati. It‚Äôs always nice to know our efforts paid off.
Happy Learning

[2025-02-17T10:07:52.089Z] Udipth (@Udipth)
I have received a mail that my project has ""No ‚ÄúMIT‚Äù in LICENSE;No Dockerfile " which I saw today. My project has MIT licence and Dockerfile was also there‚Ä¶ but to reconfirm I pulled my dockerfile from dockerhub to github only . NOw am not sure will that be considered now in my project submission or not. Requesting to kindly consider current state of my project in submission for my project.

[2025-02-17T11:09:20.695Z] Andrew David (@23f1002382)
WOMP WOMP should i call a wambulance?

[2025-02-17T11:10:37.785Z] Andrew David (@23f1002382)
(post deleted by author)

[2025-02-17T11:12:30.279Z] Andrew David (@23f1002382)
@all
those who didn‚Äôt submit, its ok EVEN I did NOT submit. Even though i get zero, i am happy with the learning i did. Once again thank you sir
@carlton
@s.anand
. This a been awesome experience , i haven‚Äôt been this alive in forever. Cheers.

[2025-02-17T11:43:24.604Z] Sakthivel S (@23f2000237)
I noticed something quite funny. The project never specified the required tech stack, so one could have done this entirely with JavaScript as well, assuming the necessary libraries are installed.

[2025-02-17T11:52:41.002Z] Andrew David (@23f1002382)
@TheVishal
EDIT: Create a new docker image with the mistaken image name , so when they pull image from repo, that image with the wrong name also gets pulled.
what to do
push a new image with the mistaken name, so in your repo there will be two images
how will this help?
since you are unsure, which image link you posted, you can be sure that even you had a mistake in link, a new image will exist with the wrong name after you push another image
@all
use this to update your image even after submission, as now they only validate the images, they do not pull it so you can edit your project and add more functionality if they release the code solutiion
CHEERS
Andrew OUT.

[2025-02-17T12:22:39.676Z] Sagandeep Kaur (@Sagan)
I didn‚Äôt submit the google form, I have made the github repo and docker image for TDS project 1. I, mistakenly, thought that I had submitted the google form but actually it was saved as a draft and closed my laptop. As soon as I realized my mistake, I hit the submit button but this was shown then,
‚ÄúThe form TDS Jan 2025 - Project 1 Submission is no longer accepting responses.‚Äù
I apologize for this. I have been working on this project for weeks.
This was my first TDS project. I would highly appreciated, if you could help me.
Thankyou
GitHub repo:
GitHub - Sagankaur/TDS_project1: LLM-based automation agent
Docker : sagandeep/tds_project1

[2025-02-17T12:47:55.488Z] VIKASH PRASAD (@21f3002277)
Sir, can we get the evaluation script now
@carlton
@s.anand

[2025-02-17T13:55:13.525Z] Shambhavi  (@24f2003130)
If I am not wrong you were getting 9/10 in task A when many of us were stuck  and you didn‚Äôt submit‚Ä¶ unbelievable

[2025-02-17T14:03:52.442Z] Shambhavi  (@24f2003130)
Thank you, sir, for giving us this amazing opportunity! Honestly, I learned more in the last week than I did throughout the three modules.
The project was a rollercoaster ride‚Äîespecially with all the errors that kept popping up‚Äîbut overall, the experience was incredibly enriching. The amount of knowledge I gained was truly valuable.
A huge thanks to
@Carlton
,
@Saransh_Saini
, and
@Jivraj
sir for their guidance and support. Without the last week‚Äôs lectures, the project couldn‚Äôt have been completed.

[2025-02-17T14:33:09.731Z] Andrew David (@23f1002382)
i couldn‚Äôt my code space ran out of compute and then it was just lagging before i found out what happened , i just submitted old code repo and the image the we created in week 2 or week1 when had to create docker image for graded assignments
EDIT:
Screenshot 2025-02-16 091101
1351√ó292 13.3 KB
Screenshot 2025-02-17 200414
1338√ó200 18.2 KB
Screenshot 2025-02-17 200525
1312√ó321 18.5 KB

[2025-02-17T15:44:43.711Z] Shambhavi  (@24f2003130)
Wait we had limits in codespace‚Ä¶I didn‚Äôt thought much of it but now that I see‚Ä¶ ‚Ä¶even mine is not so far from the limit‚Ä¶thanks for reminding‚Ä¶gotta be careful in next project

[2025-02-18T07:30:10.106Z] Pradeep Mondal (@21f2000709)
@carlton
@Jivraj
Is there something like peer-review in the project, I found this in the grading document.
Screenshot 2025-02-18 at 1.00.50 PM
126√ó226 2.02 KB

[2025-02-18T07:44:45.153Z] Pradeep Mondal (@21f2000709)
This project is one of the best experiences I had in the entire degree program. I could say this without any hesitation that what I learnt in the past 10 days >> last 3 months.
I really appreciate the idea of open internet type of evaluations, wherein, you implement things without any constraints, learning for the sake of implementing.
Doing this project, I also found many new ideas wherein function calling can be used to solve new problems. I also learned many new things from enthusiastic peers like
@23f1002382
and also got the chance to help a few.
I thank the entire TDS team -
@s.anand
sir,
@carlton
,
@Jivraj
for their support throughout this amazing experience.
Regards,
Pradeep Mondal

[2025-02-18T15:50:42.691Z] Jivraj Singh Shekhawat (@Jivraj: Course TA)
Thanks
@21f2000709
for kind words
Tagging Saransh for his efforts to project
@Saransh_Saini
.
@23f1002382
most active student on this post thanks to you too.
Kind regards

[2025-02-18T16:10:39.846Z] Pradeep Mondal (@21f2000709)
21f2000709:
@carlton
@Jivraj
Is there something like peer-review in the project, I found this in the grading document.
Anyone having any idea on this?

[2025-02-19T11:00:09.298Z] Jivraj Singh Shekhawat (@Jivraj: Course TA)
A post was merged into an existing topic:
Project 1 - Casual banter

[2025-02-24T09:01:12.099Z] Carlton D'Silva (@carlton: Regular)
No human peer reviews. The peer will be an LLM that has been given the rubrics and fine tuned.
Kind regards

[2025-02-24T09:47:29.302Z] Pradeep Mondal (@21f2000709)
carlton:
The peer will be an LLM that has been given the rubrics and fine tuned.
May the peer give me good marks

[2025-02-25T08:02:56.360Z] Yogesh (@Yogesh1)
@carlton
Would the scores of project 1 be released tomorrow?

[2025-02-26T02:41:56.425Z] Carlton D'Silva (@carlton: Regular)
@Yogesh1
We do not have an ETA on Project 1 scores yet. Might have more clarity soon.
Project 1 scores will be available roughly second week of March.
Kind regards

[2025-02-26T02:51:34.212Z] Carlton D'Silva (@carlton: Regular)
@lakshaygarg654
I know this is a late reply, but its not possible for us to consider changes to your project after the deadline for academic integrity purposes.
If we were to allow it, we would have to allow everyone to make changes to their project as well for it to be fair.
Kind regards

[2025-02-26T02:53:21.351Z] Carlton D'Silva (@carlton: Regular)
We will soon provide a complete solution for Project 1 because of its valuable learning.

[2025-02-26T06:30:31.260Z] LAKSHAY (@lakshaygarg654)
Alright,
@Carlton
. No problem at all, and thank you for your response.
I just wanted to bring a small limitation in my project‚Äôs LLM function to your attention, which I discovered after submission. It may impact one or two tasks. However, no concerns‚Äîthis has been a great learning experience.
And if possible, just add one line in your Evaluation LLM prompt:
‚ÄúGive loose marking for effort!‚Äù
‚Äîbecause, you know, creativity deserves some extra credit!

[2025-03-12T14:34:53.467Z] Garima (@garimaa)
I am not able to see my project marks please look into the problem

[2025-03-14T11:00:33.184Z] Carlton D'Silva (@carlton: Regular)
Its not been evaluated yet.
We are still processing them.
Kind regards

[2025-03-16T15:13:37.996Z] Naga durga prasad E (@23f3004114)
So will the solution be based on New MCP style or will they use the same function calling?

[2025-03-17T12:40:26.308Z] Carlton D'Silva (@carlton: Regular)
Definitely MCP style. Its the most elegant solution and it works beautifully. As soon as evals are done we will showcase it.

[2025-03-22T13:24:45.799Z] Yogesh (@Yogesh1)
@carlton
Any ETA on project 1 scores?

[2025-03-23T07:02:28.304Z] Manmeet Kaur (@21f3001993)
I would like to request some bonus like 0.5 bonus mark for each day of delay from the original expected date of receiving score for Project 1 (will be life-saving for us and will be an incentive for team to release scores quickly; or request to TAs if you had better ideas for helping us score more in Project 1)!

[2025-03-26T08:05:58.369Z] Pradeep Mondal (@21f2000709)
Any Updates? Can we expect it to be out before P2 deadline?

[2025-03-31T21:05:36.632Z] Shreyan Chaubey (@thinkmachine)
image
412√ó167 4.49 KB
image
439√ó204 7.25 KB
This docker image has outlived many students‚Äô hopes, dreams and ambitions of passing this course.
Why is it still not being detected properly on the docker hub?
What in the April Fools is this
It hasn‚Äôt even been morning yet!
PS (
@carlton
@Jivraj
): My P1 submission had passed all the basic sanity checks on 15th February. No breaking modifications to the Github repo nor the DockerHub image have been made since then. There‚Äôs something bugged in your scripts. Kindly check.

[2025-04-01T01:53:24.825Z] Bharat Choudhary (@23f1000879)
same issue here
i have my git repo public but its saying i don‚Äôt have public git repo, also i have dockerfile in my root folder but its also said fail, same for mit license
image
1889√ó1022 122 KB

[2025-04-01T05:56:46.782Z] HARISH. S (@HARISH.S)
yes sir same problem
image
885√ó346 15.3 KB
image
1330√ó718 54.7 KB
please check and say sir.
image
1918√ó1078 187 KB
sir it seems like there was a problem when i pushed this files to the repo but i defenitely did correctly. PLease allow me to add docker file alone with your permission. As you can see i haven‚Äôt opened the dockerfile since the last date of project 1. Kindly allow this sir. and i have MiT license in my repo but still showing fail . kindly check that also sir.
@carlton
@s.anand
@Jivraj

[2025-04-01T06:04:51.580Z] HARISH. S (@HARISH.S)
yes sir same problem
image
885√ó346 15.3 KB
image
1330√ó718 54.7 KB
please check and say sir.
image
1918√ó1078 187 KB
sir it seems like there was a problem when i pushed this files to the repo but i defenitely did correctly. PLease allow me to add docker file alone with your permission. As you can see i haven‚Äôt opened the dockerfile since the last date of project 1. Kindly allow this sir. and i have MiT license in my repo but still showing fail . kindly check that also sir.
@carlton
@s.anand
@Jivraj

[2025-04-01T16:52:05.625Z] Veer Shah (@23f1001524)
same issue with me , my repo has both the dockerfile , license and is public. Please look into this .
@carlton
sir .
GitHub - veershah1231/tds_proj_1: Tds project
and i have made them 2 months ago and is not a new commit.
1000105386
1072√ó1787 256 KB

[2025-04-06T06:44:58.937Z] Andrew David (@23f1002382)
I came pretty close, but too close(double entendre) to the deadline. Classic ICARUS stuff
0/20